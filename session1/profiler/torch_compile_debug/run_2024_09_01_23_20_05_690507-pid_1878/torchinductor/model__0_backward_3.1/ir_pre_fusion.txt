buf0: ExternKernelSchedulerNode(ExternKernelOut)
buf0.writes = [StarDep(name='buf0', mode=None)]
buf0.unmet_dependencies = []
buf0.met_dependencies = [StarDep(name='permute_1', mode=None), StarDep(name='tangents_1', mode=None)]
buf0.users = [NodeUser(node=SchedulerNode(name='buf3'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf5'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf8'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf21'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf23'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf25'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf31'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf33'), can_inplace=False, is_weak=False)]
buf0.node.kernel = extern_kernels.mm


buf1: ExternKernelSchedulerNode(ExternKernelOut)
buf1.writes = [StarDep(name='buf1', mode=None)]
buf1.unmet_dependencies = []
buf1.met_dependencies = [StarDep(name='tangents_1', mode=None), StarDep(name='view', mode=None)]
buf1.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf1.node.kernel = extern_kernels.mm


buf2: SchedulerNode(ComputedBuffer)
buf2.writes = [MemoryDep('buf2', c0, {c0: 1000}, None)]
buf2.unmet_dependencies = []
buf2.met_dependencies = [MemoryDep('tangents_1', c0 + 1000*c1, {c0: 1000, c1: 32}, None)]
buf2.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf2.group.device = cuda:0
buf2.group.iteration = (1000, 32)
buf2.sizes = ([1000], [32])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[32, 1000], stride=[1000, 1])
buf2_layout = FixedLayout('cuda', torch.float32, size=[1, 1000], stride=[1000, 1])
class buf2_loop_body:
    var_ranges = {z0: 1000, z1: 32}
    index0 = z0 + 1000*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('tangents_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf2', get_index_1, reduction)
        return store_reduction
buf2 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[1024, 32],
        reduction_hint=ReductionHint.DEFAULT,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 1000
        rnumel = 32
        RBLOCK: tl.constexpr = 32
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (1000*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf3: SchedulerNode(ComputedBuffer)
buf3.writes = [MemoryDep('buf3', c0, {c0: 6656}, None)]
buf3.unmet_dependencies = [   MemoryDep('buf0', c1 + 512*ModularIndexing(121*c0 + c2, 49, 32), {c0: 13, c1: 512, c2: 121}, None)]
buf3.met_dependencies = [   MemoryDep('le', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf3.users = [NodeUser(node=SchedulerNode(name='buf4'), can_inplace=False, is_weak=False)]
buf3.group.device = cuda:0
buf3.group.iteration = (6656, 121)
buf3.sizes = ([13, 512], [121])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
buf3_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf3_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = z1 + 512*ModularIndexing(121*z0 + z2, 49, 32)
    index3 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index3')
        store_reduction = ops.store_reduction('buf3', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('le', get_index)
        get_index_1 = self.get_index('index2')
        load_1 = ops.load('buf0', get_index_1)
        constant = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_1, constant)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(load, constant_1, mul)
        return where
buf3 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp12 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0).to(tl.int1)
            tmp4 = tl.load(in_ptr1 + (x0 + (512*(((r2 + (121*x1)) // 49) % 32))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp5 = 0.02040816326530612
            tmp6 = tmp4 * tmp5
            tmp7 = 0.0
            tmp8 = tl.where(tmp3, tmp7, tmp6)
            tmp9 = tl.full(tmp8.shape, 0, tmp8.dtype)
            tmp10 = tl.where(tmp2, tmp8, tmp9)
            tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
            tmp13 = _tmp12 + tmp11
            _tmp12 = tl.where(rmask & xmask, tmp13, _tmp12)
        tmp12 = tl.sum(_tmp12, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp12, xmask)


buf4: SchedulerNode(ComputedBuffer)
buf4.writes = [MemoryDep('buf4', c0, {c0: 512}, None)]
buf4.unmet_dependencies = [MemoryDep('buf3', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf4.met_dependencies = []
buf4.users = [NodeUser(node=SchedulerNode(name='buf8'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf4.group.device = cuda:0
buf4.group.iteration = (512, 13)
buf4.sizes = ([512], [13])
buf3_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf4_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf4_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf3', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf4', get_index_1, reduction)
        return store_reduction
buf4 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf5: SchedulerNode(ComputedBuffer)
buf5.writes = [MemoryDep('buf5', c0, {c0: 6656}, None)]
buf5.unmet_dependencies = [   MemoryDep('buf0', c1 + 512*ModularIndexing(121*c0 + c2, 49, 32), {c0: 13, c1: 512, c2: 121}, None)]
buf5.met_dependencies = 
    [   MemoryDep('convolution_19', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('le', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('unsqueeze_82', c1, {c0: 13, c1: 512}, None)]
buf5.users = [NodeUser(node=SchedulerNode(name='buf6'), can_inplace=False, is_weak=False)]
buf5.group.device = cuda:0
buf5.group.iteration = (6656, 121)
buf5.sizes = ([13, 512], [121])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
convolution_19_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
unsqueeze_82_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
buf5_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf5_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = z1 + 512*ModularIndexing(121*z0 + z2, 49, 32)
    index3 = z1
    index4 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf5', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('le', get_index)
        get_index_1 = self.get_index('index2')
        load_1 = ops.load('buf0', get_index_1)
        constant = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_1, constant)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(load, constant_1, mul)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('convolution_19', get_index_2)
        get_index_3 = self.get_index('index3')
        load_3 = ops.load('unsqueeze_82', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul_1 = ops.mul(where, sub)
        return mul_1
buf5 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp16 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0).to(tl.int1)
            tmp4 = tl.load(in_ptr1 + (x0 + (512*(((r2 + (121*x1)) // 49) % 32))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp5 = 0.02040816326530612
            tmp6 = tmp4 * tmp5
            tmp7 = 0.0
            tmp8 = tl.where(tmp3, tmp7, tmp6)
            tmp9 = tl.load(in_ptr2 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp10 = tl.load(in_ptr3 + (tl.broadcast_to(x0, [XBLOCK, RBLOCK])), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp11 = tmp9 - tmp10
            tmp12 = tmp8 * tmp11
            tmp13 = tl.full(tmp12.shape, 0, tmp12.dtype)
            tmp14 = tl.where(tmp2, tmp12, tmp13)
            tmp15 = tl.broadcast_to(tmp14, [XBLOCK, RBLOCK])
            tmp17 = _tmp16 + tmp15
            _tmp16 = tl.where(rmask & xmask, tmp17, _tmp16)
        tmp16 = tl.sum(_tmp16, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp16, xmask)


buf6: SchedulerNode(ComputedBuffer)
buf6.writes = [MemoryDep('buf6', c0, {c0: 512}, None)]
buf6.unmet_dependencies = [MemoryDep('buf5', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf6.met_dependencies = []
buf6.users = [NodeUser(node=SchedulerNode(name='buf7'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf8'), can_inplace=False, is_weak=False)]
buf6.group.device = cuda:0
buf6.group.iteration = (512, 13)
buf6.sizes = ([512], [13])
buf5_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf6_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf6_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf5', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf6', get_index_1, reduction)
        return store_reduction
buf6 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf7: SchedulerNode(ComputedBuffer)
buf7.writes = [MemoryDep('buf7', c0, {c0: 512}, None)]
buf7.unmet_dependencies = [MemoryDep('buf6', c0, {c0: 512}, None)]
buf7.met_dependencies = [MemoryDep('squeeze_58', c0, {c0: 512}, None)]
buf7.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf7.group.device = cuda:0
buf7.group.iteration = (512, 1)
buf7.sizes = ([512], [])
buf6_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
squeeze_58_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf7_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf7_loop_body:
    var_ranges = {z0: 512}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf6', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_58', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf7', get_index_2, mul, None)
        return store
buf7 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[512], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf8: SchedulerNode(ComputedBuffer)
buf8.writes = [MemoryDep('buf8', c0, {c0: 802816}, None)]
buf8.unmet_dependencies = 
    [   MemoryDep('buf0', 512*c0 + c2, {c0: 32, c1: 49, c2: 512}, None),
        MemoryDep('buf4', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf6', c1, {c0: 1568, c1: 512}, None)]
buf8.met_dependencies = 
    [   MemoryDep('convolution_19', c0, {c0: 802816}, None),
        MemoryDep('le', c0, {c0: 802816}, None),
        MemoryDep('primals_59', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('squeeze_58', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('unsqueeze_82', c1, {c0: 1568, c1: 512}, None)]
buf8.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf9'), can_inplace=False, is_weak=False)]
buf8.group.device = cuda:0
buf8.group.iteration = (802816, 1)
buf8.sizes = ([32, 49, 512], [])
squeeze_58_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
convolution_19_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf4_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
unsqueeze_82_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
buf6_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
primals_59_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
buf8_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf8_loop_body:
    var_ranges = {z0: 32, z1: 49, z2: 512}
    index0 = 25088*z0 + 512*z1 + z2
    index1 = 512*z0 + z2
    index2 = z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('le', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf0', get_index_1)
        constant = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_1, constant)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(load, constant_1, mul)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_19', get_index_2)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('unsqueeze_82', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('buf6', get_index_4)
        constant_2 = ops.constant(0.0006377551020408163, torch.float32)
        mul_1 = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index2')
        load_5 = ops.load('squeeze_58', get_index_5)
        get_index_6 = self.get_index('index2')
        load_6 = ops.load('squeeze_58', get_index_6)
        mul_2 = ops.mul(load_5, load_6)
        mul_3 = ops.mul(mul_1, mul_2)
        mul_4 = ops.mul(sub, mul_3)
        sub_1 = ops.sub(where, mul_4)
        get_index_7 = self.get_index('index2')
        load_7 = ops.load('buf4', get_index_7)
        constant_3 = ops.constant(0.0006377551020408163, torch.float32)
        mul_5 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_5)
        get_index_8 = self.get_index('index2')
        load_8 = ops.load('squeeze_58', get_index_8)
        get_index_9 = self.get_index('index2')
        load_9 = ops.load('primals_59', get_index_9)
        mul_6 = ops.mul(load_8, load_9)
        mul_7 = ops.mul(sub_2, mul_6)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf8', get_index_10, mul_7, None)
        return store
buf8 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x3 = xindex
        x0 = xindex % 512
        x2 = (xindex // 25088)
        tmp0 = tl.load(in_ptr0 + (x3), None).to(tl.int1)
        tmp1 = tl.load(in_ptr1 + (x0 + (512*x2)), None, eviction_policy='evict_last')
        tmp6 = tl.load(in_ptr2 + (x3), None)
        tmp7 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp9 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp17 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp20 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp2 = 0.02040816326530612
        tmp3 = tmp1 * tmp2
        tmp4 = 0.0
        tmp5 = tl.where(tmp0, tmp4, tmp3)
        tmp8 = tmp6 - tmp7
        tmp10 = 0.0006377551020408163
        tmp11 = tmp9 * tmp10
        tmp13 = tmp12 * tmp12
        tmp14 = tmp11 * tmp13
        tmp15 = tmp8 * tmp14
        tmp16 = tmp5 - tmp15
        tmp18 = tmp17 * tmp10
        tmp19 = tmp16 - tmp18
        tmp21 = tmp12 * tmp20
        tmp22 = tmp19 * tmp21
        tl.store(out_ptr0 + (x3), tmp22, None)


buf9: ExternKernelSchedulerNode(FallbackKernel)
buf9.writes = [StarDep(name='buf9', mode=None)]
buf9.unmet_dependencies = [StarDep(name='buf8', mode=None)]
buf9.met_dependencies = [StarDep(name='primals_58', mode=None), StarDep(name='relu_15', mode=None)]
buf9.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf10'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf11'), can_inplace=False, is_weak=False)]
buf9.node.kernel = None


buf10: ExternKernelSchedulerNode(MultiOutput)
buf10.writes = [StarDep(name='buf10', mode=None)]
buf10.unmet_dependencies = [StarDep(name='buf9', mode=None)]
buf10.met_dependencies = []
buf10.users = [NodeUser(node=SchedulerNode(name='buf12'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf14'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf17'), can_inplace=True, is_weak=False)]
buf10.node.kernel = None


buf11: ExternKernelSchedulerNode(MultiOutput)
buf11.writes = [StarDep(name='buf11', mode=None)]
buf11.unmet_dependencies = [StarDep(name='buf9', mode=None)]
buf11.met_dependencies = []
buf11.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf11.node.kernel = None


buf12: SchedulerNode(ComputedBuffer)
buf12.writes = [MemoryDep('buf12', c0, {c0: 6656}, None)]
buf12.unmet_dependencies = [   MemoryDep('buf10', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf12.met_dependencies = [   MemoryDep('relu_15', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf12.users = [NodeUser(node=SchedulerNode(name='buf13'), can_inplace=False, is_weak=False)]
buf12.group.device = cuda:0
buf12.group.iteration = (6656, 121)
buf12.sizes = ([13, 512], [121])
buf10_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
relu_15_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf12_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf12_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf12', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('relu_15', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf10', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        return where
buf12 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp11 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = 0.0
            tmp5 = tmp3 <= tmp4
            tmp6 = tl.load(in_ptr1 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp7 = tl.where(tmp5, tmp4, tmp6)
            tmp8 = tl.full(tmp7.shape, 0, tmp7.dtype)
            tmp9 = tl.where(tmp2, tmp7, tmp8)
            tmp10 = tl.broadcast_to(tmp9, [XBLOCK, RBLOCK])
            tmp12 = _tmp11 + tmp10
            _tmp11 = tl.where(rmask & xmask, tmp12, _tmp11)
        tmp11 = tl.sum(_tmp11, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp11, xmask)


buf13: SchedulerNode(ComputedBuffer)
buf13.writes = [MemoryDep('buf13', c0, {c0: 512}, None)]
buf13.unmet_dependencies = [MemoryDep('buf12', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf13.met_dependencies = []
buf13.users = [NodeUser(node=SchedulerNode(name='buf17'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf13.group.device = cuda:0
buf13.group.iteration = (512, 13)
buf13.sizes = ([512], [13])
buf12_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf13_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf13_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf12', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf13', get_index_1, reduction)
        return store_reduction
buf13 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf14: SchedulerNode(ComputedBuffer)
buf14.writes = [MemoryDep('buf14', c0, {c0: 6656}, None)]
buf14.unmet_dependencies = [   MemoryDep('buf10', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf14.met_dependencies = 
    [   MemoryDep('convolution_18', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('relu_15', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('unsqueeze_94', c1, {c0: 13, c1: 512}, None)]
buf14.users = [NodeUser(node=SchedulerNode(name='buf15'), can_inplace=False, is_weak=False)]
buf14.group.device = cuda:0
buf14.group.iteration = (6656, 121)
buf14.sizes = ([13, 512], [121])
unsqueeze_94_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
convolution_18_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf10_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
relu_15_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf14_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf14_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = z1
    index3 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index3')
        store_reduction = ops.store_reduction('buf14', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('relu_15', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf10', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('convolution_18', get_index_2)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('unsqueeze_94', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        return mul
buf14 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = 0.0
            tmp5 = tmp3 <= tmp4
            tmp6 = tl.load(in_ptr1 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp7 = tl.where(tmp5, tmp4, tmp6)
            tmp8 = tl.load(in_ptr2 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp9 = tl.load(in_ptr3 + (tl.broadcast_to(x0, [XBLOCK, RBLOCK])), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp10 = tmp8 - tmp9
            tmp11 = tmp7 * tmp10
            tmp12 = tl.full(tmp11.shape, 0, tmp11.dtype)
            tmp13 = tl.where(tmp2, tmp11, tmp12)
            tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
            tmp16 = _tmp15 + tmp14
            _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
        tmp15 = tl.sum(_tmp15, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp15, xmask)


buf15: SchedulerNode(ComputedBuffer)
buf15.writes = [MemoryDep('buf15', c0, {c0: 512}, None)]
buf15.unmet_dependencies = [MemoryDep('buf14', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf15.met_dependencies = []
buf15.users = [NodeUser(node=SchedulerNode(name='buf16'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf17'), can_inplace=False, is_weak=False)]
buf15.group.device = cuda:0
buf15.group.iteration = (512, 13)
buf15.sizes = ([512], [13])
buf14_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf15_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf15_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf14', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf15', get_index_1, reduction)
        return store_reduction
buf15 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf16: SchedulerNode(ComputedBuffer)
buf16.writes = [MemoryDep('buf16', c0, {c0: 512}, None)]
buf16.unmet_dependencies = [MemoryDep('buf15', c0, {c0: 512}, None)]
buf16.met_dependencies = [MemoryDep('squeeze_55', c0, {c0: 512}, None)]
buf16.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf16.group.device = cuda:0
buf16.group.iteration = (512, 1)
buf16.sizes = ([512], [])
buf15_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
squeeze_55_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf16_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf16_loop_body:
    var_ranges = {z0: 512}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf15', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_55', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf16', get_index_2, mul, None)
        return store
buf16 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[512], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf17: SchedulerNode(ComputedBuffer)
buf17.writes = [MemoryDep('buf17', c0, {c0: 802816}, None)]
buf17.unmet_dependencies = 
    [   MemoryDep('buf10', c0, {c0: 802816}, None),
        MemoryDep('buf13', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf15', c1, {c0: 1568, c1: 512}, None)]
buf17.met_dependencies = 
    [   MemoryDep('convolution_18', c0, {c0: 802816}, None),
        MemoryDep('primals_56', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('relu_15', c0, {c0: 802816}, None),
        MemoryDep('squeeze_55', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('unsqueeze_94', c1, {c0: 1568, c1: 512}, None)]
buf17.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf18'), can_inplace=False, is_weak=False)]
buf17.group.device = cuda:0
buf17.group.iteration = (802816, 1)
buf17.sizes = ([1568, 512], [])
relu_15_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
squeeze_55_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf13_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf10_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf15_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
primals_56_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
unsqueeze_94_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
convolution_18_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf17_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf17_loop_body:
    var_ranges = {z0: 1568, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_15', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf10', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_18', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_94', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf15', get_index_4)
        constant_2 = ops.constant(0.0006377551020408163, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_55', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_55', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf13', get_index_7)
        constant_3 = ops.constant(0.0006377551020408163, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_55', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_56', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf17', get_index_10, mul_6, None)
        return store
buf17 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 512
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 0.0006377551020408163
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf18: ExternKernelSchedulerNode(FallbackKernel)
buf18.writes = [StarDep(name='buf18', mode=None)]
buf18.unmet_dependencies = [StarDep(name='buf17', mode=None)]
buf18.met_dependencies = [StarDep(name='primals_55', mode=None), StarDep(name='relu_14', mode=None)]
buf18.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf19'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf20'), can_inplace=False, is_weak=False)]
buf18.node.kernel = None


buf19: ExternKernelSchedulerNode(MultiOutput)
buf19.writes = [StarDep(name='buf19', mode=None)]
buf19.unmet_dependencies = [StarDep(name='buf18', mode=None)]
buf19.met_dependencies = []
buf19.users = [NodeUser(node=SchedulerNode(name='buf21'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf23'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf25'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf31'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf33'), can_inplace=True, is_weak=False)]
buf19.node.kernel = None


buf20: ExternKernelSchedulerNode(MultiOutput)
buf20.writes = [StarDep(name='buf20', mode=None)]
buf20.unmet_dependencies = [StarDep(name='buf18', mode=None)]
buf20.met_dependencies = []
buf20.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf20.node.kernel = None


buf21: SchedulerNode(ComputedBuffer)
buf21.writes = [MemoryDep('buf21', c0, {c0: 6656}, None)]
buf21.unmet_dependencies = 
    [   MemoryDep('buf0', c1 + 512*ModularIndexing(121*c0 + c2, 49, 32), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('buf19', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf21.met_dependencies = 
    [   MemoryDep('le', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('relu_14', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf21.users = [NodeUser(node=SchedulerNode(name='buf22'), can_inplace=False, is_weak=False)]
buf21.group.device = cuda:0
buf21.group.iteration = (6656, 121)
buf21.sizes = ([13, 512], [121])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf19_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
relu_14_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf21_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf21_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = z1 + 512*ModularIndexing(121*z0 + z2, 49, 32)
    index3 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index3')
        store_reduction = ops.store_reduction('buf21', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('relu_14', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('le', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf0', get_index_2)
        constant_1 = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_2, constant_1)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(load_1, constant_2, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf19', get_index_3)
        add = ops.add(where, load_3)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add)
        return where_1
buf21 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*i1', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp17 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = 0.0
            tmp5 = tmp3 <= tmp4
            tmp6 = tl.load(in_ptr1 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0).to(tl.int1)
            tmp7 = tl.load(in_ptr2 + (x0 + (512*(((r2 + (121*x1)) // 49) % 32))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp8 = 0.02040816326530612
            tmp9 = tmp7 * tmp8
            tmp10 = tl.where(tmp6, tmp4, tmp9)
            tmp11 = tl.load(in_ptr3 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp12 = tmp10 + tmp11
            tmp13 = tl.where(tmp5, tmp4, tmp12)
            tmp14 = tl.full(tmp13.shape, 0, tmp13.dtype)
            tmp15 = tl.where(tmp2, tmp13, tmp14)
            tmp16 = tl.broadcast_to(tmp15, [XBLOCK, RBLOCK])
            tmp18 = _tmp17 + tmp16
            _tmp17 = tl.where(rmask & xmask, tmp18, _tmp17)
        tmp17 = tl.sum(_tmp17, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp17, xmask)


buf22: SchedulerNode(ComputedBuffer)
buf22.writes = [MemoryDep('buf22', c0, {c0: 512}, None)]
buf22.unmet_dependencies = [MemoryDep('buf21', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf22.met_dependencies = []
buf22.users = [NodeUser(node=SchedulerNode(name='buf25'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf33'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf22.group.device = cuda:0
buf22.group.iteration = (512, 13)
buf22.sizes = ([512], [13])
buf21_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf22_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf22_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf21', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf22', get_index_1, reduction)
        return store_reduction
buf22 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf23: SchedulerNode(ComputedBuffer)
buf23.writes = [MemoryDep('buf23', c0, {c0: 6656}, None)]
buf23.unmet_dependencies = 
    [   MemoryDep('buf0', c1 + 512*ModularIndexing(121*c0 + c2, 49, 32), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('buf19', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf23.met_dependencies = 
    [   MemoryDep('convolution_17', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('le', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('relu_14', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('unsqueeze_106', c1, {c0: 13, c1: 512}, None)]
buf23.users = [NodeUser(node=SchedulerNode(name='buf24'), can_inplace=False, is_weak=False)]
buf23.group.device = cuda:0
buf23.group.iteration = (6656, 121)
buf23.sizes = ([13, 512], [121])
unsqueeze_106_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
convolution_17_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf19_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
relu_14_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf23_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf23_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = z1 + 512*ModularIndexing(121*z0 + z2, 49, 32)
    index3 = z1
    index4 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf23', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('relu_14', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('le', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf0', get_index_2)
        constant_1 = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_2, constant_1)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(load_1, constant_2, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf19', get_index_3)
        add = ops.add(where, load_3)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('convolution_17', get_index_4)
        get_index_5 = self.get_index('index3')
        load_5 = ops.load('unsqueeze_106', get_index_5)
        sub = ops.sub(load_4, load_5)
        mul_1 = ops.mul(where_1, sub)
        return mul_1
buf23 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*i1', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp21 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = 0.0
            tmp5 = tmp3 <= tmp4
            tmp6 = tl.load(in_ptr1 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0).to(tl.int1)
            tmp7 = tl.load(in_ptr2 + (x0 + (512*(((r2 + (121*x1)) // 49) % 32))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp8 = 0.02040816326530612
            tmp9 = tmp7 * tmp8
            tmp10 = tl.where(tmp6, tmp4, tmp9)
            tmp11 = tl.load(in_ptr3 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp12 = tmp10 + tmp11
            tmp13 = tl.where(tmp5, tmp4, tmp12)
            tmp14 = tl.load(in_ptr4 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp15 = tl.load(in_ptr5 + (tl.broadcast_to(x0, [XBLOCK, RBLOCK])), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp16 = tmp14 - tmp15
            tmp17 = tmp13 * tmp16
            tmp18 = tl.full(tmp17.shape, 0, tmp17.dtype)
            tmp19 = tl.where(tmp2, tmp17, tmp18)
            tmp20 = tl.broadcast_to(tmp19, [XBLOCK, RBLOCK])
            tmp22 = _tmp21 + tmp20
            _tmp21 = tl.where(rmask & xmask, tmp22, _tmp21)
        tmp21 = tl.sum(_tmp21, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp21, xmask)


buf24: SchedulerNode(ComputedBuffer)
buf24.writes = [MemoryDep('buf24', c0, {c0: 512}, None)]
buf24.unmet_dependencies = [MemoryDep('buf23', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf24.met_dependencies = []
buf24.users = [NodeUser(node=SchedulerNode(name='buf25'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf26'), can_inplace=True, is_weak=False)]
buf24.group.device = cuda:0
buf24.group.iteration = (512, 13)
buf24.sizes = ([512], [13])
buf23_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf24_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf24_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf23', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf24', get_index_1, reduction)
        return store_reduction
buf24 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf25: SchedulerNode(ComputedBuffer)
buf25.writes = [MemoryDep('buf25', c0, {c0: 802816}, None)]
buf25.unmet_dependencies = 
    [   MemoryDep('buf0', 512*c0 + c2, {c0: 32, c1: 49, c2: 512}, None),
        MemoryDep('buf19', c0, {c0: 802816}, None),
        MemoryDep('buf22', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf24', c1, {c0: 1568, c1: 512}, None)]
buf25.met_dependencies = 
    [   MemoryDep('convolution_17', c0, {c0: 802816}, None),
        MemoryDep('le', c0, {c0: 802816}, None),
        MemoryDep('relu_14', c0, {c0: 802816}, None),
        MemoryDep('squeeze_52', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('unsqueeze_106', c1, {c0: 1568, c1: 512}, None)]
buf25.users = [NodeUser(node=SchedulerNode(name='buf27'), can_inplace=True, is_weak=False)]
buf25.group.device = cuda:0
buf25.group.iteration = (802816, 1)
buf25.sizes = ([32, 49, 512], [])
buf22_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
relu_14_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
convolution_17_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf24_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf19_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
unsqueeze_106_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
squeeze_52_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf25_loop_body:
    var_ranges = {z0: 32, z1: 49, z2: 512}
    index0 = 25088*z0 + 512*z1 + z2
    index1 = 512*z0 + z2
    index2 = z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_14', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('le', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf0', get_index_2)
        constant_1 = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_2, constant_1)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(load_1, constant_2, mul)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('buf19', get_index_3)
        add = ops.add(where, load_3)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add)
        get_index_4 = self.get_index('index0')
        load_4 = ops.load('convolution_17', get_index_4)
        get_index_5 = self.get_index('index2')
        load_5 = ops.load('unsqueeze_106', get_index_5)
        sub = ops.sub(load_4, load_5)
        get_index_6 = self.get_index('index2')
        load_6 = ops.load('buf24', get_index_6)
        constant_4 = ops.constant(0.0006377551020408163, torch.float32)
        mul_1 = ops.mul(load_6, constant_4)
        get_index_7 = self.get_index('index2')
        load_7 = ops.load('squeeze_52', get_index_7)
        get_index_8 = self.get_index('index2')
        load_8 = ops.load('squeeze_52', get_index_8)
        mul_2 = ops.mul(load_7, load_8)
        mul_3 = ops.mul(mul_1, mul_2)
        mul_4 = ops.mul(sub, mul_3)
        sub_1 = ops.sub(where_1, mul_4)
        get_index_9 = self.get_index('index2')
        load_9 = ops.load('buf22', get_index_9)
        constant_5 = ops.constant(0.0006377551020408163, torch.float32)
        mul_5 = ops.mul(load_9, constant_5)
        sub_2 = ops.sub(sub_1, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf25', get_index_10, sub_2, None)
        return store
buf25 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*i1', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x3 = xindex
        x0 = xindex % 512
        x2 = (xindex // 25088)
        tmp0 = tl.load(in_ptr0 + (x3), None)
        tmp3 = tl.load(in_ptr1 + (x3), None).to(tl.int1)
        tmp4 = tl.load(in_ptr2 + (x0 + (512*x2)), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr3 + (x3), None)
        tmp11 = tl.load(in_ptr4 + (x3), None)
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp14 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = 0.02040816326530612
        tmp6 = tmp4 * tmp5
        tmp7 = tl.where(tmp3, tmp1, tmp6)
        tmp9 = tmp7 + tmp8
        tmp10 = tl.where(tmp2, tmp1, tmp9)
        tmp13 = tmp11 - tmp12
        tmp15 = 0.0006377551020408163
        tmp16 = tmp14 * tmp15
        tmp18 = tmp17 * tmp17
        tmp19 = tmp16 * tmp18
        tmp20 = tmp13 * tmp19
        tmp21 = tmp10 - tmp20
        tmp23 = tmp22 * tmp15
        tmp24 = tmp21 - tmp23
        tl.store(out_ptr0 + (x3), tmp24, None)


buf26: SchedulerNode(ComputedBuffer)
buf26.writes = [MemoryDep('buf26', c0, {c0: 512}, None)]
buf26.unmet_dependencies = [MemoryDep('buf24', c0, {c0: 512}, None)]
buf26.met_dependencies = [MemoryDep('squeeze_52', c0, {c0: 512}, None)]
buf26.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf26.group.device = cuda:0
buf26.group.iteration = (512, 1)
buf26.sizes = ([512], [])
squeeze_52_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf24_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf26_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf26_loop_body:
    var_ranges = {z0: 512}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf24', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_52', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf26', get_index_2, mul, None)
        return store
buf26 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[512], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf27: SchedulerNode(ComputedBuffer)
buf27.writes = [MemoryDep('buf27', c0, {c0: 802816}, None)]
buf27.unmet_dependencies = [MemoryDep('buf25', c0, {c0: 802816}, None)]
buf27.met_dependencies = 
    [   MemoryDep('primals_53', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('squeeze_52', c1, {c0: 1568, c1: 512}, None)]
buf27.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf28'), can_inplace=False, is_weak=False)]
buf27.group.device = cuda:0
buf27.group.iteration = (802816, 1)
buf27.sizes = ([1568, 512], [])
primals_53_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
squeeze_52_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf27_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf27_loop_body:
    var_ranges = {z0: 1568, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf25', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('squeeze_52', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('primals_53', get_index_2)
        mul = ops.mul(load_1, load_2)
        mul_1 = ops.mul(load, mul)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf27', get_index_3, mul_1, None)
        return store
buf27 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 512
        tmp0 = tl.load(in_out_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
        tmp2 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tmp1 * tmp2
        tmp4 = tmp0 * tmp3
        tl.store(in_out_ptr0 + (x2), tmp4, None)


buf28: ExternKernelSchedulerNode(FallbackKernel)
buf28.writes = [StarDep(name='buf28', mode=None)]
buf28.unmet_dependencies = [StarDep(name='buf27', mode=None)]
buf28.met_dependencies = [StarDep(name='primals_52', mode=None), StarDep(name='relu_12', mode=None)]
buf28.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf29'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf30'), can_inplace=False, is_weak=False)]
buf28.node.kernel = None


buf29: ExternKernelSchedulerNode(MultiOutput)
buf29.writes = [StarDep(name='buf29', mode=None)]
buf29.unmet_dependencies = [StarDep(name='buf28', mode=None)]
buf29.met_dependencies = []
buf29.users = [NodeUser(node=SchedulerNode(name='buf48'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf50'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf52'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf66'), can_inplace=True, is_weak=False)]
buf29.node.kernel = None


buf30: ExternKernelSchedulerNode(MultiOutput)
buf30.writes = [StarDep(name='buf30', mode=None)]
buf30.unmet_dependencies = [StarDep(name='buf28', mode=None)]
buf30.met_dependencies = []
buf30.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf30.node.kernel = None


buf31: SchedulerNode(ComputedBuffer)
buf31.writes = [MemoryDep('buf31', c0, {c0: 6656}, None)]
buf31.unmet_dependencies = 
    [   MemoryDep('buf0', c1 + 512*ModularIndexing(121*c0 + c2, 49, 32), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('buf19', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf31.met_dependencies = 
    [   MemoryDep('convolution_16', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('le', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('relu_14', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('unsqueeze_118', c1, {c0: 13, c1: 512}, None)]
buf31.users = [NodeUser(node=SchedulerNode(name='buf32'), can_inplace=False, is_weak=False)]
buf31.group.device = cuda:0
buf31.group.iteration = (6656, 121)
buf31.sizes = ([13, 512], [121])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
convolution_16_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
unsqueeze_118_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
buf19_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
relu_14_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf31_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf31_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = z1 + 512*ModularIndexing(121*z0 + z2, 49, 32)
    index3 = z1
    index4 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf31', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('relu_14', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('le', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf0', get_index_2)
        constant_1 = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_2, constant_1)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(load_1, constant_2, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf19', get_index_3)
        add = ops.add(where, load_3)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('convolution_16', get_index_4)
        get_index_5 = self.get_index('index3')
        load_5 = ops.load('unsqueeze_118', get_index_5)
        sub = ops.sub(load_4, load_5)
        mul_1 = ops.mul(where_1, sub)
        return mul_1
buf31 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*i1', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp21 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = 0.0
            tmp5 = tmp3 <= tmp4
            tmp6 = tl.load(in_ptr1 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0).to(tl.int1)
            tmp7 = tl.load(in_ptr2 + (x0 + (512*(((r2 + (121*x1)) // 49) % 32))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp8 = 0.02040816326530612
            tmp9 = tmp7 * tmp8
            tmp10 = tl.where(tmp6, tmp4, tmp9)
            tmp11 = tl.load(in_ptr3 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp12 = tmp10 + tmp11
            tmp13 = tl.where(tmp5, tmp4, tmp12)
            tmp14 = tl.load(in_ptr4 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp15 = tl.load(in_ptr5 + (tl.broadcast_to(x0, [XBLOCK, RBLOCK])), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp16 = tmp14 - tmp15
            tmp17 = tmp13 * tmp16
            tmp18 = tl.full(tmp17.shape, 0, tmp17.dtype)
            tmp19 = tl.where(tmp2, tmp17, tmp18)
            tmp20 = tl.broadcast_to(tmp19, [XBLOCK, RBLOCK])
            tmp22 = _tmp21 + tmp20
            _tmp21 = tl.where(rmask & xmask, tmp22, _tmp21)
        tmp21 = tl.sum(_tmp21, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp21, xmask)


buf32: SchedulerNode(ComputedBuffer)
buf32.writes = [MemoryDep('buf32', c0, {c0: 512}, None)]
buf32.unmet_dependencies = [MemoryDep('buf31', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf32.met_dependencies = []
buf32.users = [NodeUser(node=SchedulerNode(name='buf33'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf34'), can_inplace=True, is_weak=False)]
buf32.group.device = cuda:0
buf32.group.iteration = (512, 13)
buf32.sizes = ([512], [13])
buf31_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf32_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf32_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf31', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf32', get_index_1, reduction)
        return store_reduction
buf32 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf33: SchedulerNode(ComputedBuffer)
buf33.writes = [MemoryDep('buf33', c0, {c0: 802816}, None)]
buf33.unmet_dependencies = 
    [   MemoryDep('buf0', 512*c0 + c2, {c0: 32, c1: 49, c2: 512}, None),
        MemoryDep('buf19', c0, {c0: 802816}, None),
        MemoryDep('buf22', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf32', c1, {c0: 1568, c1: 512}, None)]
buf33.met_dependencies = 
    [   MemoryDep('convolution_16', c0, {c0: 802816}, None),
        MemoryDep('le', c0, {c0: 802816}, None),
        MemoryDep('relu_14', c0, {c0: 802816}, None),
        MemoryDep('squeeze_49', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('unsqueeze_118', c1, {c0: 1568, c1: 512}, None)]
buf33.users = [NodeUser(node=SchedulerNode(name='buf35'), can_inplace=True, is_weak=False)]
buf33.group.device = cuda:0
buf33.group.iteration = (802816, 1)
buf33.sizes = ([32, 49, 512], [])
squeeze_49_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
convolution_16_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf22_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
relu_14_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
le_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf32_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf19_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
unsqueeze_118_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[32, 512], stride=[512, 1])
buf33_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf33_loop_body:
    var_ranges = {z0: 32, z1: 49, z2: 512}
    index0 = 25088*z0 + 512*z1 + z2
    index1 = 512*z0 + z2
    index2 = z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_14', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('le', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf0', get_index_2)
        constant_1 = ops.constant(0.02040816326530612, torch.float32)
        mul = ops.mul(load_2, constant_1)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(load_1, constant_2, mul)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('buf19', get_index_3)
        add = ops.add(where, load_3)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add)
        get_index_4 = self.get_index('index0')
        load_4 = ops.load('convolution_16', get_index_4)
        get_index_5 = self.get_index('index2')
        load_5 = ops.load('unsqueeze_118', get_index_5)
        sub = ops.sub(load_4, load_5)
        get_index_6 = self.get_index('index2')
        load_6 = ops.load('buf32', get_index_6)
        constant_4 = ops.constant(0.0006377551020408163, torch.float32)
        mul_1 = ops.mul(load_6, constant_4)
        get_index_7 = self.get_index('index2')
        load_7 = ops.load('squeeze_49', get_index_7)
        get_index_8 = self.get_index('index2')
        load_8 = ops.load('squeeze_49', get_index_8)
        mul_2 = ops.mul(load_7, load_8)
        mul_3 = ops.mul(mul_1, mul_2)
        mul_4 = ops.mul(sub, mul_3)
        sub_1 = ops.sub(where_1, mul_4)
        get_index_9 = self.get_index('index2')
        load_9 = ops.load('buf22', get_index_9)
        constant_5 = ops.constant(0.0006377551020408163, torch.float32)
        mul_5 = ops.mul(load_9, constant_5)
        sub_2 = ops.sub(sub_1, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf33', get_index_10, sub_2, None)
        return store
buf33 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*i1', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x3 = xindex
        x0 = xindex % 512
        x2 = (xindex // 25088)
        tmp0 = tl.load(in_ptr0 + (x3), None)
        tmp3 = tl.load(in_ptr1 + (x3), None).to(tl.int1)
        tmp4 = tl.load(in_ptr2 + (x0 + (512*x2)), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr3 + (x3), None)
        tmp11 = tl.load(in_ptr4 + (x3), None)
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp14 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = 0.02040816326530612
        tmp6 = tmp4 * tmp5
        tmp7 = tl.where(tmp3, tmp1, tmp6)
        tmp9 = tmp7 + tmp8
        tmp10 = tl.where(tmp2, tmp1, tmp9)
        tmp13 = tmp11 - tmp12
        tmp15 = 0.0006377551020408163
        tmp16 = tmp14 * tmp15
        tmp18 = tmp17 * tmp17
        tmp19 = tmp16 * tmp18
        tmp20 = tmp13 * tmp19
        tmp21 = tmp10 - tmp20
        tmp23 = tmp22 * tmp15
        tmp24 = tmp21 - tmp23
        tl.store(out_ptr0 + (x3), tmp24, None)


buf34: SchedulerNode(ComputedBuffer)
buf34.writes = [MemoryDep('buf34', c0, {c0: 512}, None)]
buf34.unmet_dependencies = [MemoryDep('buf32', c0, {c0: 512}, None)]
buf34.met_dependencies = [MemoryDep('squeeze_49', c0, {c0: 512}, None)]
buf34.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf34.group.device = cuda:0
buf34.group.iteration = (512, 1)
buf34.sizes = ([512], [])
squeeze_49_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf34_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf34_loop_body:
    var_ranges = {z0: 512}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf32', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_49', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf34', get_index_2, mul, None)
        return store
buf34 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[512], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf35: SchedulerNode(ComputedBuffer)
buf35.writes = [MemoryDep('buf35', c0, {c0: 802816}, None)]
buf35.unmet_dependencies = [MemoryDep('buf33', c0, {c0: 802816}, None)]
buf35.met_dependencies = 
    [   MemoryDep('primals_50', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('squeeze_49', c1, {c0: 1568, c1: 512}, None)]
buf35.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf36'), can_inplace=False, is_weak=False)]
buf35.group.device = cuda:0
buf35.group.iteration = (802816, 1)
buf35.sizes = ([1568, 512], [])
squeeze_49_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf33_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
primals_50_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf35_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf35_loop_body:
    var_ranges = {z0: 1568, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf33', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('squeeze_49', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('primals_50', get_index_2)
        mul = ops.mul(load_1, load_2)
        mul_1 = ops.mul(load, mul)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf35', get_index_3, mul_1, None)
        return store
buf35 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 512
        tmp0 = tl.load(in_out_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
        tmp2 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tmp1 * tmp2
        tmp4 = tmp0 * tmp3
        tl.store(in_out_ptr0 + (x2), tmp4, None)


buf36: ExternKernelSchedulerNode(FallbackKernel)
buf36.writes = [StarDep(name='buf36', mode=None)]
buf36.unmet_dependencies = [StarDep(name='buf35', mode=None)]
buf36.met_dependencies = [StarDep(name='primals_49', mode=None), StarDep(name='relu_13', mode=None)]
buf36.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf37'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf38'), can_inplace=False, is_weak=False)]
buf36.node.kernel = None


buf37: ExternKernelSchedulerNode(MultiOutput)
buf37.writes = [StarDep(name='buf37', mode=None)]
buf37.unmet_dependencies = [StarDep(name='buf36', mode=None)]
buf37.met_dependencies = []
buf37.users = [NodeUser(node=SchedulerNode(name='buf39'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf41'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf44'), can_inplace=True, is_weak=False)]
buf37.node.kernel = None


buf38: ExternKernelSchedulerNode(MultiOutput)
buf38.writes = [StarDep(name='buf38', mode=None)]
buf38.unmet_dependencies = [StarDep(name='buf36', mode=None)]
buf38.met_dependencies = []
buf38.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf38.node.kernel = None


buf39: SchedulerNode(ComputedBuffer)
buf39.writes = [MemoryDep('buf39', c0, {c0: 6656}, None)]
buf39.unmet_dependencies = [   MemoryDep('buf37', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf39.met_dependencies = [   MemoryDep('relu_13', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf39.users = [NodeUser(node=SchedulerNode(name='buf40'), can_inplace=False, is_weak=False)]
buf39.group.device = cuda:0
buf39.group.iteration = (6656, 121)
buf39.sizes = ([13, 512], [121])
relu_13_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf37_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf39_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf39_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf39', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('relu_13', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf37', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        return where
buf39 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp11 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = 0.0
            tmp5 = tmp3 <= tmp4
            tmp6 = tl.load(in_ptr1 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp7 = tl.where(tmp5, tmp4, tmp6)
            tmp8 = tl.full(tmp7.shape, 0, tmp7.dtype)
            tmp9 = tl.where(tmp2, tmp7, tmp8)
            tmp10 = tl.broadcast_to(tmp9, [XBLOCK, RBLOCK])
            tmp12 = _tmp11 + tmp10
            _tmp11 = tl.where(rmask & xmask, tmp12, _tmp11)
        tmp11 = tl.sum(_tmp11, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp11, xmask)


buf40: SchedulerNode(ComputedBuffer)
buf40.writes = [MemoryDep('buf40', c0, {c0: 512}, None)]
buf40.unmet_dependencies = [MemoryDep('buf39', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf40.met_dependencies = []
buf40.users = [NodeUser(node=SchedulerNode(name='buf44'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf40.group.device = cuda:0
buf40.group.iteration = (512, 13)
buf40.sizes = ([512], [13])
buf39_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf40_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf40_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf39', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf40', get_index_1, reduction)
        return store_reduction
buf40 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf41: SchedulerNode(ComputedBuffer)
buf41.writes = [MemoryDep('buf41', c0, {c0: 6656}, None)]
buf41.unmet_dependencies = [   MemoryDep('buf37', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf41.met_dependencies = 
    [   MemoryDep('convolution_15', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('relu_13', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None),
        MemoryDep('unsqueeze_130', c1, {c0: 13, c1: 512}, None)]
buf41.users = [NodeUser(node=SchedulerNode(name='buf42'), can_inplace=False, is_weak=False)]
buf41.group.device = cuda:0
buf41.group.iteration = (6656, 121)
buf41.sizes = ([13, 512], [121])
relu_13_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
convolution_15_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
unsqueeze_130_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
buf37_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf41_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
class buf41_loop_body:
    var_ranges = {z0: 13, z1: 512, z2: 121}
    index0 = 121*z0 + z2
    index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
    index2 = z1
    index3 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1568, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index3')
        store_reduction = ops.store_reduction('buf41', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('relu_13', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf37', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('convolution_15', get_index_2)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('unsqueeze_130', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        return mul
buf41 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[8192, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 6656
        rnumel = 121
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x1 = (xindex // 512)
        x0 = xindex % 512
        _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = r2 + (121*x1)
            tmp1 = tl.full([1, 1], 1568, tl.int32)
            tmp2 = tmp0 < tmp1
            tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = 0.0
            tmp5 = tmp3 <= tmp4
            tmp6 = tl.load(in_ptr1 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp7 = tl.where(tmp5, tmp4, tmp6)
            tmp8 = tl.load(in_ptr2 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp9 = tl.load(in_ptr3 + (tl.broadcast_to(x0, [XBLOCK, RBLOCK])), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
            tmp10 = tmp8 - tmp9
            tmp11 = tmp7 * tmp10
            tmp12 = tl.full(tmp11.shape, 0, tmp11.dtype)
            tmp13 = tl.where(tmp2, tmp11, tmp12)
            tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
            tmp16 = _tmp15 + tmp14
            _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
        tmp15 = tl.sum(_tmp15, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp15, xmask)


buf42: SchedulerNode(ComputedBuffer)
buf42.writes = [MemoryDep('buf42', c0, {c0: 512}, None)]
buf42.unmet_dependencies = [MemoryDep('buf41', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf42.met_dependencies = []
buf42.users = [NodeUser(node=SchedulerNode(name='buf43'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf44'), can_inplace=False, is_weak=False)]
buf42.group.device = cuda:0
buf42.group.iteration = (512, 13)
buf42.sizes = ([512], [13])
buf41_layout = FixedLayout('cuda', torch.float32, size=[512, 13], stride=[1, 512])
buf42_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf42_loop_body:
    var_ranges = {z0: 512, z1: 13}
    index0 = z0 + 512*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf41', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf42', get_index_1, reduction)
        return store_reduction
buf42 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[512, 16],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        rnumel = 13
        RBLOCK: tl.constexpr = 16
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf43: SchedulerNode(ComputedBuffer)
buf43.writes = [MemoryDep('buf43', c0, {c0: 512}, None)]
buf43.unmet_dependencies = [MemoryDep('buf42', c0, {c0: 512}, None)]
buf43.met_dependencies = [MemoryDep('squeeze_46', c0, {c0: 512}, None)]
buf43.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf43.group.device = cuda:0
buf43.group.iteration = (512, 1)
buf43.sizes = ([512], [])
buf42_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
squeeze_46_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf43_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
class buf43_loop_body:
    var_ranges = {z0: 512}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf42', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_46', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf43', get_index_2, mul, None)
        return store
buf43 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[512], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf44: SchedulerNode(ComputedBuffer)
buf44.writes = [MemoryDep('buf44', c0, {c0: 802816}, None)]
buf44.unmet_dependencies = 
    [   MemoryDep('buf37', c0, {c0: 802816}, None),
        MemoryDep('buf40', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf42', c1, {c0: 1568, c1: 512}, None)]
buf44.met_dependencies = 
    [   MemoryDep('convolution_15', c0, {c0: 802816}, None),
        MemoryDep('primals_47', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('relu_13', c0, {c0: 802816}, None),
        MemoryDep('squeeze_46', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('unsqueeze_130', c1, {c0: 1568, c1: 512}, None)]
buf44.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf45'), can_inplace=False, is_weak=False)]
buf44.group.device = cuda:0
buf44.group.iteration = (802816, 1)
buf44.sizes = ([1568, 512], [])
unsqueeze_130_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 1, 1])
buf37_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf40_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf42_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
convolution_15_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
primals_47_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
squeeze_46_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
relu_13_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf44_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf44_loop_body:
    var_ranges = {z0: 1568, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_13', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf37', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_15', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_130', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf42', get_index_4)
        constant_2 = ops.constant(0.0006377551020408163, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_46', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_46', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf40', get_index_7)
        constant_3 = ops.constant(0.0006377551020408163, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_46', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_47', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf44', get_index_10, mul_6, None)
        return store
buf44 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 512
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 0.0006377551020408163
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf45: ExternKernelSchedulerNode(FallbackKernel)
buf45.writes = [StarDep(name='buf45', mode=None)]
buf45.unmet_dependencies = [StarDep(name='buf44', mode=None)]
buf45.met_dependencies = [StarDep(name='primals_46', mode=None), StarDep(name='relu_12', mode=None)]
buf45.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf46'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf47'), can_inplace=False, is_weak=False)]
buf45.node.kernel = None


buf46: ExternKernelSchedulerNode(MultiOutput)
buf46.writes = [StarDep(name='buf46', mode=None)]
buf46.unmet_dependencies = [StarDep(name='buf45', mode=None)]
buf46.met_dependencies = []
buf46.users = [NodeUser(node=SchedulerNode(name='buf48'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf50'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf52'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf66'), can_inplace=True, is_weak=False)]
buf46.node.kernel = None


buf47: ExternKernelSchedulerNode(MultiOutput)
buf47.writes = [StarDep(name='buf47', mode=None)]
buf47.unmet_dependencies = [StarDep(name='buf45', mode=None)]
buf47.met_dependencies = []
buf47.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf47.node.kernel = None


buf48: SchedulerNode(ComputedBuffer)
buf48.writes = [MemoryDep('buf48', c0, {c0: 12544}, None)]
buf48.unmet_dependencies = 
    [   MemoryDep('buf29', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('buf46', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf48.met_dependencies = [MemoryDep('relu_12', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf48.users = [NodeUser(node=SchedulerNode(name='buf49'), can_inplace=False, is_weak=False)]
buf48.group.device = cuda:0
buf48.group.iteration = (12544, 128)
buf48.sizes = ([49, 256], [128])
buf46_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
relu_12_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf48_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf48_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_12', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf29', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf46', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_3 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf48', get_index_3, reduction)
        return store_reduction
buf48 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = tl.load(in_ptr2 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp5 = tmp3 + tmp4
            tmp6 = tl.where(tmp2, tmp1, tmp5)
            tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
            tmp9 = _tmp8 + tmp7
            _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp8 = tl.sum(_tmp8, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp8, xmask)


buf49: SchedulerNode(ComputedBuffer)
buf49.writes = [MemoryDep('buf49', c0, {c0: 256}, None)]
buf49.unmet_dependencies = [MemoryDep('buf48', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf49.met_dependencies = []
buf49.users = [NodeUser(node=SchedulerNode(name='buf52'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf49.group.device = cuda:0
buf49.group.iteration = (256, 49)
buf49.sizes = ([256], [49])
buf48_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf49_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf49_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf48', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf49', get_index_1, reduction)
        return store_reduction
buf49 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf50: SchedulerNode(ComputedBuffer)
buf50.writes = [MemoryDep('buf50', c0, {c0: 12544}, None)]
buf50.unmet_dependencies = 
    [   MemoryDep('buf29', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('buf46', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf50.met_dependencies = 
    [   MemoryDep('convolution_14', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('relu_12', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('unsqueeze_142', c1, {c0: 49, c1: 256}, None)]
buf50.users = [NodeUser(node=SchedulerNode(name='buf51'), can_inplace=False, is_weak=False)]
buf50.group.device = cuda:0
buf50.group.iteration = (12544, 128)
buf50.sizes = ([49, 256], [128])
relu_12_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf46_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
unsqueeze_142_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
convolution_14_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf50_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf50_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = z1
    index2 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_12', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf29', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf46', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('convolution_14', get_index_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('unsqueeze_142', get_index_4)
        sub = ops.sub(load_3, load_4)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_5 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf50', get_index_5, reduction)
        return store_reduction
buf50 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        tmp8 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
        _tmp12 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = tl.load(in_ptr2 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp7 = tl.load(in_ptr3 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp5 = tmp3 + tmp4
            tmp6 = tl.where(tmp2, tmp1, tmp5)
            tmp9 = tmp7 - tmp8
            tmp10 = tmp6 * tmp9
            tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
            tmp13 = _tmp12 + tmp11
            _tmp12 = tl.where(rmask & xmask, tmp13, _tmp12)
        tmp12 = tl.sum(_tmp12, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp12, xmask)


buf51: SchedulerNode(ComputedBuffer)
buf51.writes = [MemoryDep('buf51', c0, {c0: 256}, None)]
buf51.unmet_dependencies = [MemoryDep('buf50', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf51.met_dependencies = []
buf51.users = [NodeUser(node=SchedulerNode(name='buf52'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf53'), can_inplace=True, is_weak=False)]
buf51.group.device = cuda:0
buf51.group.iteration = (256, 49)
buf51.sizes = ([256], [49])
buf50_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf51_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf51_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf50', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf51', get_index_1, reduction)
        return store_reduction
buf51 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf52: SchedulerNode(ComputedBuffer)
buf52.writes = [MemoryDep('buf52', c0, {c0: 1605632}, None)]
buf52.unmet_dependencies = 
    [   MemoryDep('buf29', c0, {c0: 1605632}, None),
        MemoryDep('buf46', c0, {c0: 1605632}, None),
        MemoryDep('buf49', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf51', c1, {c0: 6272, c1: 256}, None)]
buf52.met_dependencies = 
    [   MemoryDep('convolution_14', c0, {c0: 1605632}, None),
        MemoryDep('primals_44', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('relu_12', c0, {c0: 1605632}, None),
        MemoryDep('squeeze_43', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('unsqueeze_142', c1, {c0: 6272, c1: 256}, None)]
buf52.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf54'), can_inplace=False, is_weak=False)]
buf52.group.device = cuda:0
buf52.group.iteration = (1605632, 1)
buf52.sizes = ([6272, 256], [])
buf51_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
unsqueeze_142_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
squeeze_43_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
convolution_14_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf46_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
relu_12_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf49_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
primals_44_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf52_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf52_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_12', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf29', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf46', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('convolution_14', get_index_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('unsqueeze_142', get_index_4)
        sub = ops.sub(load_3, load_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('buf51', get_index_5)
        constant_2 = ops.constant(0.00015943877551020407, torch.float32)
        mul = ops.mul(load_5, constant_2)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_43', get_index_6)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_43', get_index_7)
        mul_1 = ops.mul(load_6, load_7)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('buf49', get_index_8)
        constant_3 = ops.constant(0.00015943877551020407, torch.float32)
        mul_4 = ops.mul(load_8, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('squeeze_43', get_index_9)
        get_index_10 = self.get_index('index1')
        load_10 = ops.load('primals_44', get_index_10)
        mul_5 = ops.mul(load_9, load_10)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf52', get_index_11, mul_6, None)
        return store
buf52 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp4 = tl.load(in_ptr2 + (x2), None)
        tmp7 = tl.load(in_ptr3 + (x2), None)
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp13 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp18 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp21 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp9 = tmp7 - tmp8
        tmp11 = 0.00015943877551020407
        tmp12 = tmp10 * tmp11
        tmp14 = tmp13 * tmp13
        tmp15 = tmp12 * tmp14
        tmp16 = tmp9 * tmp15
        tmp17 = tmp6 - tmp16
        tmp19 = tmp18 * tmp11
        tmp20 = tmp17 - tmp19
        tmp22 = tmp13 * tmp21
        tmp23 = tmp20 * tmp22
        tl.store(out_ptr0 + (x2), tmp23, None)


buf53: SchedulerNode(ComputedBuffer)
buf53.writes = [MemoryDep('buf53', c0, {c0: 256}, None)]
buf53.unmet_dependencies = [MemoryDep('buf51', c0, {c0: 256}, None)]
buf53.met_dependencies = [MemoryDep('squeeze_43', c0, {c0: 256}, None)]
buf53.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf53.group.device = cuda:0
buf53.group.iteration = (256, 1)
buf53.sizes = ([256], [])
squeeze_43_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf51_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf53_loop_body:
    var_ranges = {z0: 256}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf51', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_43', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf53', get_index_2, mul, None)
        return store
buf53 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[256], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf54: ExternKernelSchedulerNode(FallbackKernel)
buf54.writes = [StarDep(name='buf54', mode=None)]
buf54.unmet_dependencies = [StarDep(name='buf52', mode=None)]
buf54.met_dependencies = [StarDep(name='primals_43', mode=None), StarDep(name='relu_11', mode=None)]
buf54.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf55'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf56'), can_inplace=False, is_weak=False)]
buf54.node.kernel = None


buf55: ExternKernelSchedulerNode(MultiOutput)
buf55.writes = [StarDep(name='buf55', mode=None)]
buf55.unmet_dependencies = [StarDep(name='buf54', mode=None)]
buf55.met_dependencies = []
buf55.users = [NodeUser(node=SchedulerNode(name='buf57'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf59'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf62'), can_inplace=True, is_weak=False)]
buf55.node.kernel = None


buf56: ExternKernelSchedulerNode(MultiOutput)
buf56.writes = [StarDep(name='buf56', mode=None)]
buf56.unmet_dependencies = [StarDep(name='buf54', mode=None)]
buf56.met_dependencies = []
buf56.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf56.node.kernel = None


buf57: SchedulerNode(ComputedBuffer)
buf57.writes = [MemoryDep('buf57', c0, {c0: 12544}, None)]
buf57.unmet_dependencies = [MemoryDep('buf55', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf57.met_dependencies = [MemoryDep('relu_11', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf57.users = [NodeUser(node=SchedulerNode(name='buf58'), can_inplace=False, is_weak=False)]
buf57.group.device = cuda:0
buf57.group.iteration = (12544, 128)
buf57.sizes = ([49, 256], [128])
relu_11_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf55_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf57_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf57_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_11', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf55', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_2 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf57', get_index_2, reduction)
        return store_reduction
buf57 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf58: SchedulerNode(ComputedBuffer)
buf58.writes = [MemoryDep('buf58', c0, {c0: 256}, None)]
buf58.unmet_dependencies = [MemoryDep('buf57', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf58.met_dependencies = []
buf58.users = [NodeUser(node=SchedulerNode(name='buf62'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf58.group.device = cuda:0
buf58.group.iteration = (256, 49)
buf58.sizes = ([256], [49])
buf57_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf58_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf58_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf57', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf58', get_index_1, reduction)
        return store_reduction
buf58 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf59: SchedulerNode(ComputedBuffer)
buf59.writes = [MemoryDep('buf59', c0, {c0: 12544}, None)]
buf59.unmet_dependencies = [MemoryDep('buf55', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf59.met_dependencies = 
    [   MemoryDep('convolution_13', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('relu_11', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('unsqueeze_154', c1, {c0: 49, c1: 256}, None)]
buf59.users = [NodeUser(node=SchedulerNode(name='buf60'), can_inplace=False, is_weak=False)]
buf59.group.device = cuda:0
buf59.group.iteration = (12544, 128)
buf59.sizes = ([49, 256], [128])
relu_11_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
convolution_13_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf55_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
unsqueeze_154_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
buf59_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf59_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = z1
    index2 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_11', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf55', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_13', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_154', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_4 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf59', get_index_4, reduction)
        return store_reduction
buf59 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        tmp6 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
        _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp5 = tl.load(in_ptr2 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp7 = tmp5 - tmp6
            tmp8 = tmp4 * tmp7
            tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
            tmp11 = _tmp10 + tmp9
            _tmp10 = tl.where(rmask & xmask, tmp11, _tmp10)
        tmp10 = tl.sum(_tmp10, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp10, xmask)


buf60: SchedulerNode(ComputedBuffer)
buf60.writes = [MemoryDep('buf60', c0, {c0: 256}, None)]
buf60.unmet_dependencies = [MemoryDep('buf59', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf60.met_dependencies = []
buf60.users = [NodeUser(node=SchedulerNode(name='buf61'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf62'), can_inplace=False, is_weak=False)]
buf60.group.device = cuda:0
buf60.group.iteration = (256, 49)
buf60.sizes = ([256], [49])
buf59_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf60_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf60_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf59', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf60', get_index_1, reduction)
        return store_reduction
buf60 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf61: SchedulerNode(ComputedBuffer)
buf61.writes = [MemoryDep('buf61', c0, {c0: 256}, None)]
buf61.unmet_dependencies = [MemoryDep('buf60', c0, {c0: 256}, None)]
buf61.met_dependencies = [MemoryDep('squeeze_40', c0, {c0: 256}, None)]
buf61.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf61.group.device = cuda:0
buf61.group.iteration = (256, 1)
buf61.sizes = ([256], [])
squeeze_40_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf61_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf61_loop_body:
    var_ranges = {z0: 256}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf60', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_40', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf61', get_index_2, mul, None)
        return store
buf61 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[256], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf62: SchedulerNode(ComputedBuffer)
buf62.writes = [MemoryDep('buf62', c0, {c0: 1605632}, None)]
buf62.unmet_dependencies = 
    [   MemoryDep('buf55', c0, {c0: 1605632}, None),
        MemoryDep('buf58', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf60', c1, {c0: 6272, c1: 256}, None)]
buf62.met_dependencies = 
    [   MemoryDep('convolution_13', c0, {c0: 1605632}, None),
        MemoryDep('primals_41', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('relu_11', c0, {c0: 1605632}, None),
        MemoryDep('squeeze_40', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('unsqueeze_154', c1, {c0: 6272, c1: 256}, None)]
buf62.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf63'), can_inplace=False, is_weak=False)]
buf62.group.device = cuda:0
buf62.group.iteration = (1605632, 1)
buf62.sizes = ([6272, 256], [])
relu_11_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf60_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
primals_41_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
convolution_13_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf55_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
unsqueeze_154_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
squeeze_40_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf58_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf62_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf62_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_11', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf55', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_13', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_154', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf60', get_index_4)
        constant_2 = ops.constant(0.00015943877551020407, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_40', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_40', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf58', get_index_7)
        constant_3 = ops.constant(0.00015943877551020407, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_40', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_41', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf62', get_index_10, mul_6, None)
        return store
buf62 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 0.00015943877551020407
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf63: ExternKernelSchedulerNode(FallbackKernel)
buf63.writes = [StarDep(name='buf63', mode=None)]
buf63.unmet_dependencies = [StarDep(name='buf62', mode=None)]
buf63.met_dependencies = [StarDep(name='primals_40', mode=None), StarDep(name='relu_10', mode=None)]
buf63.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf64'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf65'), can_inplace=False, is_weak=False)]
buf63.node.kernel = None


buf64: ExternKernelSchedulerNode(MultiOutput)
buf64.writes = [StarDep(name='buf64', mode=None)]
buf64.unmet_dependencies = [StarDep(name='buf63', mode=None)]
buf64.met_dependencies = []
buf64.users = [NodeUser(node=SchedulerNode(name='buf66'), can_inplace=True, is_weak=False)]
buf64.node.kernel = None


buf65: ExternKernelSchedulerNode(MultiOutput)
buf65.writes = [StarDep(name='buf65', mode=None)]
buf65.unmet_dependencies = [StarDep(name='buf63', mode=None)]
buf65.met_dependencies = []
buf65.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf65.node.kernel = None


buf66: SchedulerNode(ComputedBuffer)
buf66.writes = [MemoryDep('buf66', c0, {c0: 1605632}, None)]
buf66.unmet_dependencies = 
    [   MemoryDep('buf29', c0, {c0: 1605632}, None),
        MemoryDep('buf46', c0, {c0: 1605632}, None),
        MemoryDep('buf64', c0, {c0: 1605632}, None)]
buf66.met_dependencies = 
    [   MemoryDep('relu_10', c0, {c0: 1605632}, None),
        MemoryDep('relu_12', c0, {c0: 1605632}, None)]
buf66.users = [NodeUser(node=SchedulerNode(name='buf67'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf69'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf72'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf76'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf79'), can_inplace=True, is_weak=False)]
buf66.group.device = cuda:0
buf66.group.iteration = (1605632, 1)
buf66.sizes = ([1605632], [])
buf46_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
relu_12_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
relu_10_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf64_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf66_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf66_loop_body:
    var_ranges = {z0: 1605632}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_10', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('relu_12', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        le_1 = ops.le(load_1, constant_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf29', get_index_2)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('buf46', get_index_3)
        add = ops.add(load_2, load_3)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(le_1, constant_2, add)
        get_index_4 = self.get_index('index0')
        load_4 = ops.load('buf64', get_index_4)
        add_1 = ops.add(where, load_4)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf66', get_index_5, where_1, None)
        return store
buf66 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), None)
        tmp3 = tl.load(in_ptr1 + (x0), None)
        tmp5 = tl.load(in_ptr2 + (x0), None)
        tmp6 = tl.load(in_ptr3 + (x0), None)
        tmp9 = tl.load(in_out_ptr0 + (x0), None)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tmp3 <= tmp1
        tmp7 = tmp5 + tmp6
        tmp8 = tl.where(tmp4, tmp1, tmp7)
        tmp10 = tmp8 + tmp9
        tmp11 = tl.where(tmp2, tmp1, tmp10)
        tl.store(in_out_ptr0 + (x0), tmp11, None)


buf67: SchedulerNode(ComputedBuffer)
buf67.writes = [MemoryDep('buf67', c0, {c0: 12544}, None)]
buf67.unmet_dependencies = [MemoryDep('buf66', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf67.met_dependencies = []
buf67.users = [NodeUser(node=SchedulerNode(name='buf68'), can_inplace=False, is_weak=False)]
buf67.group.device = cuda:0
buf67.group.iteration = (12544, 128)
buf67.sizes = ([49, 256], [128])
buf66_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf67_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf67_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf66', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf67', get_index_1, reduction)
        return store_reduction
buf67 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp2, xmask)


buf68: SchedulerNode(ComputedBuffer)
buf68.writes = [MemoryDep('buf68', c0, {c0: 256}, None)]
buf68.unmet_dependencies = [MemoryDep('buf67', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf68.met_dependencies = []
buf68.users = [NodeUser(node=SchedulerNode(name='buf72'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf79'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf68.group.device = cuda:0
buf68.group.iteration = (256, 49)
buf68.sizes = ([256], [49])
buf67_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf68_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf68_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf67', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf68', get_index_1, reduction)
        return store_reduction
buf68 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf69: SchedulerNode(ComputedBuffer)
buf69.writes = [MemoryDep('buf69', c0, {c0: 12544}, None)]
buf69.unmet_dependencies = [MemoryDep('buf66', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf69.met_dependencies = 
    [   MemoryDep('convolution_12', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('unsqueeze_166', c1, {c0: 49, c1: 256}, None)]
buf69.users = [NodeUser(node=SchedulerNode(name='buf70'), can_inplace=False, is_weak=False)]
buf69.group.device = cuda:0
buf69.group.iteration = (12544, 128)
buf69.sizes = ([49, 256], [128])
buf66_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
unsqueeze_166_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
convolution_12_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf69_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf69_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = z1
    index2 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf66', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_12', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_166', get_index_2)
        sub = ops.sub(load_1, load_2)
        mul = ops.mul(load, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf69', get_index_3, reduction)
        return store_reduction
buf69 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        tmp2 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tmp1 - tmp2
            tmp4 = tmp0 * tmp3
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf70: SchedulerNode(ComputedBuffer)
buf70.writes = [MemoryDep('buf70', c0, {c0: 256}, None)]
buf70.unmet_dependencies = [MemoryDep('buf69', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf70.met_dependencies = []
buf70.users = [NodeUser(node=SchedulerNode(name='buf71'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf72'), can_inplace=False, is_weak=False)]
buf70.group.device = cuda:0
buf70.group.iteration = (256, 49)
buf70.sizes = ([256], [49])
buf69_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf70_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf70_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf69', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf70', get_index_1, reduction)
        return store_reduction
buf70 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf71: SchedulerNode(ComputedBuffer)
buf71.writes = [MemoryDep('buf71', c0, {c0: 256}, None)]
buf71.unmet_dependencies = [MemoryDep('buf70', c0, {c0: 256}, None)]
buf71.met_dependencies = [MemoryDep('squeeze_37', c0, {c0: 256}, None)]
buf71.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf71.group.device = cuda:0
buf71.group.iteration = (256, 1)
buf71.sizes = ([256], [])
buf70_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
squeeze_37_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf71_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf71_loop_body:
    var_ranges = {z0: 256}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf70', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_37', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf71', get_index_2, mul, None)
        return store
buf71 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[256], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf72: SchedulerNode(ComputedBuffer)
buf72.writes = [MemoryDep('buf72', c0, {c0: 1605632}, None)]
buf72.unmet_dependencies = 
    [   MemoryDep('buf66', c0, {c0: 1605632}, None),
        MemoryDep('buf68', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf70', c1, {c0: 6272, c1: 256}, None)]
buf72.met_dependencies = 
    [   MemoryDep('convolution_12', c0, {c0: 1605632}, None),
        MemoryDep('primals_38', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('squeeze_37', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('unsqueeze_166', c1, {c0: 6272, c1: 256}, None)]
buf72.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf73'), can_inplace=False, is_weak=False)]
buf72.group.device = cuda:0
buf72.group.iteration = (1605632, 1)
buf72.sizes = ([6272, 256], [])
buf66_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf70_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
primals_38_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
squeeze_37_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf68_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
unsqueeze_166_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
convolution_12_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf72_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf72_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf66', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_12', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_166', get_index_2)
        sub = ops.sub(load_1, load_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf70', get_index_3)
        constant = ops.constant(0.00015943877551020407, torch.float32)
        mul = ops.mul(load_3, constant)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('squeeze_37', get_index_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_37', get_index_5)
        mul_1 = ops.mul(load_4, load_5)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(load, mul_3)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('buf68', get_index_6)
        constant_1 = ops.constant(0.00015943877551020407, torch.float32)
        mul_4 = ops.mul(load_6, constant_1)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_37', get_index_7)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('primals_38', get_index_8)
        mul_5 = ops.mul(load_7, load_8)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_9 = self.get_index('index0')
        store = ops.store('buf72', get_index_9, mul_6, None)
        return store
buf72 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x2), None)
        tmp2 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp4 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp7 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp3 = tmp1 - tmp2
        tmp5 = 0.00015943877551020407
        tmp6 = tmp4 * tmp5
        tmp8 = tmp7 * tmp7
        tmp9 = tmp6 * tmp8
        tmp10 = tmp3 * tmp9
        tmp11 = tmp0 - tmp10
        tmp13 = tmp12 * tmp5
        tmp14 = tmp11 - tmp13
        tmp16 = tmp7 * tmp15
        tmp17 = tmp14 * tmp16
        tl.store(out_ptr0 + (x2), tmp17, None)


buf73: ExternKernelSchedulerNode(FallbackKernel)
buf73.writes = [StarDep(name='buf73', mode=None)]
buf73.unmet_dependencies = [StarDep(name='buf72', mode=None)]
buf73.met_dependencies = [StarDep(name='primals_37', mode=None), StarDep(name='relu_8', mode=None)]
buf73.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf74'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf75'), can_inplace=False, is_weak=False)]
buf73.node.kernel = None


buf74: ExternKernelSchedulerNode(MultiOutput)
buf74.writes = [StarDep(name='buf74', mode=None)]
buf74.unmet_dependencies = [StarDep(name='buf73', mode=None)]
buf74.met_dependencies = []
buf74.users = [NodeUser(node=SchedulerNode(name='buf92'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf94'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf96'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf110'), can_inplace=True, is_weak=False)]
buf74.node.kernel = None


buf75: ExternKernelSchedulerNode(MultiOutput)
buf75.writes = [StarDep(name='buf75', mode=None)]
buf75.unmet_dependencies = [StarDep(name='buf73', mode=None)]
buf75.met_dependencies = []
buf75.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf75.node.kernel = None


buf76: SchedulerNode(ComputedBuffer)
buf76.writes = [MemoryDep('buf76', c0, {c0: 12544}, None)]
buf76.unmet_dependencies = [MemoryDep('buf66', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf76.met_dependencies = 
    [   MemoryDep('convolution_11', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('unsqueeze_178', c1, {c0: 49, c1: 256}, None)]
buf76.users = [NodeUser(node=SchedulerNode(name='buf77'), can_inplace=False, is_weak=False)]
buf76.group.device = cuda:0
buf76.group.iteration = (12544, 128)
buf76.sizes = ([49, 256], [128])
unsqueeze_178_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
buf66_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
convolution_11_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf76_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf76_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = z1
    index2 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf66', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_11', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_178', get_index_2)
        sub = ops.sub(load_1, load_2)
        mul = ops.mul(load, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf76', get_index_3, reduction)
        return store_reduction
buf76 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        tmp2 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tmp1 - tmp2
            tmp4 = tmp0 * tmp3
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf77: SchedulerNode(ComputedBuffer)
buf77.writes = [MemoryDep('buf77', c0, {c0: 256}, None)]
buf77.unmet_dependencies = [MemoryDep('buf76', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf77.met_dependencies = []
buf77.users = [NodeUser(node=SchedulerNode(name='buf78'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf79'), can_inplace=False, is_weak=False)]
buf77.group.device = cuda:0
buf77.group.iteration = (256, 49)
buf77.sizes = ([256], [49])
buf76_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf77_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf77_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf76', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf77', get_index_1, reduction)
        return store_reduction
buf77 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf78: SchedulerNode(ComputedBuffer)
buf78.writes = [MemoryDep('buf78', c0, {c0: 256}, None)]
buf78.unmet_dependencies = [MemoryDep('buf77', c0, {c0: 256}, None)]
buf78.met_dependencies = [MemoryDep('squeeze_34', c0, {c0: 256}, None)]
buf78.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf78.group.device = cuda:0
buf78.group.iteration = (256, 1)
buf78.sizes = ([256], [])
squeeze_34_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf77_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf78_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf78_loop_body:
    var_ranges = {z0: 256}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf77', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_34', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf78', get_index_2, mul, None)
        return store
buf78 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[256], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf79: SchedulerNode(ComputedBuffer)
buf79.writes = [MemoryDep('buf79', c0, {c0: 1605632}, None)]
buf79.unmet_dependencies = 
    [   MemoryDep('buf66', c0, {c0: 1605632}, None),
        MemoryDep('buf68', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf77', c1, {c0: 6272, c1: 256}, None)]
buf79.met_dependencies = 
    [   MemoryDep('convolution_11', c0, {c0: 1605632}, None),
        MemoryDep('primals_35', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('squeeze_34', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('unsqueeze_178', c1, {c0: 6272, c1: 256}, None)]
buf79.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf80'), can_inplace=False, is_weak=False)]
buf79.group.device = cuda:0
buf79.group.iteration = (1605632, 1)
buf79.sizes = ([6272, 256], [])
buf66_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
primals_35_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf77_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
unsqueeze_178_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
convolution_11_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
squeeze_34_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf68_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf79_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf79_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf66', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_11', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_178', get_index_2)
        sub = ops.sub(load_1, load_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf77', get_index_3)
        constant = ops.constant(0.00015943877551020407, torch.float32)
        mul = ops.mul(load_3, constant)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('squeeze_34', get_index_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_34', get_index_5)
        mul_1 = ops.mul(load_4, load_5)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(load, mul_3)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('buf68', get_index_6)
        constant_1 = ops.constant(0.00015943877551020407, torch.float32)
        mul_4 = ops.mul(load_6, constant_1)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_34', get_index_7)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('primals_35', get_index_8)
        mul_5 = ops.mul(load_7, load_8)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_9 = self.get_index('index0')
        store = ops.store('buf79', get_index_9, mul_6, None)
        return store
buf79 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x2), None)
        tmp2 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp4 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp7 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp3 = tmp1 - tmp2
        tmp5 = 0.00015943877551020407
        tmp6 = tmp4 * tmp5
        tmp8 = tmp7 * tmp7
        tmp9 = tmp6 * tmp8
        tmp10 = tmp3 * tmp9
        tmp11 = tmp0 - tmp10
        tmp13 = tmp12 * tmp5
        tmp14 = tmp11 - tmp13
        tmp16 = tmp7 * tmp15
        tmp17 = tmp14 * tmp16
        tl.store(out_ptr0 + (x2), tmp17, None)


buf80: ExternKernelSchedulerNode(FallbackKernel)
buf80.writes = [StarDep(name='buf80', mode=None)]
buf80.unmet_dependencies = [StarDep(name='buf79', mode=None)]
buf80.met_dependencies = [StarDep(name='primals_34', mode=None), StarDep(name='relu_9', mode=None)]
buf80.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf81'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf82'), can_inplace=False, is_weak=False)]
buf80.node.kernel = None


buf81: ExternKernelSchedulerNode(MultiOutput)
buf81.writes = [StarDep(name='buf81', mode=None)]
buf81.unmet_dependencies = [StarDep(name='buf80', mode=None)]
buf81.met_dependencies = []
buf81.users = [NodeUser(node=SchedulerNode(name='buf83'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf85'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf88'), can_inplace=True, is_weak=False)]
buf81.node.kernel = None


buf82: ExternKernelSchedulerNode(MultiOutput)
buf82.writes = [StarDep(name='buf82', mode=None)]
buf82.unmet_dependencies = [StarDep(name='buf80', mode=None)]
buf82.met_dependencies = []
buf82.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf82.node.kernel = None


buf83: SchedulerNode(ComputedBuffer)
buf83.writes = [MemoryDep('buf83', c0, {c0: 12544}, None)]
buf83.unmet_dependencies = [MemoryDep('buf81', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf83.met_dependencies = [MemoryDep('relu_9', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf83.users = [NodeUser(node=SchedulerNode(name='buf84'), can_inplace=False, is_weak=False)]
buf83.group.device = cuda:0
buf83.group.iteration = (12544, 128)
buf83.sizes = ([49, 256], [128])
relu_9_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf81_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf83_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf83_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_9', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf81', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_2 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf83', get_index_2, reduction)
        return store_reduction
buf83 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf84: SchedulerNode(ComputedBuffer)
buf84.writes = [MemoryDep('buf84', c0, {c0: 256}, None)]
buf84.unmet_dependencies = [MemoryDep('buf83', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf84.met_dependencies = []
buf84.users = [NodeUser(node=SchedulerNode(name='buf88'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf84.group.device = cuda:0
buf84.group.iteration = (256, 49)
buf84.sizes = ([256], [49])
buf83_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf84_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf84_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf83', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf84', get_index_1, reduction)
        return store_reduction
buf84 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf85: SchedulerNode(ComputedBuffer)
buf85.writes = [MemoryDep('buf85', c0, {c0: 12544}, None)]
buf85.unmet_dependencies = [MemoryDep('buf81', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf85.met_dependencies = 
    [   MemoryDep('convolution_10', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('relu_9', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None),
        MemoryDep('unsqueeze_190', c1, {c0: 49, c1: 256}, None)]
buf85.users = [NodeUser(node=SchedulerNode(name='buf86'), can_inplace=False, is_weak=False)]
buf85.group.device = cuda:0
buf85.group.iteration = (12544, 128)
buf85.sizes = ([49, 256], [128])
relu_9_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf81_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
unsqueeze_190_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
convolution_10_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf85_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
class buf85_loop_body:
    var_ranges = {z0: 49, z1: 256, z2: 128}
    index0 = 32768*z0 + z1 + 256*z2
    index1 = z1
    index2 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_9', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf81', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_10', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_190', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_4 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf85', get_index_4, reduction)
        return store_reduction
buf85 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[16384, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 12544
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 256
        x1 = (xindex // 256)
        tmp6 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
        _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp5 = tl.load(in_ptr2 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp7 = tmp5 - tmp6
            tmp8 = tmp4 * tmp7
            tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
            tmp11 = _tmp10 + tmp9
            _tmp10 = tl.where(rmask & xmask, tmp11, _tmp10)
        tmp10 = tl.sum(_tmp10, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp10, xmask)


buf86: SchedulerNode(ComputedBuffer)
buf86.writes = [MemoryDep('buf86', c0, {c0: 256}, None)]
buf86.unmet_dependencies = [MemoryDep('buf85', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf86.met_dependencies = []
buf86.users = [NodeUser(node=SchedulerNode(name='buf87'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf88'), can_inplace=False, is_weak=False)]
buf86.group.device = cuda:0
buf86.group.iteration = (256, 49)
buf86.sizes = ([256], [49])
buf85_layout = FixedLayout('cuda', torch.float32, size=[256, 49], stride=[1, 256])
buf86_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf86_loop_body:
    var_ranges = {z0: 256, z1: 49}
    index0 = z0 + 256*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf85', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf86', get_index_1, reduction)
        return store_reduction
buf86 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[256, 64],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        rnumel = 49
        RBLOCK: tl.constexpr = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rindex = tl.arange(0, RBLOCK)[None, :]
        roffset = 0
        rmask = rindex < rnumel
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = tl.where(rmask & xmask, tmp1, 0)
        tmp4 = tl.sum(tmp3, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp4, xmask)


buf87: SchedulerNode(ComputedBuffer)
buf87.writes = [MemoryDep('buf87', c0, {c0: 256}, None)]
buf87.unmet_dependencies = [MemoryDep('buf86', c0, {c0: 256}, None)]
buf87.met_dependencies = [MemoryDep('squeeze_31', c0, {c0: 256}, None)]
buf87.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf87.group.device = cuda:0
buf87.group.iteration = (256, 1)
buf87.sizes = ([256], [])
squeeze_31_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf86_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf87_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
class buf87_loop_body:
    var_ranges = {z0: 256}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf86', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_31', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf87', get_index_2, mul, None)
        return store
buf87 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[256], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 256
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf88: SchedulerNode(ComputedBuffer)
buf88.writes = [MemoryDep('buf88', c0, {c0: 1605632}, None)]
buf88.unmet_dependencies = 
    [   MemoryDep('buf81', c0, {c0: 1605632}, None),
        MemoryDep('buf84', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf86', c1, {c0: 6272, c1: 256}, None)]
buf88.met_dependencies = 
    [   MemoryDep('convolution_10', c0, {c0: 1605632}, None),
        MemoryDep('primals_32', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('relu_9', c0, {c0: 1605632}, None),
        MemoryDep('squeeze_31', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('unsqueeze_190', c1, {c0: 6272, c1: 256}, None)]
buf88.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf89'), can_inplace=False, is_weak=False)]
buf88.group.device = cuda:0
buf88.group.iteration = (1605632, 1)
buf88.sizes = ([6272, 256], [])
unsqueeze_190_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 1, 1])
squeeze_31_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
relu_9_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
primals_32_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf86_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf81_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
convolution_10_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf84_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf88_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf88_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_9', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf81', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_10', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_190', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf86', get_index_4)
        constant_2 = ops.constant(0.00015943877551020407, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_31', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_31', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf84', get_index_7)
        constant_3 = ops.constant(0.00015943877551020407, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_31', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_32', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf88', get_index_10, mul_6, None)
        return store
buf88 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 0.00015943877551020407
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf89: ExternKernelSchedulerNode(FallbackKernel)
buf89.writes = [StarDep(name='buf89', mode=None)]
buf89.unmet_dependencies = [StarDep(name='buf88', mode=None)]
buf89.met_dependencies = [StarDep(name='primals_31', mode=None), StarDep(name='relu_8', mode=None)]
buf89.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf90'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf91'), can_inplace=False, is_weak=False)]
buf89.node.kernel = None


buf90: ExternKernelSchedulerNode(MultiOutput)
buf90.writes = [StarDep(name='buf90', mode=None)]
buf90.unmet_dependencies = [StarDep(name='buf89', mode=None)]
buf90.met_dependencies = []
buf90.users = [NodeUser(node=SchedulerNode(name='buf92'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf94'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf96'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf110'), can_inplace=True, is_weak=False)]
buf90.node.kernel = None


buf91: ExternKernelSchedulerNode(MultiOutput)
buf91.writes = [StarDep(name='buf91', mode=None)]
buf91.unmet_dependencies = [StarDep(name='buf89', mode=None)]
buf91.met_dependencies = []
buf91.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf91.node.kernel = None


buf92: SchedulerNode(ComputedBuffer)
buf92.writes = [MemoryDep('buf92', c0, {c0: 25088}, None)]
buf92.unmet_dependencies = 
    [   MemoryDep('buf74', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('buf90', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf92.met_dependencies = [MemoryDep('relu_8', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf92.users = [NodeUser(node=SchedulerNode(name='buf93'), can_inplace=False, is_weak=False)]
buf92.group.device = cuda:0
buf92.group.iteration = (25088, 128)
buf92.sizes = ([196, 128], [128])
relu_8_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf90_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf74_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf92_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf92_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_8', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf74', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf90', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_3 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf92', get_index_3, reduction)
        return store_reduction
buf92 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = tl.load(in_ptr2 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp5 = tmp3 + tmp4
            tmp6 = tl.where(tmp2, tmp1, tmp5)
            tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
            tmp9 = _tmp8 + tmp7
            _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp8 = tl.sum(_tmp8, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp8, xmask)


buf93: SchedulerNode(ComputedBuffer)
buf93.writes = [MemoryDep('buf93', c0, {c0: 128}, None)]
buf93.unmet_dependencies = [MemoryDep('buf92', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf93.met_dependencies = []
buf93.users = [NodeUser(node=SchedulerNode(name='buf96'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf93.group.device = cuda:0
buf93.group.iteration = (128, 196)
buf93.sizes = ([128], [196])
buf92_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf93_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf93_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf92', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf93', get_index_1, reduction)
        return store_reduction
buf93 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf94: SchedulerNode(ComputedBuffer)
buf94.writes = [MemoryDep('buf94', c0, {c0: 25088}, None)]
buf94.unmet_dependencies = 
    [   MemoryDep('buf74', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('buf90', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf94.met_dependencies = 
    [   MemoryDep('convolution_9', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('relu_8', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('unsqueeze_202', c1, {c0: 196, c1: 128}, None)]
buf94.users = [NodeUser(node=SchedulerNode(name='buf95'), can_inplace=False, is_weak=False)]
buf94.group.device = cuda:0
buf94.group.iteration = (25088, 128)
buf94.sizes = ([196, 128], [128])
relu_8_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf90_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
convolution_9_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf74_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
unsqueeze_202_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
buf94_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf94_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = z1
    index2 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_8', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf74', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf90', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('convolution_9', get_index_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('unsqueeze_202', get_index_4)
        sub = ops.sub(load_3, load_4)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_5 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf94', get_index_5, reduction)
        return store_reduction
buf94 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        tmp8 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
        _tmp12 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp4 = tl.load(in_ptr2 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp7 = tl.load(in_ptr3 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp5 = tmp3 + tmp4
            tmp6 = tl.where(tmp2, tmp1, tmp5)
            tmp9 = tmp7 - tmp8
            tmp10 = tmp6 * tmp9
            tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
            tmp13 = _tmp12 + tmp11
            _tmp12 = tl.where(rmask & xmask, tmp13, _tmp12)
        tmp12 = tl.sum(_tmp12, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp12, xmask)


buf95: SchedulerNode(ComputedBuffer)
buf95.writes = [MemoryDep('buf95', c0, {c0: 128}, None)]
buf95.unmet_dependencies = [MemoryDep('buf94', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf95.met_dependencies = []
buf95.users = [NodeUser(node=SchedulerNode(name='buf96'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf97'), can_inplace=True, is_weak=False)]
buf95.group.device = cuda:0
buf95.group.iteration = (128, 196)
buf95.sizes = ([128], [196])
buf94_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf95_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf95_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf94', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf95', get_index_1, reduction)
        return store_reduction
buf95 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf96: SchedulerNode(ComputedBuffer)
buf96.writes = [MemoryDep('buf96', c0, {c0: 3211264}, None)]
buf96.unmet_dependencies = 
    [   MemoryDep('buf74', c0, {c0: 3211264}, None),
        MemoryDep('buf90', c0, {c0: 3211264}, None),
        MemoryDep('buf93', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf95', c1, {c0: 25088, c1: 128}, None)]
buf96.met_dependencies = 
    [   MemoryDep('convolution_9', c0, {c0: 3211264}, None),
        MemoryDep('primals_29', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('relu_8', c0, {c0: 3211264}, None),
        MemoryDep('squeeze_28', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('unsqueeze_202', c1, {c0: 25088, c1: 128}, None)]
buf96.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf98'), can_inplace=False, is_weak=False)]
buf96.group.device = cuda:0
buf96.group.iteration = (3211264, 1)
buf96.sizes = ([25088, 128], [])
primals_29_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
relu_8_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
unsqueeze_202_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
buf93_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf90_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf74_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf95_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
convolution_9_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
squeeze_28_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf96_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf96_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_8', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf74', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf90', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('convolution_9', get_index_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('unsqueeze_202', get_index_4)
        sub = ops.sub(load_3, load_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('buf95', get_index_5)
        constant_2 = ops.constant(3.985969387755102e-05, torch.float32)
        mul = ops.mul(load_5, constant_2)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_28', get_index_6)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_28', get_index_7)
        mul_1 = ops.mul(load_6, load_7)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('buf93', get_index_8)
        constant_3 = ops.constant(3.985969387755102e-05, torch.float32)
        mul_4 = ops.mul(load_8, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('squeeze_28', get_index_9)
        get_index_10 = self.get_index('index1')
        load_10 = ops.load('primals_29', get_index_10)
        mul_5 = ops.mul(load_9, load_10)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf96', get_index_11, mul_6, None)
        return store
buf96 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp4 = tl.load(in_ptr2 + (x2), None)
        tmp7 = tl.load(in_ptr3 + (x2), None)
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp13 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp18 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp21 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp9 = tmp7 - tmp8
        tmp11 = 3.985969387755102e-05
        tmp12 = tmp10 * tmp11
        tmp14 = tmp13 * tmp13
        tmp15 = tmp12 * tmp14
        tmp16 = tmp9 * tmp15
        tmp17 = tmp6 - tmp16
        tmp19 = tmp18 * tmp11
        tmp20 = tmp17 - tmp19
        tmp22 = tmp13 * tmp21
        tmp23 = tmp20 * tmp22
        tl.store(out_ptr0 + (x2), tmp23, None)


buf97: SchedulerNode(ComputedBuffer)
buf97.writes = [MemoryDep('buf97', c0, {c0: 128}, None)]
buf97.unmet_dependencies = [MemoryDep('buf95', c0, {c0: 128}, None)]
buf97.met_dependencies = [MemoryDep('squeeze_28', c0, {c0: 128}, None)]
buf97.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf97.group.device = cuda:0
buf97.group.iteration = (128, 1)
buf97.sizes = ([128], [])
buf95_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
squeeze_28_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf97_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf97_loop_body:
    var_ranges = {z0: 128}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf95', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_28', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf97', get_index_2, mul, None)
        return store
buf97 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf98: ExternKernelSchedulerNode(FallbackKernel)
buf98.writes = [StarDep(name='buf98', mode=None)]
buf98.unmet_dependencies = [StarDep(name='buf96', mode=None)]
buf98.met_dependencies = [StarDep(name='primals_28', mode=None), StarDep(name='relu_7', mode=None)]
buf98.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf99'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf100'), can_inplace=False, is_weak=False)]
buf98.node.kernel = None


buf99: ExternKernelSchedulerNode(MultiOutput)
buf99.writes = [StarDep(name='buf99', mode=None)]
buf99.unmet_dependencies = [StarDep(name='buf98', mode=None)]
buf99.met_dependencies = []
buf99.users = [NodeUser(node=SchedulerNode(name='buf101'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf103'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf106'), can_inplace=True, is_weak=False)]
buf99.node.kernel = None


buf100: ExternKernelSchedulerNode(MultiOutput)
buf100.writes = [StarDep(name='buf100', mode=None)]
buf100.unmet_dependencies = [StarDep(name='buf98', mode=None)]
buf100.met_dependencies = []
buf100.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf100.node.kernel = None


buf101: SchedulerNode(ComputedBuffer)
buf101.writes = [MemoryDep('buf101', c0, {c0: 25088}, None)]
buf101.unmet_dependencies = [MemoryDep('buf99', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf101.met_dependencies = [MemoryDep('relu_7', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf101.users = [NodeUser(node=SchedulerNode(name='buf102'), can_inplace=False, is_weak=False)]
buf101.group.device = cuda:0
buf101.group.iteration = (25088, 128)
buf101.sizes = ([196, 128], [128])
relu_7_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf99_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf101_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf101_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_7', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf99', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_2 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf101', get_index_2, reduction)
        return store_reduction
buf101 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf102: SchedulerNode(ComputedBuffer)
buf102.writes = [MemoryDep('buf102', c0, {c0: 128}, None)]
buf102.unmet_dependencies = [MemoryDep('buf101', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf102.met_dependencies = []
buf102.users = [NodeUser(node=SchedulerNode(name='buf106'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf102.group.device = cuda:0
buf102.group.iteration = (128, 196)
buf102.sizes = ([128], [196])
buf101_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf102_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf102_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf101', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf102', get_index_1, reduction)
        return store_reduction
buf102 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf103: SchedulerNode(ComputedBuffer)
buf103.writes = [MemoryDep('buf103', c0, {c0: 25088}, None)]
buf103.unmet_dependencies = [MemoryDep('buf99', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf103.met_dependencies = 
    [   MemoryDep('convolution_8', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('relu_7', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('unsqueeze_214', c1, {c0: 196, c1: 128}, None)]
buf103.users = [NodeUser(node=SchedulerNode(name='buf104'), can_inplace=False, is_weak=False)]
buf103.group.device = cuda:0
buf103.group.iteration = (25088, 128)
buf103.sizes = ([196, 128], [128])
convolution_8_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
relu_7_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf99_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
unsqueeze_214_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
buf103_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf103_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = z1
    index2 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_7', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf99', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_8', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_214', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_4 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf103', get_index_4, reduction)
        return store_reduction
buf103 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        tmp6 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
        _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp5 = tl.load(in_ptr2 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp7 = tmp5 - tmp6
            tmp8 = tmp4 * tmp7
            tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
            tmp11 = _tmp10 + tmp9
            _tmp10 = tl.where(rmask & xmask, tmp11, _tmp10)
        tmp10 = tl.sum(_tmp10, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp10, xmask)


buf104: SchedulerNode(ComputedBuffer)
buf104.writes = [MemoryDep('buf104', c0, {c0: 128}, None)]
buf104.unmet_dependencies = [MemoryDep('buf103', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf104.met_dependencies = []
buf104.users = [NodeUser(node=SchedulerNode(name='buf105'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf106'), can_inplace=False, is_weak=False)]
buf104.group.device = cuda:0
buf104.group.iteration = (128, 196)
buf104.sizes = ([128], [196])
buf103_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf104_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf104_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf103', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf104', get_index_1, reduction)
        return store_reduction
buf104 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf105: SchedulerNode(ComputedBuffer)
buf105.writes = [MemoryDep('buf105', c0, {c0: 128}, None)]
buf105.unmet_dependencies = [MemoryDep('buf104', c0, {c0: 128}, None)]
buf105.met_dependencies = [MemoryDep('squeeze_25', c0, {c0: 128}, None)]
buf105.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf105.group.device = cuda:0
buf105.group.iteration = (128, 1)
buf105.sizes = ([128], [])
buf104_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
squeeze_25_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf105_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf105_loop_body:
    var_ranges = {z0: 128}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf104', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_25', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf105', get_index_2, mul, None)
        return store
buf105 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf106: SchedulerNode(ComputedBuffer)
buf106.writes = [MemoryDep('buf106', c0, {c0: 3211264}, None)]
buf106.unmet_dependencies = 
    [   MemoryDep('buf102', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf104', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf99', c0, {c0: 3211264}, None)]
buf106.met_dependencies = 
    [   MemoryDep('convolution_8', c0, {c0: 3211264}, None),
        MemoryDep('primals_26', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('relu_7', c0, {c0: 3211264}, None),
        MemoryDep('squeeze_25', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('unsqueeze_214', c1, {c0: 25088, c1: 128}, None)]
buf106.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf107'), can_inplace=False, is_weak=False)]
buf106.group.device = cuda:0
buf106.group.iteration = (3211264, 1)
buf106.sizes = ([25088, 128], [])
primals_26_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf104_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf102_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf99_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
squeeze_25_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
unsqueeze_214_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
convolution_8_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
relu_7_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf106_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf106_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_7', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf99', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_8', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_214', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf104', get_index_4)
        constant_2 = ops.constant(3.985969387755102e-05, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_25', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_25', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf102', get_index_7)
        constant_3 = ops.constant(3.985969387755102e-05, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_25', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_26', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf106', get_index_10, mul_6, None)
        return store
buf106 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 3.985969387755102e-05
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf107: ExternKernelSchedulerNode(FallbackKernel)
buf107.writes = [StarDep(name='buf107', mode=None)]
buf107.unmet_dependencies = [StarDep(name='buf106', mode=None)]
buf107.met_dependencies = [StarDep(name='primals_25', mode=None), StarDep(name='relu_6', mode=None)]
buf107.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf108'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf109'), can_inplace=False, is_weak=False)]
buf107.node.kernel = None


buf108: ExternKernelSchedulerNode(MultiOutput)
buf108.writes = [StarDep(name='buf108', mode=None)]
buf108.unmet_dependencies = [StarDep(name='buf107', mode=None)]
buf108.met_dependencies = []
buf108.users = [NodeUser(node=SchedulerNode(name='buf110'), can_inplace=True, is_weak=False)]
buf108.node.kernel = None


buf109: ExternKernelSchedulerNode(MultiOutput)
buf109.writes = [StarDep(name='buf109', mode=None)]
buf109.unmet_dependencies = [StarDep(name='buf107', mode=None)]
buf109.met_dependencies = []
buf109.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf109.node.kernel = None


buf110: SchedulerNode(ComputedBuffer)
buf110.writes = [MemoryDep('buf110', c0, {c0: 3211264}, None)]
buf110.unmet_dependencies = 
    [   MemoryDep('buf108', c0, {c0: 3211264}, None),
        MemoryDep('buf74', c0, {c0: 3211264}, None),
        MemoryDep('buf90', c0, {c0: 3211264}, None)]
buf110.met_dependencies = 
    [   MemoryDep('relu_6', c0, {c0: 3211264}, None),
        MemoryDep('relu_8', c0, {c0: 3211264}, None)]
buf110.users = [NodeUser(node=SchedulerNode(name='buf111'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf113'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf116'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf120'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf123'), can_inplace=True, is_weak=False)]
buf110.group.device = cuda:0
buf110.group.iteration = (3211264, 1)
buf110.sizes = ([3211264], [])
buf108_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
relu_8_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf90_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf74_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
relu_6_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf110_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf110_loop_body:
    var_ranges = {z0: 3211264}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_6', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('relu_8', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        le_1 = ops.le(load_1, constant_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf74', get_index_2)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('buf90', get_index_3)
        add = ops.add(load_2, load_3)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(le_1, constant_2, add)
        get_index_4 = self.get_index('index0')
        load_4 = ops.load('buf108', get_index_4)
        add_1 = ops.add(where, load_4)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf110', get_index_5, where_1, None)
        return store
buf110 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), None)
        tmp3 = tl.load(in_ptr1 + (x0), None)
        tmp5 = tl.load(in_ptr2 + (x0), None)
        tmp6 = tl.load(in_ptr3 + (x0), None)
        tmp9 = tl.load(in_out_ptr0 + (x0), None)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tmp3 <= tmp1
        tmp7 = tmp5 + tmp6
        tmp8 = tl.where(tmp4, tmp1, tmp7)
        tmp10 = tmp8 + tmp9
        tmp11 = tl.where(tmp2, tmp1, tmp10)
        tl.store(in_out_ptr0 + (x0), tmp11, None)


buf111: SchedulerNode(ComputedBuffer)
buf111.writes = [MemoryDep('buf111', c0, {c0: 25088}, None)]
buf111.unmet_dependencies = [MemoryDep('buf110', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf111.met_dependencies = []
buf111.users = [NodeUser(node=SchedulerNode(name='buf112'), can_inplace=False, is_weak=False)]
buf111.group.device = cuda:0
buf111.group.iteration = (25088, 128)
buf111.sizes = ([196, 128], [128])
buf110_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf111_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf111_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf110', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf111', get_index_1, reduction)
        return store_reduction
buf111 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp2, xmask)


buf112: SchedulerNode(ComputedBuffer)
buf112.writes = [MemoryDep('buf112', c0, {c0: 128}, None)]
buf112.unmet_dependencies = [MemoryDep('buf111', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf112.met_dependencies = []
buf112.users = [NodeUser(node=SchedulerNode(name='buf116'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf123'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf112.group.device = cuda:0
buf112.group.iteration = (128, 196)
buf112.sizes = ([128], [196])
buf111_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf112_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf112_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf111', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf112', get_index_1, reduction)
        return store_reduction
buf112 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf113: SchedulerNode(ComputedBuffer)
buf113.writes = [MemoryDep('buf113', c0, {c0: 25088}, None)]
buf113.unmet_dependencies = [MemoryDep('buf110', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf113.met_dependencies = 
    [   MemoryDep('convolution_7', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('unsqueeze_226', c1, {c0: 196, c1: 128}, None)]
buf113.users = [NodeUser(node=SchedulerNode(name='buf114'), can_inplace=False, is_weak=False)]
buf113.group.device = cuda:0
buf113.group.iteration = (25088, 128)
buf113.sizes = ([196, 128], [128])
buf110_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
unsqueeze_226_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
convolution_7_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf113_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf113_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = z1
    index2 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf110', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_7', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_226', get_index_2)
        sub = ops.sub(load_1, load_2)
        mul = ops.mul(load, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf113', get_index_3, reduction)
        return store_reduction
buf113 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        tmp2 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tmp1 - tmp2
            tmp4 = tmp0 * tmp3
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf114: SchedulerNode(ComputedBuffer)
buf114.writes = [MemoryDep('buf114', c0, {c0: 128}, None)]
buf114.unmet_dependencies = [MemoryDep('buf113', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf114.met_dependencies = []
buf114.users = [NodeUser(node=SchedulerNode(name='buf115'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf116'), can_inplace=False, is_weak=False)]
buf114.group.device = cuda:0
buf114.group.iteration = (128, 196)
buf114.sizes = ([128], [196])
buf113_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf114_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf114_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf113', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf114', get_index_1, reduction)
        return store_reduction
buf114 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf115: SchedulerNode(ComputedBuffer)
buf115.writes = [MemoryDep('buf115', c0, {c0: 128}, None)]
buf115.unmet_dependencies = [MemoryDep('buf114', c0, {c0: 128}, None)]
buf115.met_dependencies = [MemoryDep('squeeze_22', c0, {c0: 128}, None)]
buf115.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf115.group.device = cuda:0
buf115.group.iteration = (128, 1)
buf115.sizes = ([128], [])
buf114_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
squeeze_22_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf115_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf115_loop_body:
    var_ranges = {z0: 128}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf114', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_22', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf115', get_index_2, mul, None)
        return store
buf115 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf116: SchedulerNode(ComputedBuffer)
buf116.writes = [MemoryDep('buf116', c0, {c0: 3211264}, None)]
buf116.unmet_dependencies = 
    [   MemoryDep('buf110', c0, {c0: 3211264}, None),
        MemoryDep('buf112', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf114', c1, {c0: 25088, c1: 128}, None)]
buf116.met_dependencies = 
    [   MemoryDep('convolution_7', c0, {c0: 3211264}, None),
        MemoryDep('primals_23', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('squeeze_22', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('unsqueeze_226', c1, {c0: 25088, c1: 128}, None)]
buf116.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf117'), can_inplace=False, is_weak=False)]
buf116.group.device = cuda:0
buf116.group.iteration = (3211264, 1)
buf116.sizes = ([25088, 128], [])
primals_23_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf114_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf110_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
convolution_7_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
unsqueeze_226_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
buf112_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
squeeze_22_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf116_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf116_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf110', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_7', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_226', get_index_2)
        sub = ops.sub(load_1, load_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf114', get_index_3)
        constant = ops.constant(3.985969387755102e-05, torch.float32)
        mul = ops.mul(load_3, constant)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('squeeze_22', get_index_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_22', get_index_5)
        mul_1 = ops.mul(load_4, load_5)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(load, mul_3)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('buf112', get_index_6)
        constant_1 = ops.constant(3.985969387755102e-05, torch.float32)
        mul_4 = ops.mul(load_6, constant_1)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_22', get_index_7)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('primals_23', get_index_8)
        mul_5 = ops.mul(load_7, load_8)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_9 = self.get_index('index0')
        store = ops.store('buf116', get_index_9, mul_6, None)
        return store
buf116 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x2), None)
        tmp2 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp4 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp7 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp3 = tmp1 - tmp2
        tmp5 = 3.985969387755102e-05
        tmp6 = tmp4 * tmp5
        tmp8 = tmp7 * tmp7
        tmp9 = tmp6 * tmp8
        tmp10 = tmp3 * tmp9
        tmp11 = tmp0 - tmp10
        tmp13 = tmp12 * tmp5
        tmp14 = tmp11 - tmp13
        tmp16 = tmp7 * tmp15
        tmp17 = tmp14 * tmp16
        tl.store(out_ptr0 + (x2), tmp17, None)


buf117: ExternKernelSchedulerNode(FallbackKernel)
buf117.writes = [StarDep(name='buf117', mode=None)]
buf117.unmet_dependencies = [StarDep(name='buf116', mode=None)]
buf117.met_dependencies = [StarDep(name='primals_22', mode=None), StarDep(name='relu_4', mode=None)]
buf117.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf118'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf119'), can_inplace=False, is_weak=False)]
buf117.node.kernel = None


buf118: ExternKernelSchedulerNode(MultiOutput)
buf118.writes = [StarDep(name='buf118', mode=None)]
buf118.unmet_dependencies = [StarDep(name='buf117', mode=None)]
buf118.met_dependencies = []
buf118.users = [NodeUser(node=SchedulerNode(name='buf136'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf138'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf140'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf154'), can_inplace=True, is_weak=False)]
buf118.node.kernel = None


buf119: ExternKernelSchedulerNode(MultiOutput)
buf119.writes = [StarDep(name='buf119', mode=None)]
buf119.unmet_dependencies = [StarDep(name='buf117', mode=None)]
buf119.met_dependencies = []
buf119.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf119.node.kernel = None


buf120: SchedulerNode(ComputedBuffer)
buf120.writes = [MemoryDep('buf120', c0, {c0: 25088}, None)]
buf120.unmet_dependencies = [MemoryDep('buf110', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf120.met_dependencies = 
    [   MemoryDep('convolution_6', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('unsqueeze_238', c1, {c0: 196, c1: 128}, None)]
buf120.users = [NodeUser(node=SchedulerNode(name='buf121'), can_inplace=False, is_weak=False)]
buf120.group.device = cuda:0
buf120.group.iteration = (25088, 128)
buf120.sizes = ([196, 128], [128])
buf110_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
unsqueeze_238_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
convolution_6_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf120_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf120_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = z1
    index2 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf110', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_6', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_238', get_index_2)
        sub = ops.sub(load_1, load_2)
        mul = ops.mul(load, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf120', get_index_3, reduction)
        return store_reduction
buf120 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        tmp2 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tmp1 - tmp2
            tmp4 = tmp0 * tmp3
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf121: SchedulerNode(ComputedBuffer)
buf121.writes = [MemoryDep('buf121', c0, {c0: 128}, None)]
buf121.unmet_dependencies = [MemoryDep('buf120', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf121.met_dependencies = []
buf121.users = [NodeUser(node=SchedulerNode(name='buf122'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf123'), can_inplace=False, is_weak=False)]
buf121.group.device = cuda:0
buf121.group.iteration = (128, 196)
buf121.sizes = ([128], [196])
buf120_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf121_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf121_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf120', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf121', get_index_1, reduction)
        return store_reduction
buf121 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf122: SchedulerNode(ComputedBuffer)
buf122.writes = [MemoryDep('buf122', c0, {c0: 128}, None)]
buf122.unmet_dependencies = [MemoryDep('buf121', c0, {c0: 128}, None)]
buf122.met_dependencies = [MemoryDep('squeeze_19', c0, {c0: 128}, None)]
buf122.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf122.group.device = cuda:0
buf122.group.iteration = (128, 1)
buf122.sizes = ([128], [])
buf121_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
squeeze_19_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf122_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf122_loop_body:
    var_ranges = {z0: 128}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf121', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_19', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf122', get_index_2, mul, None)
        return store
buf122 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf123: SchedulerNode(ComputedBuffer)
buf123.writes = [MemoryDep('buf123', c0, {c0: 3211264}, None)]
buf123.unmet_dependencies = 
    [   MemoryDep('buf110', c0, {c0: 3211264}, None),
        MemoryDep('buf112', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf121', c1, {c0: 25088, c1: 128}, None)]
buf123.met_dependencies = 
    [   MemoryDep('convolution_6', c0, {c0: 3211264}, None),
        MemoryDep('primals_20', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('squeeze_19', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('unsqueeze_238', c1, {c0: 25088, c1: 128}, None)]
buf123.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf124'), can_inplace=False, is_weak=False)]
buf123.group.device = cuda:0
buf123.group.iteration = (3211264, 1)
buf123.sizes = ([25088, 128], [])
squeeze_19_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf110_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf121_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf112_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
unsqueeze_238_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
convolution_6_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
primals_20_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf123_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf123_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf110', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_6', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_238', get_index_2)
        sub = ops.sub(load_1, load_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf121', get_index_3)
        constant = ops.constant(3.985969387755102e-05, torch.float32)
        mul = ops.mul(load_3, constant)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('squeeze_19', get_index_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_19', get_index_5)
        mul_1 = ops.mul(load_4, load_5)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(load, mul_3)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('buf112', get_index_6)
        constant_1 = ops.constant(3.985969387755102e-05, torch.float32)
        mul_4 = ops.mul(load_6, constant_1)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_19', get_index_7)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('primals_20', get_index_8)
        mul_5 = ops.mul(load_7, load_8)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_9 = self.get_index('index0')
        store = ops.store('buf123', get_index_9, mul_6, None)
        return store
buf123 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x2), None)
        tmp2 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp4 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp7 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp3 = tmp1 - tmp2
        tmp5 = 3.985969387755102e-05
        tmp6 = tmp4 * tmp5
        tmp8 = tmp7 * tmp7
        tmp9 = tmp6 * tmp8
        tmp10 = tmp3 * tmp9
        tmp11 = tmp0 - tmp10
        tmp13 = tmp12 * tmp5
        tmp14 = tmp11 - tmp13
        tmp16 = tmp7 * tmp15
        tmp17 = tmp14 * tmp16
        tl.store(out_ptr0 + (x2), tmp17, None)


buf124: ExternKernelSchedulerNode(FallbackKernel)
buf124.writes = [StarDep(name='buf124', mode=None)]
buf124.unmet_dependencies = [StarDep(name='buf123', mode=None)]
buf124.met_dependencies = [StarDep(name='primals_19', mode=None), StarDep(name='relu_5', mode=None)]
buf124.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf125'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf126'), can_inplace=False, is_weak=False)]
buf124.node.kernel = None


buf125: ExternKernelSchedulerNode(MultiOutput)
buf125.writes = [StarDep(name='buf125', mode=None)]
buf125.unmet_dependencies = [StarDep(name='buf124', mode=None)]
buf125.met_dependencies = []
buf125.users = [NodeUser(node=SchedulerNode(name='buf127'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf129'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf132'), can_inplace=True, is_weak=False)]
buf125.node.kernel = None


buf126: ExternKernelSchedulerNode(MultiOutput)
buf126.writes = [StarDep(name='buf126', mode=None)]
buf126.unmet_dependencies = [StarDep(name='buf124', mode=None)]
buf126.met_dependencies = []
buf126.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf126.node.kernel = None


buf127: SchedulerNode(ComputedBuffer)
buf127.writes = [MemoryDep('buf127', c0, {c0: 25088}, None)]
buf127.unmet_dependencies = [MemoryDep('buf125', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf127.met_dependencies = [MemoryDep('relu_5', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf127.users = [NodeUser(node=SchedulerNode(name='buf128'), can_inplace=False, is_weak=False)]
buf127.group.device = cuda:0
buf127.group.iteration = (25088, 128)
buf127.sizes = ([196, 128], [128])
buf125_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
relu_5_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf127_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf127_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_5', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf125', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_2 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf127', get_index_2, reduction)
        return store_reduction
buf127 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, xmask)


buf128: SchedulerNode(ComputedBuffer)
buf128.writes = [MemoryDep('buf128', c0, {c0: 128}, None)]
buf128.unmet_dependencies = [MemoryDep('buf127', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf128.met_dependencies = []
buf128.users = [NodeUser(node=SchedulerNode(name='buf132'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf128.group.device = cuda:0
buf128.group.iteration = (128, 196)
buf128.sizes = ([128], [196])
buf127_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf128_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf128_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf127', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf128', get_index_1, reduction)
        return store_reduction
buf128 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf129: SchedulerNode(ComputedBuffer)
buf129.writes = [MemoryDep('buf129', c0, {c0: 25088}, None)]
buf129.unmet_dependencies = [MemoryDep('buf125', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf129.met_dependencies = 
    [   MemoryDep('convolution_5', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('relu_5', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None),
        MemoryDep('unsqueeze_250', c1, {c0: 196, c1: 128}, None)]
buf129.users = [NodeUser(node=SchedulerNode(name='buf130'), can_inplace=False, is_weak=False)]
buf129.group.device = cuda:0
buf129.group.iteration = (25088, 128)
buf129.sizes = ([196, 128], [128])
unsqueeze_250_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
convolution_5_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf125_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
relu_5_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf129_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
class buf129_loop_body:
    var_ranges = {z0: 196, z1: 128, z2: 128}
    index0 = 16384*z0 + z1 + 128*z2
    index1 = z1
    index2 = 128*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_5', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf125', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_5', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_250', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_4 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf129', get_index_4, reduction)
        return store_reduction
buf129 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 128],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 25088
        rnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 128
        x1 = (xindex // 128)
        tmp6 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
        _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp5 = tl.load(in_ptr2 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp7 = tmp5 - tmp6
            tmp8 = tmp4 * tmp7
            tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
            tmp11 = _tmp10 + tmp9
            _tmp10 = tl.where(rmask & xmask, tmp11, _tmp10)
        tmp10 = tl.sum(_tmp10, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp10, xmask)


buf130: SchedulerNode(ComputedBuffer)
buf130.writes = [MemoryDep('buf130', c0, {c0: 128}, None)]
buf130.unmet_dependencies = [MemoryDep('buf129', c0 + 128*c1, {c0: 128, c1: 196}, None)]
buf130.met_dependencies = []
buf130.users = [NodeUser(node=SchedulerNode(name='buf131'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf132'), can_inplace=False, is_weak=False)]
buf130.group.device = cuda:0
buf130.group.iteration = (128, 196)
buf130.sizes = ([128], [196])
buf129_layout = FixedLayout('cuda', torch.float32, size=[128, 196], stride=[1, 128])
buf130_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf130_loop_body:
    var_ranges = {z0: 128, z1: 196}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf129', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf130', get_index_1, reduction)
        return store_reduction
buf130 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[128, 256],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 128
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf131: SchedulerNode(ComputedBuffer)
buf131.writes = [MemoryDep('buf131', c0, {c0: 128}, None)]
buf131.unmet_dependencies = [MemoryDep('buf130', c0, {c0: 128}, None)]
buf131.met_dependencies = [MemoryDep('squeeze_16', c0, {c0: 128}, None)]
buf131.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf131.group.device = cuda:0
buf131.group.iteration = (128, 1)
buf131.sizes = ([128], [])
squeeze_16_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf130_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf131_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
class buf131_loop_body:
    var_ranges = {z0: 128}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf130', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_16', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf131', get_index_2, mul, None)
        return store
buf131 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 128
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf132: SchedulerNode(ComputedBuffer)
buf132.writes = [MemoryDep('buf132', c0, {c0: 3211264}, None)]
buf132.unmet_dependencies = 
    [   MemoryDep('buf125', c0, {c0: 3211264}, None),
        MemoryDep('buf128', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf130', c1, {c0: 25088, c1: 128}, None)]
buf132.met_dependencies = 
    [   MemoryDep('convolution_5', c0, {c0: 3211264}, None),
        MemoryDep('primals_17', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('relu_5', c0, {c0: 3211264}, None),
        MemoryDep('squeeze_16', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('unsqueeze_250', c1, {c0: 25088, c1: 128}, None)]
buf132.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf133'), can_inplace=False, is_weak=False)]
buf132.group.device = cuda:0
buf132.group.iteration = (3211264, 1)
buf132.sizes = ([25088, 128], [])
convolution_5_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
squeeze_16_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf130_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
primals_17_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf128_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
unsqueeze_250_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 1, 1])
buf125_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
relu_5_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf132_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf132_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_5', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf125', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_5', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_250', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf130', get_index_4)
        constant_2 = ops.constant(3.985969387755102e-05, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_16', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_16', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf128', get_index_7)
        constant_3 = ops.constant(3.985969387755102e-05, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_16', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_17', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf132', get_index_10, mul_6, None)
        return store
buf132 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 3.985969387755102e-05
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf133: ExternKernelSchedulerNode(FallbackKernel)
buf133.writes = [StarDep(name='buf133', mode=None)]
buf133.unmet_dependencies = [StarDep(name='buf132', mode=None)]
buf133.met_dependencies = [StarDep(name='primals_16', mode=None), StarDep(name='relu_4', mode=None)]
buf133.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf134'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf135'), can_inplace=False, is_weak=False)]
buf133.node.kernel = None


buf134: ExternKernelSchedulerNode(MultiOutput)
buf134.writes = [StarDep(name='buf134', mode=None)]
buf134.unmet_dependencies = [StarDep(name='buf133', mode=None)]
buf134.met_dependencies = []
buf134.users = [NodeUser(node=SchedulerNode(name='buf136'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf138'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf140'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf154'), can_inplace=True, is_weak=False)]
buf134.node.kernel = None


buf135: ExternKernelSchedulerNode(MultiOutput)
buf135.writes = [StarDep(name='buf135', mode=None)]
buf135.unmet_dependencies = [StarDep(name='buf133', mode=None)]
buf135.met_dependencies = []
buf135.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf135.node.kernel = None


buf136: SchedulerNode(ComputedBuffer)
buf136.writes = [MemoryDep('buf136', c0, {c0: 32768}, None)]
buf136.unmet_dependencies = 
    [   MemoryDep('buf118', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('buf134', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf136.met_dependencies = [MemoryDep('relu_4', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf136.users = [NodeUser(node=SchedulerNode(name='buf137'), can_inplace=False, is_weak=False)]
buf136.group.device = cuda:0
buf136.group.iteration = (32768, 196)
buf136.sizes = ([512, 64], [196])
buf118_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
relu_4_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf134_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf136_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf136_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_4', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf118', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf134', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_3 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf136', get_index_3, reduction)
        return store_reduction
buf136 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp4 = tl.load(in_ptr2 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp5 = tmp3 + tmp4
            tmp6 = tl.where(tmp2, tmp1, tmp5)
            tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
            tmp9 = _tmp8 + tmp7
            _tmp8 = tl.where(rmask, tmp9, _tmp8)
        tmp8 = tl.sum(_tmp8, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp8, None)


buf137: SchedulerNode(ComputedBuffer)
buf137.writes = [MemoryDep('buf137', c0, {c0: 64}, None)]
buf137.unmet_dependencies = [MemoryDep('buf136', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf137.met_dependencies = []
buf137.users = [NodeUser(node=SchedulerNode(name='buf140'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf137.group.device = cuda:0
buf137.group.iteration = (64, 512)
buf137.sizes = ([64], [512])
buf136_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf137_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf137_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf136', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf137', get_index_1, reduction)
        return store_reduction
buf137 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf138: SchedulerNode(ComputedBuffer)
buf138.writes = [MemoryDep('buf138', c0, {c0: 32768}, None)]
buf138.unmet_dependencies = 
    [   MemoryDep('buf118', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('buf134', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf138.met_dependencies = 
    [   MemoryDep('convolution_4', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('relu_4', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('unsqueeze_262', c1, {c0: 512, c1: 64}, None)]
buf138.users = [NodeUser(node=SchedulerNode(name='buf139'), can_inplace=False, is_weak=False)]
buf138.group.device = cuda:0
buf138.group.iteration = (32768, 196)
buf138.sizes = ([512, 64], [196])
convolution_4_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf118_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
relu_4_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
unsqueeze_262_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf134_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf138_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf138_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = z1
    index2 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_4', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf118', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf134', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('convolution_4', get_index_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('unsqueeze_262', get_index_4)
        sub = ops.sub(load_3, load_4)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_5 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf138', get_index_5, reduction)
        return store_reduction
buf138 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        _tmp12 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp4 = tl.load(in_ptr2 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp7 = tl.load(in_ptr3 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp5 = tmp3 + tmp4
            tmp6 = tl.where(tmp2, tmp1, tmp5)
            tmp9 = tmp7 - tmp8
            tmp10 = tmp6 * tmp9
            tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
            tmp13 = _tmp12 + tmp11
            _tmp12 = tl.where(rmask, tmp13, _tmp12)
        tmp12 = tl.sum(_tmp12, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp12, None)


buf139: SchedulerNode(ComputedBuffer)
buf139.writes = [MemoryDep('buf139', c0, {c0: 64}, None)]
buf139.unmet_dependencies = [MemoryDep('buf138', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf139.met_dependencies = []
buf139.users = [NodeUser(node=SchedulerNode(name='buf140'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf141'), can_inplace=True, is_weak=False)]
buf139.group.device = cuda:0
buf139.group.iteration = (64, 512)
buf139.sizes = ([64], [512])
buf138_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf139_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf139_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf138', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf139', get_index_1, reduction)
        return store_reduction
buf139 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf140: SchedulerNode(ComputedBuffer)
buf140.writes = [MemoryDep('buf140', c0, {c0: 6422528}, None)]
buf140.unmet_dependencies = 
    [   MemoryDep('buf118', c0, {c0: 6422528}, None),
        MemoryDep('buf134', c0, {c0: 6422528}, None),
        MemoryDep('buf137', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf139', c1, {c0: 100352, c1: 64}, None)]
buf140.met_dependencies = 
    [   MemoryDep('convolution_4', c0, {c0: 6422528}, None),
        MemoryDep('primals_14', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('relu_4', c0, {c0: 6422528}, None),
        MemoryDep('squeeze_13', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('unsqueeze_262', c1, {c0: 100352, c1: 64}, None)]
buf140.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf142'), can_inplace=False, is_weak=False)]
buf140.group.device = cuda:0
buf140.group.iteration = (6422528, 1)
buf140.sizes = ([100352, 64], [])
buf139_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf137_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
primals_14_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
relu_4_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
unsqueeze_262_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf134_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
squeeze_13_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf118_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
convolution_4_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf140_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf140_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_4', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf118', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf134', get_index_2)
        add = ops.add(load_1, load_2)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, add)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('convolution_4', get_index_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('unsqueeze_262', get_index_4)
        sub = ops.sub(load_3, load_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('buf139', get_index_5)
        constant_2 = ops.constant(9.964923469387754e-06, torch.float32)
        mul = ops.mul(load_5, constant_2)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_13', get_index_6)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_13', get_index_7)
        mul_1 = ops.mul(load_6, load_7)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('buf137', get_index_8)
        constant_3 = ops.constant(9.964923469387754e-06, torch.float32)
        mul_4 = ops.mul(load_8, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('squeeze_13', get_index_9)
        get_index_10 = self.get_index('index1')
        load_10 = ops.load('primals_14', get_index_10)
        mul_5 = ops.mul(load_9, load_10)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf140', get_index_11, mul_6, None)
        return store
buf140 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp4 = tl.load(in_ptr2 + (x2), None)
        tmp7 = tl.load(in_ptr3 + (x2), None)
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp13 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp18 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp21 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp9 = tmp7 - tmp8
        tmp11 = 9.964923469387754e-06
        tmp12 = tmp10 * tmp11
        tmp14 = tmp13 * tmp13
        tmp15 = tmp12 * tmp14
        tmp16 = tmp9 * tmp15
        tmp17 = tmp6 - tmp16
        tmp19 = tmp18 * tmp11
        tmp20 = tmp17 - tmp19
        tmp22 = tmp13 * tmp21
        tmp23 = tmp20 * tmp22
        tl.store(out_ptr0 + (x2), tmp23, None)


buf141: SchedulerNode(ComputedBuffer)
buf141.writes = [MemoryDep('buf141', c0, {c0: 64}, None)]
buf141.unmet_dependencies = [MemoryDep('buf139', c0, {c0: 64}, None)]
buf141.met_dependencies = [MemoryDep('squeeze_13', c0, {c0: 64}, None)]
buf141.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf141.group.device = cuda:0
buf141.group.iteration = (64, 1)
buf141.sizes = ([64], [])
squeeze_13_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf139_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf141_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf141_loop_body:
    var_ranges = {z0: 64}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf139', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_13', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf141', get_index_2, mul, None)
        return store
buf141 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[64], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf142: ExternKernelSchedulerNode(FallbackKernel)
buf142.writes = [StarDep(name='buf142', mode=None)]
buf142.unmet_dependencies = [StarDep(name='buf140', mode=None)]
buf142.met_dependencies = [StarDep(name='primals_13', mode=None), StarDep(name='relu_3', mode=None)]
buf142.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf143'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf144'), can_inplace=False, is_weak=False)]
buf142.node.kernel = None


buf143: ExternKernelSchedulerNode(MultiOutput)
buf143.writes = [StarDep(name='buf143', mode=None)]
buf143.unmet_dependencies = [StarDep(name='buf142', mode=None)]
buf143.met_dependencies = []
buf143.users = [NodeUser(node=SchedulerNode(name='buf145'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf147'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf150'), can_inplace=True, is_weak=False)]
buf143.node.kernel = None


buf144: ExternKernelSchedulerNode(MultiOutput)
buf144.writes = [StarDep(name='buf144', mode=None)]
buf144.unmet_dependencies = [StarDep(name='buf142', mode=None)]
buf144.met_dependencies = []
buf144.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf144.node.kernel = None


buf145: SchedulerNode(ComputedBuffer)
buf145.writes = [MemoryDep('buf145', c0, {c0: 32768}, None)]
buf145.unmet_dependencies = [MemoryDep('buf143', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf145.met_dependencies = [MemoryDep('relu_3', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf145.users = [NodeUser(node=SchedulerNode(name='buf146'), can_inplace=False, is_weak=False)]
buf145.group.device = cuda:0
buf145.group.iteration = (32768, 196)
buf145.sizes = ([512, 64], [196])
relu_3_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf143_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf145_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf145_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_3', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf143', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_2 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf145', get_index_2, reduction)
        return store_reduction
buf145 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, None)


buf146: SchedulerNode(ComputedBuffer)
buf146.writes = [MemoryDep('buf146', c0, {c0: 64}, None)]
buf146.unmet_dependencies = [MemoryDep('buf145', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf146.met_dependencies = []
buf146.users = [NodeUser(node=SchedulerNode(name='buf150'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf146.group.device = cuda:0
buf146.group.iteration = (64, 512)
buf146.sizes = ([64], [512])
buf145_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf146_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf146_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf145', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf146', get_index_1, reduction)
        return store_reduction
buf146 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf147: SchedulerNode(ComputedBuffer)
buf147.writes = [MemoryDep('buf147', c0, {c0: 32768}, None)]
buf147.unmet_dependencies = [MemoryDep('buf143', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf147.met_dependencies = 
    [   MemoryDep('convolution_3', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('relu_3', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('unsqueeze_274', c1, {c0: 512, c1: 64}, None)]
buf147.users = [NodeUser(node=SchedulerNode(name='buf148'), can_inplace=False, is_weak=False)]
buf147.group.device = cuda:0
buf147.group.iteration = (32768, 196)
buf147.sizes = ([512, 64], [196])
relu_3_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf143_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
convolution_3_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
unsqueeze_274_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf147_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf147_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = z1
    index2 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_3', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf143', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_3', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_274', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_4 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf147', get_index_4, reduction)
        return store_reduction
buf147 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp5 = tl.load(in_ptr2 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp7 = tmp5 - tmp6
            tmp8 = tmp4 * tmp7
            tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
            tmp11 = _tmp10 + tmp9
            _tmp10 = tl.where(rmask, tmp11, _tmp10)
        tmp10 = tl.sum(_tmp10, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp10, None)


buf148: SchedulerNode(ComputedBuffer)
buf148.writes = [MemoryDep('buf148', c0, {c0: 64}, None)]
buf148.unmet_dependencies = [MemoryDep('buf147', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf148.met_dependencies = []
buf148.users = [NodeUser(node=SchedulerNode(name='buf149'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf150'), can_inplace=False, is_weak=False)]
buf148.group.device = cuda:0
buf148.group.iteration = (64, 512)
buf148.sizes = ([64], [512])
buf147_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf148_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf148_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf147', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf148', get_index_1, reduction)
        return store_reduction
buf148 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf149: SchedulerNode(ComputedBuffer)
buf149.writes = [MemoryDep('buf149', c0, {c0: 64}, None)]
buf149.unmet_dependencies = [MemoryDep('buf148', c0, {c0: 64}, None)]
buf149.met_dependencies = [MemoryDep('squeeze_10', c0, {c0: 64}, None)]
buf149.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf149.group.device = cuda:0
buf149.group.iteration = (64, 1)
buf149.sizes = ([64], [])
buf148_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
squeeze_10_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf149_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf149_loop_body:
    var_ranges = {z0: 64}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf148', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_10', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf149', get_index_2, mul, None)
        return store
buf149 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[64], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf150: SchedulerNode(ComputedBuffer)
buf150.writes = [MemoryDep('buf150', c0, {c0: 6422528}, None)]
buf150.unmet_dependencies = 
    [   MemoryDep('buf143', c0, {c0: 6422528}, None),
        MemoryDep('buf146', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf148', c1, {c0: 100352, c1: 64}, None)]
buf150.met_dependencies = 
    [   MemoryDep('convolution_3', c0, {c0: 6422528}, None),
        MemoryDep('primals_11', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('relu_3', c0, {c0: 6422528}, None),
        MemoryDep('squeeze_10', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('unsqueeze_274', c1, {c0: 100352, c1: 64}, None)]
buf150.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf151'), can_inplace=False, is_weak=False)]
buf150.group.device = cuda:0
buf150.group.iteration = (6422528, 1)
buf150.sizes = ([100352, 64], [])
buf143_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf148_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf146_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
relu_3_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
primals_11_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
convolution_3_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
squeeze_10_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
unsqueeze_274_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf150_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf150_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_3', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf143', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_3', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_274', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf148', get_index_4)
        constant_2 = ops.constant(9.964923469387754e-06, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_10', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_10', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf146', get_index_7)
        constant_3 = ops.constant(9.964923469387754e-06, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_10', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_11', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf150', get_index_10, mul_6, None)
        return store
buf150 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 9.964923469387754e-06
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf151: ExternKernelSchedulerNode(FallbackKernel)
buf151.writes = [StarDep(name='buf151', mode=None)]
buf151.unmet_dependencies = [StarDep(name='buf150', mode=None)]
buf151.met_dependencies = [StarDep(name='primals_10', mode=None), StarDep(name='relu_2', mode=None)]
buf151.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf152'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf153'), can_inplace=False, is_weak=False)]
buf151.node.kernel = None


buf152: ExternKernelSchedulerNode(MultiOutput)
buf152.writes = [StarDep(name='buf152', mode=None)]
buf152.unmet_dependencies = [StarDep(name='buf151', mode=None)]
buf152.met_dependencies = []
buf152.users = [NodeUser(node=SchedulerNode(name='buf154'), can_inplace=True, is_weak=False)]
buf152.node.kernel = None


buf153: ExternKernelSchedulerNode(MultiOutput)
buf153.writes = [StarDep(name='buf153', mode=None)]
buf153.unmet_dependencies = [StarDep(name='buf151', mode=None)]
buf153.met_dependencies = []
buf153.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf153.node.kernel = None


buf154: SchedulerNode(ComputedBuffer)
buf154.writes = [MemoryDep('buf154', c0, {c0: 6422528}, None)]
buf154.unmet_dependencies = 
    [   MemoryDep('buf118', c0, {c0: 6422528}, None),
        MemoryDep('buf134', c0, {c0: 6422528}, None),
        MemoryDep('buf152', c0, {c0: 6422528}, None)]
buf154.met_dependencies = 
    [   MemoryDep('relu_2', c0, {c0: 6422528}, None),
        MemoryDep('relu_4', c0, {c0: 6422528}, None)]
buf154.users = [NodeUser(node=SchedulerNode(name='buf155'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf157'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf160'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf173'), can_inplace=True, is_weak=False)]
buf154.group.device = cuda:0
buf154.group.iteration = (6422528, 1)
buf154.sizes = ([6422528], [])
relu_2_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf134_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf152_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
relu_4_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf118_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf154_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf154_loop_body:
    var_ranges = {z0: 6422528}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_2', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('relu_4', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        le_1 = ops.le(load_1, constant_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf118', get_index_2)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('buf134', get_index_3)
        add = ops.add(load_2, load_3)
        constant_2 = ops.constant(0.0, torch.float32)
        where = ops.where(le_1, constant_2, add)
        get_index_4 = self.get_index('index0')
        load_4 = ops.load('buf152', get_index_4)
        add_1 = ops.add(where, load_4)
        constant_3 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(le, constant_3, add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf154', get_index_5, where_1, None)
        return store
buf154 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), None)
        tmp3 = tl.load(in_ptr1 + (x0), None)
        tmp5 = tl.load(in_ptr2 + (x0), None)
        tmp6 = tl.load(in_ptr3 + (x0), None)
        tmp9 = tl.load(in_out_ptr0 + (x0), None)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tmp3 <= tmp1
        tmp7 = tmp5 + tmp6
        tmp8 = tl.where(tmp4, tmp1, tmp7)
        tmp10 = tmp8 + tmp9
        tmp11 = tl.where(tmp2, tmp1, tmp10)
        tl.store(in_out_ptr0 + (x0), tmp11, None)


buf155: SchedulerNode(ComputedBuffer)
buf155.writes = [MemoryDep('buf155', c0, {c0: 32768}, None)]
buf155.unmet_dependencies = [MemoryDep('buf154', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf155.met_dependencies = []
buf155.users = [NodeUser(node=SchedulerNode(name='buf156'), can_inplace=False, is_weak=False)]
buf155.group.device = cuda:0
buf155.group.iteration = (32768, 196)
buf155.sizes = ([512, 64], [196])
buf154_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf155_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf155_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf154', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf155', get_index_1, reduction)
        return store_reduction
buf155 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp2, None)


buf156: SchedulerNode(ComputedBuffer)
buf156.writes = [MemoryDep('buf156', c0, {c0: 64}, None)]
buf156.unmet_dependencies = [MemoryDep('buf155', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf156.met_dependencies = []
buf156.users = [NodeUser(node=SchedulerNode(name='buf160'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf156.group.device = cuda:0
buf156.group.iteration = (64, 512)
buf156.sizes = ([64], [512])
buf155_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf156_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf156_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf155', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf156', get_index_1, reduction)
        return store_reduction
buf156 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf157: SchedulerNode(ComputedBuffer)
buf157.writes = [MemoryDep('buf157', c0, {c0: 32768}, None)]
buf157.unmet_dependencies = [MemoryDep('buf154', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf157.met_dependencies = 
    [   MemoryDep('convolution_2', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('unsqueeze_286', c1, {c0: 512, c1: 64}, None)]
buf157.users = [NodeUser(node=SchedulerNode(name='buf158'), can_inplace=False, is_weak=False)]
buf157.group.device = cuda:0
buf157.group.iteration = (32768, 196)
buf157.sizes = ([512, 64], [196])
convolution_2_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf154_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
unsqueeze_286_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf157_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf157_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = z1
    index2 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf154', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_2', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_286', get_index_2)
        sub = ops.sub(load_1, load_2)
        mul = ops.mul(load, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf157', get_index_3, reduction)
        return store_reduction
buf157 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        tmp2 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tmp1 - tmp2
            tmp4 = tmp0 * tmp3
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, None)


buf158: SchedulerNode(ComputedBuffer)
buf158.writes = [MemoryDep('buf158', c0, {c0: 64}, None)]
buf158.unmet_dependencies = [MemoryDep('buf157', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf158.met_dependencies = []
buf158.users = [NodeUser(node=SchedulerNode(name='buf159'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf160'), can_inplace=False, is_weak=False)]
buf158.group.device = cuda:0
buf158.group.iteration = (64, 512)
buf158.sizes = ([64], [512])
buf157_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf158_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf158_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf157', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf158', get_index_1, reduction)
        return store_reduction
buf158 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf159: SchedulerNode(ComputedBuffer)
buf159.writes = [MemoryDep('buf159', c0, {c0: 64}, None)]
buf159.unmet_dependencies = [MemoryDep('buf158', c0, {c0: 64}, None)]
buf159.met_dependencies = [MemoryDep('squeeze_7', c0, {c0: 64}, None)]
buf159.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf159.group.device = cuda:0
buf159.group.iteration = (64, 1)
buf159.sizes = ([64], [])
buf158_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
squeeze_7_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf159_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf159_loop_body:
    var_ranges = {z0: 64}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf158', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_7', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf159', get_index_2, mul, None)
        return store
buf159 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[64], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf160: SchedulerNode(ComputedBuffer)
buf160.writes = [MemoryDep('buf160', c0, {c0: 6422528}, None)]
buf160.unmet_dependencies = 
    [   MemoryDep('buf154', c0, {c0: 6422528}, None),
        MemoryDep('buf156', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf158', c1, {c0: 100352, c1: 64}, None)]
buf160.met_dependencies = 
    [   MemoryDep('convolution_2', c0, {c0: 6422528}, None),
        MemoryDep('primals_8', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('squeeze_7', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('unsqueeze_286', c1, {c0: 100352, c1: 64}, None)]
buf160.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf161'), can_inplace=False, is_weak=False)]
buf160.group.device = cuda:0
buf160.group.iteration = (6422528, 1)
buf160.sizes = ([100352, 64], [])
buf154_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
convolution_2_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf158_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
primals_8_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
squeeze_7_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf156_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
unsqueeze_286_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf160_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf160_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf154', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('convolution_2', get_index_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('unsqueeze_286', get_index_2)
        sub = ops.sub(load_1, load_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('buf158', get_index_3)
        constant = ops.constant(9.964923469387754e-06, torch.float32)
        mul = ops.mul(load_3, constant)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('squeeze_7', get_index_4)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_7', get_index_5)
        mul_1 = ops.mul(load_4, load_5)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(load, mul_3)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('buf156', get_index_6)
        constant_1 = ops.constant(9.964923469387754e-06, torch.float32)
        mul_4 = ops.mul(load_6, constant_1)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('squeeze_7', get_index_7)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('primals_8', get_index_8)
        mul_5 = ops.mul(load_7, load_8)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_9 = self.get_index('index0')
        store = ops.store('buf160', get_index_9, mul_6, None)
        return store
buf160 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x2), None)
        tmp2 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp4 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp7 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp3 = tmp1 - tmp2
        tmp5 = 9.964923469387754e-06
        tmp6 = tmp4 * tmp5
        tmp8 = tmp7 * tmp7
        tmp9 = tmp6 * tmp8
        tmp10 = tmp3 * tmp9
        tmp11 = tmp0 - tmp10
        tmp13 = tmp12 * tmp5
        tmp14 = tmp11 - tmp13
        tmp16 = tmp7 * tmp15
        tmp17 = tmp14 * tmp16
        tl.store(out_ptr0 + (x2), tmp17, None)


buf161: ExternKernelSchedulerNode(FallbackKernel)
buf161.writes = [StarDep(name='buf161', mode=None)]
buf161.unmet_dependencies = [StarDep(name='buf160', mode=None)]
buf161.met_dependencies = [StarDep(name='primals_7', mode=None), StarDep(name='relu_1', mode=None)]
buf161.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf162'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf163'), can_inplace=False, is_weak=False)]
buf161.node.kernel = None


buf162: ExternKernelSchedulerNode(MultiOutput)
buf162.writes = [StarDep(name='buf162', mode=None)]
buf162.unmet_dependencies = [StarDep(name='buf161', mode=None)]
buf162.met_dependencies = []
buf162.users = [NodeUser(node=SchedulerNode(name='buf164'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf166'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf169'), can_inplace=True, is_weak=False)]
buf162.node.kernel = None


buf163: ExternKernelSchedulerNode(MultiOutput)
buf163.writes = [StarDep(name='buf163', mode=None)]
buf163.unmet_dependencies = [StarDep(name='buf161', mode=None)]
buf163.met_dependencies = []
buf163.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf163.node.kernel = None


buf164: SchedulerNode(ComputedBuffer)
buf164.writes = [MemoryDep('buf164', c0, {c0: 32768}, None)]
buf164.unmet_dependencies = [MemoryDep('buf162', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf164.met_dependencies = [MemoryDep('relu_1', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf164.users = [NodeUser(node=SchedulerNode(name='buf165'), can_inplace=False, is_weak=False)]
buf164.group.device = cuda:0
buf164.group.iteration = (32768, 196)
buf164.sizes = ([512, 64], [196])
buf162_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
relu_1_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf164_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf164_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_1', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf162', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_2 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf164', get_index_2, reduction)
        return store_reduction
buf164 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, None)


buf165: SchedulerNode(ComputedBuffer)
buf165.writes = [MemoryDep('buf165', c0, {c0: 64}, None)]
buf165.unmet_dependencies = [MemoryDep('buf164', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf165.met_dependencies = []
buf165.users = [NodeUser(node=SchedulerNode(name='buf169'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf165.group.device = cuda:0
buf165.group.iteration = (64, 512)
buf165.sizes = ([64], [512])
buf164_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf165_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf165_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf164', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf165', get_index_1, reduction)
        return store_reduction
buf165 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf166: SchedulerNode(ComputedBuffer)
buf166.writes = [MemoryDep('buf166', c0, {c0: 32768}, None)]
buf166.unmet_dependencies = [MemoryDep('buf162', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf166.met_dependencies = 
    [   MemoryDep('convolution_1', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('relu_1', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None),
        MemoryDep('unsqueeze_298', c1, {c0: 512, c1: 64}, None)]
buf166.users = [NodeUser(node=SchedulerNode(name='buf167'), can_inplace=False, is_weak=False)]
buf166.group.device = cuda:0
buf166.group.iteration = (32768, 196)
buf166.sizes = ([512, 64], [196])
unsqueeze_298_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
convolution_1_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf162_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
relu_1_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf166_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf166_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 196}
    index0 = 12544*z0 + z1 + 64*z2
    index1 = z1
    index2 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_1', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf162', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_1', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_298', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_4 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf166', get_index_4, reduction)
        return store_reduction
buf166 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 256],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 196
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp5 = tl.load(in_ptr2 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp7 = tmp5 - tmp6
            tmp8 = tmp4 * tmp7
            tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
            tmp11 = _tmp10 + tmp9
            _tmp10 = tl.where(rmask, tmp11, _tmp10)
        tmp10 = tl.sum(_tmp10, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp10, None)


buf167: SchedulerNode(ComputedBuffer)
buf167.writes = [MemoryDep('buf167', c0, {c0: 64}, None)]
buf167.unmet_dependencies = [MemoryDep('buf166', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf167.met_dependencies = []
buf167.users = [NodeUser(node=SchedulerNode(name='buf168'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf169'), can_inplace=False, is_weak=False)]
buf167.group.device = cuda:0
buf167.group.iteration = (64, 512)
buf167.sizes = ([64], [512])
buf166_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf167_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf167_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf166', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf167', get_index_1, reduction)
        return store_reduction
buf167 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf168: SchedulerNode(ComputedBuffer)
buf168.writes = [MemoryDep('buf168', c0, {c0: 64}, None)]
buf168.unmet_dependencies = [MemoryDep('buf167', c0, {c0: 64}, None)]
buf168.met_dependencies = [MemoryDep('squeeze_4', c0, {c0: 64}, None)]
buf168.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf168.group.device = cuda:0
buf168.group.iteration = (64, 1)
buf168.sizes = ([64], [])
buf167_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
squeeze_4_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf168_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf168_loop_body:
    var_ranges = {z0: 64}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf167', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_4', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf168', get_index_2, mul, None)
        return store
buf168 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[64], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf169: SchedulerNode(ComputedBuffer)
buf169.writes = [MemoryDep('buf169', c0, {c0: 6422528}, None)]
buf169.unmet_dependencies = 
    [   MemoryDep('buf162', c0, {c0: 6422528}, None),
        MemoryDep('buf165', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf167', c1, {c0: 100352, c1: 64}, None)]
buf169.met_dependencies = 
    [   MemoryDep('convolution_1', c0, {c0: 6422528}, None),
        MemoryDep('primals_5', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('relu_1', c0, {c0: 6422528}, None),
        MemoryDep('squeeze_4', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('unsqueeze_298', c1, {c0: 100352, c1: 64}, None)]
buf169.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf170'), can_inplace=False, is_weak=False)]
buf169.group.device = cuda:0
buf169.group.iteration = (6422528, 1)
buf169.sizes = ([100352, 64], [])
buf162_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
convolution_1_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
primals_5_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
unsqueeze_298_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf167_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
relu_1_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf165_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
squeeze_4_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf169_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf169_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_1', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf162', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution_1', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_298', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf167', get_index_4)
        constant_2 = ops.constant(9.964923469387754e-06, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_4', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_4', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf165', get_index_7)
        constant_3 = ops.constant(9.964923469387754e-06, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_4', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_5', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf169', get_index_10, mul_6, None)
        return store
buf169 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 9.964923469387754e-06
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf170: ExternKernelSchedulerNode(FallbackKernel)
buf170.writes = [StarDep(name='buf170', mode=None)]
buf170.unmet_dependencies = [StarDep(name='buf169', mode=None)]
buf170.met_dependencies = [StarDep(name='getitem_2', mode=None), StarDep(name='primals_4', mode=None)]
buf170.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf171'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf172'), can_inplace=False, is_weak=False)]
buf170.node.kernel = None


buf171: ExternKernelSchedulerNode(MultiOutput)
buf171.writes = [StarDep(name='buf171', mode=None)]
buf171.unmet_dependencies = [StarDep(name='buf170', mode=None)]
buf171.met_dependencies = []
buf171.users = [NodeUser(node=SchedulerNode(name='buf173'), can_inplace=True, is_weak=False)]
buf171.node.kernel = None


buf172: ExternKernelSchedulerNode(MultiOutput)
buf172.writes = [StarDep(name='buf172', mode=None)]
buf172.unmet_dependencies = [StarDep(name='buf170', mode=None)]
buf172.met_dependencies = []
buf172.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf172.node.kernel = None


buf173: SchedulerNode(ComputedBuffer)
buf173.writes = [MemoryDep('buf173', c0, {c0: 6422528}, None)]
buf173.unmet_dependencies = 
    [   MemoryDep('buf154', c0, {c0: 6422528}, None),
        MemoryDep('buf171', c0, {c0: 6422528}, None)]
buf173.met_dependencies = []
buf173.users = [NodeUser(node=SchedulerNode(name='buf174'), can_inplace=False, is_weak=False)]
buf173.group.device = cuda:0
buf173.group.iteration = (6422528, 1)
buf173.sizes = ([6422528], [])
buf154_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf171_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf173_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf173_loop_body:
    var_ranges = {z0: 6422528}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf154', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf171', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf173', get_index_2, add, None)
        return store
buf173 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), None)
        tmp1 = tl.load(in_out_ptr0 + (x0), None)
        tmp2 = tmp0 + tmp1
        tl.store(in_out_ptr0 + (x0), tmp2, None)


buf174: SchedulerNode(ComputedBuffer)
buf174.writes = [MemoryDep('buf174', c0, {c0: 25690112}, None)]
buf174.unmet_dependencies = 
    [   MemoryDep('buf173', 200704*c0 + c3 + 3584*Min(Max(0, (c1//2)) + 1, Min(56, ((c1 + 1)//2) + 1) - 1) + 64*Min(Max(0, (c2//2)) + 1, Min(56, ((c2 + 1)//2) + 1) - 1), {c0: 32, c1: 112, c2: 112, c3: 64}, None),
        MemoryDep('buf173', 200704*c0 + c3 + 3584*Min(Max(0, (c1//2)) + 1, Min(56, ((c1 + 1)//2) + 1) - 1) + 64*Min(Min(56, ((c2 + 1)//2) + 1) - 1, Max(0, (c2//2))), {c0: 32, c1: 112, c2: 112, c3: 64}, None),
        MemoryDep('buf173', 200704*c0 + c3 + 3584*Min(Min(56, ((c1 + 1)//2) + 1) - 1, Max(0, (c1//2))) + 64*Min(Min(56, ((c2 + 1)//2) + 1) - 1, Max(0, (c2//2))), {c0: 32, c1: 112, c2: 112, c3: 64}, None),
        MemoryDep('buf173', 200704*c0 + c3 + 64*Min(Max(0, (c2//2)) + 1, Min(56, ((c2 + 1)//2) + 1) - 1) + 3584*Min(Min(56, ((c1 + 1)//2) + 1) - 1, Max(0, (c1//2))), {c0: 32, c1: 112, c2: 112, c3: 64}, None)]
buf174.met_dependencies = 
    [   MemoryDep('getitem_3', 200704*c0 + c3 + 3584*Min(Max(0, (c1//2)) + 1, Min(56, ((c1 + 1)//2) + 1) - 1) + 64*Min(Max(0, (c2//2)) + 1, Min(56, ((c2 + 1)//2) + 1) - 1), {c0: 32, c1: 112, c2: 112, c3: 64}, None),
        MemoryDep('getitem_3', 200704*c0 + c3 + 3584*Min(Max(0, (c1//2)) + 1, Min(56, ((c1 + 1)//2) + 1) - 1) + 64*Min(Min(56, ((c2 + 1)//2) + 1) - 1, Max(0, (c2//2))), {c0: 32, c1: 112, c2: 112, c3: 64}, None),
        MemoryDep('getitem_3', 200704*c0 + c3 + 3584*Min(Min(56, ((c1 + 1)//2) + 1) - 1, Max(0, (c1//2))) + 64*Min(Min(56, ((c2 + 1)//2) + 1) - 1, Max(0, (c2//2))), {c0: 32, c1: 112, c2: 112, c3: 64}, None),
        MemoryDep('getitem_3', 200704*c0 + c3 + 64*Min(Max(0, (c2//2)) + 1, Min(56, ((c2 + 1)//2) + 1) - 1) + 3584*Min(Min(56, ((c1 + 1)//2) + 1) - 1, Max(0, (c1//2))), {c0: 32, c1: 112, c2: 112, c3: 64}, None)]
buf174.users = [NodeUser(node=SchedulerNode(name='buf175'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf177'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf180'), can_inplace=True, is_weak=False)]
buf174.group.device = cuda:0
buf174.group.iteration = (25690112, 1)
buf174.sizes = ([32, 112, 112, 64], [])
buf173_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf173_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf173_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf173_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
getitem_3_layout = FixedLayout('cuda', torch.int8, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
getitem_3_layout = FixedLayout('cuda', torch.int8, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
getitem_3_layout = FixedLayout('cuda', torch.int8, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
getitem_3_layout = FixedLayout('cuda', torch.int8, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf174_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
class buf174_loop_body:
    var_ranges = {z0: 32, z1: 112, z2: 112, z3: 64}
    index0 = 200704*z0 + z3 + 3584*Min(Min(56, ((z1 + 1)//2) + 1) - 1, Max(0, (z1//2))) + 64*Min(Min(56, ((z2 + 1)//2) + 1) - 1, Max(0, (z2//2)))
    index1 = 2*Min(Min(56, ((z1 + 1)//2) + 1) - 1, Max(0, (z1//2))) - 1
    index2 = 2*Min(Min(56, ((z2 + 1)//2) + 1) - 1, Max(0, (z2//2))) - 1
    index3 = 112*z1 + z2
    index4 = 200704*z0 + z3 + 64*Min(Max(0, (z2//2)) + 1, Min(56, ((z2 + 1)//2) + 1) - 1) + 3584*Min(Min(56, ((z1 + 1)//2) + 1) - 1, Max(0, (z1//2)))
    index5 = 2*Min(Max(0, (z2//2)) + 1, Min(56, ((z2 + 1)//2) + 1) - 1) - 1
    index6 = Max(0, (z1//2))
    index7 = Min(56, ((z1 + 1)//2) + 1)
    index8 = Max(0, (z2//2)) + 1
    index9 = Min(56, ((z2 + 1)//2) + 1)
    index10 = 200704*z0 + z3 + 3584*Min(Max(0, (z1//2)) + 1, Min(56, ((z1 + 1)//2) + 1) - 1) + 64*Min(Min(56, ((z2 + 1)//2) + 1) - 1, Max(0, (z2//2)))
    index11 = 2*Min(Max(0, (z1//2)) + 1, Min(56, ((z1 + 1)//2) + 1) - 1) - 1
    index12 = Max(0, (z1//2)) + 1
    index13 = Max(0, (z2//2))
    index14 = 200704*z0 + z3 + 3584*Min(Max(0, (z1//2)) + 1, Min(56, ((z1 + 1)//2) + 1) - 1) + 64*Min(Max(0, (z2//2)) + 1, Min(56, ((z2 + 1)//2) + 1) - 1)
    index15 = 802816*z0 + 7168*z1 + 64*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('getitem_3', get_index)
        constant = ops.constant(3, torch.int32)
        floordiv = ops.floordiv(load, constant)
        constant_1 = ops.constant(3, torch.int32)
        mul = ops.mul(floordiv, constant_1)
        sub = ops.sub(load, mul)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int64)
        add = ops.add(index_expr, floordiv)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int64)
        add_1 = ops.add(index_expr_1, sub)
        constant_2 = ops.constant(112, torch.int64)
        mul_1 = ops.mul(add, constant_2)
        add_2 = ops.add(mul_1, add_1)
        get_index_3 = self.get_index('index0')
        load_1 = ops.load('buf173', get_index_3)
        get_index_4 = self.get_index('index3')
        index_expr_2 = ops.index_expr(get_index_4, torch.int32)
        eq = ops.eq(add_2, index_expr_2)
        constant_3 = ops.constant(0.0, torch.float32)
        where = ops.where(eq, load_1, constant_3)
        get_index_5 = self.get_index('index4')
        load_2 = ops.load('getitem_3', get_index_5)
        constant_4 = ops.constant(3, torch.int32)
        floordiv_1 = ops.floordiv(load_2, constant_4)
        constant_5 = ops.constant(3, torch.int32)
        mul_2 = ops.mul(floordiv_1, constant_5)
        sub_1 = ops.sub(load_2, mul_2)
        get_index_6 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_6, torch.int64)
        add_3 = ops.add(index_expr_3, floordiv_1)
        get_index_7 = self.get_index('index5')
        index_expr_4 = ops.index_expr(get_index_7, torch.int64)
        add_4 = ops.add(index_expr_4, sub_1)
        constant_6 = ops.constant(112, torch.int64)
        mul_3 = ops.mul(add_3, constant_6)
        add_5 = ops.add(mul_3, add_4)
        get_index_8 = self.get_index('index4')
        load_3 = ops.load('buf173', get_index_8)
        get_index_9 = self.get_index('index3')
        index_expr_5 = ops.index_expr(get_index_9, torch.int32)
        eq_1 = ops.eq(add_5, index_expr_5)
        get_index_10 = self.get_index('index6')
        index_expr_6 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index7')
        index_expr_7 = ops.index_expr(get_index_11, torch.int32)
        lt = ops.lt(index_expr_6, index_expr_7)
        get_index_12 = self.get_index('index8')
        index_expr_8 = ops.index_expr(get_index_12, torch.int32)
        get_index_13 = self.get_index('index9')
        index_expr_9 = ops.index_expr(get_index_13, torch.int32)
        lt_1 = ops.lt(index_expr_8, index_expr_9)
        and_ = ops.and_(lt, lt_1)
        and__1 = ops.and_(and_, eq_1)
        add_6 = ops.add(where, load_3)
        where_1 = ops.where(and__1, add_6, where)
        get_index_14 = self.get_index('index10')
        load_4 = ops.load('getitem_3', get_index_14)
        constant_7 = ops.constant(3, torch.int32)
        floordiv_2 = ops.floordiv(load_4, constant_7)
        constant_8 = ops.constant(3, torch.int32)
        mul_4 = ops.mul(floordiv_2, constant_8)
        sub_2 = ops.sub(load_4, mul_4)
        get_index_15 = self.get_index('index11')
        index_expr_10 = ops.index_expr(get_index_15, torch.int64)
        add_7 = ops.add(index_expr_10, floordiv_2)
        get_index_16 = self.get_index('index2')
        index_expr_11 = ops.index_expr(get_index_16, torch.int64)
        add_8 = ops.add(index_expr_11, sub_2)
        constant_9 = ops.constant(112, torch.int64)
        mul_5 = ops.mul(add_7, constant_9)
        add_9 = ops.add(mul_5, add_8)
        get_index_17 = self.get_index('index10')
        load_5 = ops.load('buf173', get_index_17)
        get_index_18 = self.get_index('index3')
        index_expr_12 = ops.index_expr(get_index_18, torch.int32)
        eq_2 = ops.eq(add_9, index_expr_12)
        get_index_19 = self.get_index('index12')
        index_expr_13 = ops.index_expr(get_index_19, torch.int32)
        get_index_20 = self.get_index('index7')
        index_expr_14 = ops.index_expr(get_index_20, torch.int32)
        lt_2 = ops.lt(index_expr_13, index_expr_14)
        get_index_21 = self.get_index('index13')
        index_expr_15 = ops.index_expr(get_index_21, torch.int32)
        get_index_22 = self.get_index('index9')
        index_expr_16 = ops.index_expr(get_index_22, torch.int32)
        lt_3 = ops.lt(index_expr_15, index_expr_16)
        and__2 = ops.and_(lt_2, lt_3)
        and__3 = ops.and_(and__2, eq_2)
        add_10 = ops.add(where_1, load_5)
        where_2 = ops.where(and__3, add_10, where_1)
        get_index_23 = self.get_index('index14')
        load_6 = ops.load('getitem_3', get_index_23)
        constant_10 = ops.constant(3, torch.int32)
        floordiv_3 = ops.floordiv(load_6, constant_10)
        constant_11 = ops.constant(3, torch.int32)
        mul_6 = ops.mul(floordiv_3, constant_11)
        sub_3 = ops.sub(load_6, mul_6)
        get_index_24 = self.get_index('index11')
        index_expr_17 = ops.index_expr(get_index_24, torch.int64)
        add_11 = ops.add(index_expr_17, floordiv_3)
        get_index_25 = self.get_index('index5')
        index_expr_18 = ops.index_expr(get_index_25, torch.int64)
        add_12 = ops.add(index_expr_18, sub_3)
        constant_12 = ops.constant(112, torch.int64)
        mul_7 = ops.mul(add_11, constant_12)
        add_13 = ops.add(mul_7, add_12)
        get_index_26 = self.get_index('index14')
        load_7 = ops.load('buf173', get_index_26)
        get_index_27 = self.get_index('index3')
        index_expr_19 = ops.index_expr(get_index_27, torch.int32)
        eq_3 = ops.eq(add_13, index_expr_19)
        get_index_28 = self.get_index('index12')
        index_expr_20 = ops.index_expr(get_index_28, torch.int32)
        get_index_29 = self.get_index('index7')
        index_expr_21 = ops.index_expr(get_index_29, torch.int32)
        lt_4 = ops.lt(index_expr_20, index_expr_21)
        get_index_30 = self.get_index('index8')
        index_expr_22 = ops.index_expr(get_index_30, torch.int32)
        get_index_31 = self.get_index('index9')
        index_expr_23 = ops.index_expr(get_index_31, torch.int32)
        lt_5 = ops.lt(index_expr_22, index_expr_23)
        and__4 = ops.and_(lt_4, lt_5)
        and__5 = ops.and_(and__4, eq_3)
        add_14 = ops.add(where_2, load_7)
        where_3 = ops.where(and__5, add_14, where_2)
        get_index_32 = self.get_index('index15')
        store = ops.store('buf174', get_index_32, where_3, None)
        return store
buf174 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[33554432], 
        filename=__file__,
        triton_meta={'signature': {0: '*i8', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 25690112
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex % 64
        x1 = (xindex // 64) % 112
        x2 = (xindex // 7168) % 112
        x3 = (xindex // 802816)
        x6 = (xindex // 64) % 12544
        x7 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (64*(tl.minimum(tl.maximum(0, (x1 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(tl.maximum(0, (x2 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp12 = tl.load(in_ptr1 + (x0 + (64*(tl.minimum(tl.maximum(0, (x1 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(tl.maximum(0, (x2 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp17 = tl.load(in_ptr0 + (x0 + (64*(tl.minimum(1 + (tl.maximum(0, (x1 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(tl.maximum(0, (x2 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp26 = tl.load(in_ptr1 + (x0 + (64*(tl.minimum(1 + (tl.maximum(0, (x1 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(tl.maximum(0, (x2 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp38 = tl.load(in_ptr0 + (x0 + (64*(tl.minimum(tl.maximum(0, (x1 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(1 + (tl.maximum(0, (x2 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp47 = tl.load(in_ptr1 + (x0 + (64*(tl.minimum(tl.maximum(0, (x1 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(1 + (tl.maximum(0, (x2 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp57 = tl.load(in_ptr0 + (x0 + (64*(tl.minimum(1 + (tl.maximum(0, (x1 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(1 + (tl.maximum(0, (x2 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp65 = tl.load(in_ptr1 + (x0 + (64*(tl.minimum(1 + (tl.maximum(0, (x1 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2)))))) + (3584*(tl.minimum(1 + (tl.maximum(0, (x2 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2)))))) + (200704*x3)), None)
        tmp1 = tl.full([1], 3, tl.int32)
        tmp2 = tl.where((tmp0 < 0) != (tmp1 < 0), tl.where(tmp0 % tmp1 != 0, tmp0 // tmp1 - 1, tmp0 // tmp1), tmp0 // tmp1)
        tmp3 = tmp2 * tmp1
        tmp4 = tmp0 - tmp3
        tmp5 = (-1) + (2*(tl.minimum(tl.maximum(0, (x2 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2))))))
        tmp6 = tmp5 + tmp2
        tmp7 = (-1) + (2*(tl.minimum(tl.maximum(0, (x1 // 2)), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2))))))
        tmp8 = tmp7 + tmp4
        tmp9 = tl.full([1], 112, tl.int64)
        tmp10 = tmp6 * tmp9
        tmp11 = tmp10 + tmp8
        tmp13 = x6
        tmp14 = tmp11 == tmp13
        tmp15 = 0.0
        tmp16 = tl.where(tmp14, tmp12, tmp15)
        tmp18 = tl.where((tmp17 < 0) != (tmp1 < 0), tl.where(tmp17 % tmp1 != 0, tmp17 // tmp1 - 1, tmp17 // tmp1), tmp17 // tmp1)
        tmp19 = tmp18 * tmp1
        tmp20 = tmp17 - tmp19
        tmp21 = tmp5 + tmp18
        tmp22 = (-1) + (2*(tl.minimum(1 + (tl.maximum(0, (x1 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x1) // 2))))))
        tmp23 = tmp22 + tmp20
        tmp24 = tmp21 * tmp9
        tmp25 = tmp24 + tmp23
        tmp27 = tmp25 == tmp13
        tmp28 = tl.maximum(0, (x2 // 2))
        tmp29 = tl.minimum(56, 1 + ((1 + x2) // 2))
        tmp30 = tmp28 < tmp29
        tmp31 = 1 + (tl.maximum(0, (x1 // 2)))
        tmp32 = tl.minimum(56, 1 + ((1 + x1) // 2))
        tmp33 = tmp31 < tmp32
        tmp34 = tmp30 & tmp33
        tmp35 = tmp34 & tmp27
        tmp36 = tmp16 + tmp26
        tmp37 = tl.where(tmp35, tmp36, tmp16)
        tmp39 = tl.where((tmp38 < 0) != (tmp1 < 0), tl.where(tmp38 % tmp1 != 0, tmp38 // tmp1 - 1, tmp38 // tmp1), tmp38 // tmp1)
        tmp40 = tmp39 * tmp1
        tmp41 = tmp38 - tmp40
        tmp42 = (-1) + (2*(tl.minimum(1 + (tl.maximum(0, (x2 // 2))), (-1) + (tl.minimum(56, 1 + ((1 + x2) // 2))))))
        tmp43 = tmp42 + tmp39
        tmp44 = tmp7 + tmp41
        tmp45 = tmp43 * tmp9
        tmp46 = tmp45 + tmp44
        tmp48 = tmp46 == tmp13
        tmp49 = 1 + (tl.maximum(0, (x2 // 2)))
        tmp50 = tmp49 < tmp29
        tmp51 = tl.maximum(0, (x1 // 2))
        tmp52 = tmp51 < tmp32
        tmp53 = tmp50 & tmp52
        tmp54 = tmp53 & tmp48
        tmp55 = tmp37 + tmp47
        tmp56 = tl.where(tmp54, tmp55, tmp37)
        tmp58 = tl.where((tmp57 < 0) != (tmp1 < 0), tl.where(tmp57 % tmp1 != 0, tmp57 // tmp1 - 1, tmp57 // tmp1), tmp57 // tmp1)
        tmp59 = tmp58 * tmp1
        tmp60 = tmp57 - tmp59
        tmp61 = tmp42 + tmp58
        tmp62 = tmp22 + tmp60
        tmp63 = tmp61 * tmp9
        tmp64 = tmp63 + tmp62
        tmp66 = tmp64 == tmp13
        tmp67 = tmp50 & tmp33
        tmp68 = tmp67 & tmp66
        tmp69 = tmp56 + tmp65
        tmp70 = tl.where(tmp68, tmp69, tmp56)
        tl.store(out_ptr0 + (x7), tmp70, None)


buf175: SchedulerNode(ComputedBuffer)
buf175.writes = [MemoryDep('buf175', c0, {c0: 32768}, None)]
buf175.unmet_dependencies = [   MemoryDep('buf174', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None)]
buf175.met_dependencies = [   MemoryDep('relu', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None)]
buf175.users = [NodeUser(node=SchedulerNode(name='buf176'), can_inplace=False, is_weak=False)]
buf175.group.device = cuda:0
buf175.group.iteration = (32768, 784)
buf175.sizes = ([512, 64], [784])
buf174_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
relu_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
buf175_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf175_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 784}
    index0 = z1 + 7168*(((784*z0 + z2)//112)) + 64*ModularIndexing(z2, 1, 112)
    index1 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf174', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where)
        get_index_2 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf175', get_index_2, reduction)
        return store_reduction
buf175 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 1024],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 784
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
            tmp7 = _tmp6 + tmp5
            _tmp6 = tl.where(rmask, tmp7, _tmp6)
        tmp6 = tl.sum(_tmp6, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp6, None)


buf176: SchedulerNode(ComputedBuffer)
buf176.writes = [MemoryDep('buf176', c0, {c0: 64}, None)]
buf176.unmet_dependencies = [MemoryDep('buf175', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf176.met_dependencies = []
buf176.users = [NodeUser(node=SchedulerNode(name='buf180'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf176.group.device = cuda:0
buf176.group.iteration = (64, 512)
buf176.sizes = ([64], [512])
buf175_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf176_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf176_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf175', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf176', get_index_1, reduction)
        return store_reduction
buf176 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf177: SchedulerNode(ComputedBuffer)
buf177.writes = [MemoryDep('buf177', c0, {c0: 32768}, None)]
buf177.unmet_dependencies = [   MemoryDep('buf174', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None)]
buf177.met_dependencies = 
    [   MemoryDep('convolution', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None),
        MemoryDep('relu', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None),
        MemoryDep('unsqueeze_310', c1, {c0: 512, c1: 64}, None)]
buf177.users = [NodeUser(node=SchedulerNode(name='buf178'), can_inplace=False, is_weak=False)]
buf177.group.device = cuda:0
buf177.group.iteration = (32768, 784)
buf177.sizes = ([512, 64], [784])
unsqueeze_310_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
buf174_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
convolution_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
relu_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
buf177_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
class buf177_loop_body:
    var_ranges = {z0: 512, z1: 64, z2: 784}
    index0 = z1 + 7168*(((784*z0 + z2)//112)) + 64*ModularIndexing(z2, 1, 112)
    index1 = z1
    index2 = 64*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf174', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_310', get_index_3)
        sub = ops.sub(load_2, load_3)
        mul = ops.mul(where, sub)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul)
        get_index_4 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf177', get_index_4, reduction)
        return store_reduction
buf177 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 1024],
        reduction_hint=ReductionHint.OUTER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 784
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex % 64
        x1 = (xindex // 64)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        x3 = xindex
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r2 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
            tmp3 = tl.load(in_ptr1 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
            tmp5 = tl.load(in_ptr2 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tmp4 = tl.where(tmp2, tmp1, tmp3)
            tmp7 = tmp5 - tmp6
            tmp8 = tmp4 * tmp7
            tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
            tmp11 = _tmp10 + tmp9
            _tmp10 = tl.where(rmask, tmp11, _tmp10)
        tmp10 = tl.sum(_tmp10, 1)[:, None]
        tl.store(out_ptr0 + (x3), tmp10, None)


buf178: SchedulerNode(ComputedBuffer)
buf178.writes = [MemoryDep('buf178', c0, {c0: 64}, None)]
buf178.unmet_dependencies = [MemoryDep('buf177', c0 + 64*c1, {c0: 64, c1: 512}, None)]
buf178.met_dependencies = []
buf178.users = [NodeUser(node=SchedulerNode(name='buf179'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf180'), can_inplace=False, is_weak=False)]
buf178.group.device = cuda:0
buf178.group.iteration = (64, 512)
buf178.sizes = ([64], [512])
buf177_layout = FixedLayout('cuda', torch.float32, size=[64, 512], stride=[1, 64])
buf178_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf178_loop_body:
    var_ranges = {z0: 64, z1: 512}
    index0 = z0 + 64*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf177', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf178', get_index_1, reduction)
        return store_reduction
buf178 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[64, 512],
        reduction_hint=ReductionHint.OUTER_TINY,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 64
        rnumel = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf179: SchedulerNode(ComputedBuffer)
buf179.writes = [MemoryDep('buf179', c0, {c0: 64}, None)]
buf179.unmet_dependencies = [MemoryDep('buf178', c0, {c0: 64}, None)]
buf179.met_dependencies = [MemoryDep('squeeze_1', c0, {c0: 64}, None)]
buf179.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf179.group.device = cuda:0
buf179.group.iteration = (64, 1)
buf179.sizes = ([64], [])
squeeze_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf178_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf179_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
class buf179_loop_body:
    var_ranges = {z0: 64}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf178', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('squeeze_1', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf179', get_index_2, mul, None)
        return store
buf179 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[64], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 64
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf180: SchedulerNode(ComputedBuffer)
buf180.writes = [MemoryDep('buf180', c0, {c0: 25690112}, None)]
buf180.unmet_dependencies = 
    [   MemoryDep('buf174', c0, {c0: 25690112}, None),
        MemoryDep('buf176', c1, {c0: 401408, c1: 64}, None),
        MemoryDep('buf178', c1, {c0: 401408, c1: 64}, None)]
buf180.met_dependencies = 
    [   MemoryDep('convolution', c0, {c0: 25690112}, None),
        MemoryDep('primals_2', c1, {c0: 401408, c1: 64}, None),
        MemoryDep('relu', c0, {c0: 25690112}, None),
        MemoryDep('squeeze_1', c1, {c0: 401408, c1: 64}, None),
        MemoryDep('unsqueeze_310', c1, {c0: 401408, c1: 64}, None)]
buf180.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf181'), can_inplace=False, is_weak=False)]
buf180.group.device = cuda:0
buf180.group.iteration = (25690112, 1)
buf180.sizes = ([401408, 64], [])
convolution_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
buf176_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
unsqueeze_310_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 1, 1])
relu_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
buf178_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
primals_2_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
squeeze_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf174_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
buf180_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
class buf180_loop_body:
    var_ranges = {z0: 401408, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf174', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('convolution', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('unsqueeze_310', get_index_3)
        sub = ops.sub(load_2, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('buf178', get_index_4)
        constant_2 = ops.constant(2.4912308673469386e-06, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('squeeze_1', get_index_5)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('squeeze_1', get_index_6)
        mul_1 = ops.mul(load_5, load_6)
        mul_2 = ops.mul(mul, mul_1)
        mul_3 = ops.mul(sub, mul_2)
        sub_1 = ops.sub(where, mul_3)
        get_index_7 = self.get_index('index1')
        load_7 = ops.load('buf176', get_index_7)
        constant_3 = ops.constant(2.4912308673469386e-06, torch.float32)
        mul_4 = ops.mul(load_7, constant_3)
        sub_2 = ops.sub(sub_1, mul_4)
        get_index_8 = self.get_index('index1')
        load_8 = ops.load('squeeze_1', get_index_8)
        get_index_9 = self.get_index('index1')
        load_9 = ops.load('primals_2', get_index_9)
        mul_5 = ops.mul(load_8, load_9)
        mul_6 = ops.mul(sub_2, mul_5)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf180', get_index_10, mul_6, None)
        return store
buf180 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[33554432], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 25690112
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp3 = tl.load(in_ptr1 + (x2), None)
        tmp5 = tl.load(in_ptr2 + (x2), None)
        tmp6 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
        tmp16 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
        tmp19 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp7 = tmp5 - tmp6
        tmp9 = 2.4912308673469386e-06
        tmp10 = tmp8 * tmp9
        tmp12 = tmp11 * tmp11
        tmp13 = tmp10 * tmp12
        tmp14 = tmp7 * tmp13
        tmp15 = tmp4 - tmp14
        tmp17 = tmp16 * tmp9
        tmp18 = tmp15 - tmp17
        tmp20 = tmp11 * tmp19
        tmp21 = tmp18 * tmp20
        tl.store(out_ptr0 + (x2), tmp21, None)


buf181: ExternKernelSchedulerNode(FallbackKernel)
buf181.writes = [StarDep(name='buf181', mode=None)]
buf181.unmet_dependencies = [StarDep(name='buf180', mode=None)]
buf181.met_dependencies = [StarDep(name='primals_1', mode=None), StarDep(name='primals_123', mode=None)]
buf181.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf182'), can_inplace=False, is_weak=False)]
buf181.node.kernel = None


buf182: ExternKernelSchedulerNode(MultiOutput)
buf182.writes = [StarDep(name='buf182', mode=None)]
buf182.unmet_dependencies = [StarDep(name='buf181', mode=None)]
buf182.met_dependencies = []
buf182.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf182.node.kernel = None


