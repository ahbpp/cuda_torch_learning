buf0: SchedulerNode(ComputedBuffer)
buf0.writes = [MemoryDep('buf0', 147*c0 + c1 + 3*c2, {c0: 64, c1: 3, c2: 49}, None)]
buf0.unmet_dependencies = []
buf0.met_dependencies = [MemoryDep('primals_1', c0, {c0: 9408}, None)]
buf0.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf18'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf0.group.device = cuda:0
buf0.group.iteration = (9408, 1)
buf0.sizes = ([64, 3, 49], [])
primals_1_layout = FixedLayout('cuda', torch.float32, size=[64, 3, 7, 7], stride=[147, 49, 7, 1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[64, 3, 7, 7], stride=[147, 1, 21, 3])
class buf0_loop_body:
    var_ranges = {z0: 64, z1: 3, z2: 49}
    index0 = 147*z0 + 49*z1 + z2
    index1 = 147*z0 + z1 + 3*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_1', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf0', get_index_1, load, None)
        return store
buf0 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[256, 64], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 192
        xnumel = 49
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 3
        y1 = (yindex // 3)
        tmp0 = tl.load(in_ptr0 + (x2 + (49*y3)), xmask & ymask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (3*x2) + (147*y1)), tmp0, xmask & ymask)


buf1: SchedulerNode(ComputedBuffer)
buf1.writes = [MemoryDep('buf1', 576*c0 + c1 + 64*c2, {c0: 64, c1: 64, c2: 9}, None)]
buf1.unmet_dependencies = []
buf1.met_dependencies = [MemoryDep('primals_4', c0, {c0: 36864}, None)]
buf1.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf32'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf1.group.device = cuda:0
buf1.group.iteration = (36864, 1)
buf1.sizes = ([64, 64, 9], [])
primals_4_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 9, 3, 1])
buf1_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 1, 192, 64])
class buf1_loop_body:
    var_ranges = {z0: 64, z1: 64, z2: 9}
    index0 = 576*z0 + 9*z1 + z2
    index1 = 576*z0 + z1 + 64*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_4', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf1', get_index_1, load, None)
        return store
buf1 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4096, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 4096
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 64
        y1 = (yindex // 64)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)


buf2: SchedulerNode(ComputedBuffer)
buf2.writes = [MemoryDep('buf2', 576*c0 + c1 + 64*c2, {c0: 64, c1: 64, c2: 9}, None)]
buf2.unmet_dependencies = []
buf2.met_dependencies = [MemoryDep('primals_7', c0, {c0: 36864}, None)]
buf2.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf44'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf2.group.device = cuda:0
buf2.group.iteration = (36864, 1)
buf2.sizes = ([64, 64, 9], [])
primals_7_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 9, 3, 1])
buf2_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 1, 192, 64])
class buf2_loop_body:
    var_ranges = {z0: 64, z1: 64, z2: 9}
    index0 = 576*z0 + 9*z1 + z2
    index1 = 576*z0 + z1 + 64*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf2', get_index_1, load, None)
        return store
buf2 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4096, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 4096
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 64
        y1 = (yindex // 64)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)


buf3: SchedulerNode(ComputedBuffer)
buf3.writes = [MemoryDep('buf3', 576*c0 + c1 + 64*c2, {c0: 64, c1: 64, c2: 9}, None)]
buf3.unmet_dependencies = []
buf3.met_dependencies = [MemoryDep('primals_10', c0, {c0: 36864}, None)]
buf3.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf56'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf3.group.device = cuda:0
buf3.group.iteration = (36864, 1)
buf3.sizes = ([64, 64, 9], [])
primals_10_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 9, 3, 1])
buf3_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 1, 192, 64])
class buf3_loop_body:
    var_ranges = {z0: 64, z1: 64, z2: 9}
    index0 = 576*z0 + 9*z1 + z2
    index1 = 576*z0 + z1 + 64*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_10', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf3', get_index_1, load, None)
        return store
buf3 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4096, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 4096
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 64
        y1 = (yindex // 64)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)


buf4: SchedulerNode(ComputedBuffer)
buf4.writes = [MemoryDep('buf4', 576*c0 + c1 + 64*c2, {c0: 64, c1: 64, c2: 9}, None)]
buf4.unmet_dependencies = []
buf4.met_dependencies = [MemoryDep('primals_13', c0, {c0: 36864}, None)]
buf4.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf68'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf4.group.device = cuda:0
buf4.group.iteration = (36864, 1)
buf4.sizes = ([64, 64, 9], [])
primals_13_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 9, 3, 1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[64, 64, 3, 3], stride=[576, 1, 192, 64])
class buf4_loop_body:
    var_ranges = {z0: 64, z1: 64, z2: 9}
    index0 = 576*z0 + 9*z1 + z2
    index1 = 576*z0 + z1 + 64*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_13', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf4', get_index_1, load, None)
        return store
buf4 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4096, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 4096
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 64
        y1 = (yindex // 64)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)


buf5: SchedulerNode(ComputedBuffer)
buf5.writes = [MemoryDep('buf5', 576*c0 + c1 + 64*c2, {c0: 128, c1: 64, c2: 9}, None)]
buf5.unmet_dependencies = []
buf5.met_dependencies = [MemoryDep('primals_16', c0, {c0: 73728}, None)]
buf5.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf80'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf5.group.device = cuda:0
buf5.group.iteration = (73728, 1)
buf5.sizes = ([128, 64, 9], [])
primals_16_layout = FixedLayout('cuda', torch.float32, size=[128, 64, 3, 3], stride=[576, 9, 3, 1])
buf5_layout = FixedLayout('cuda', torch.float32, size=[128, 64, 3, 3], stride=[576, 1, 192, 64])
class buf5_loop_body:
    var_ranges = {z0: 128, z1: 64, z2: 9}
    index0 = 576*z0 + 9*z1 + z2
    index1 = 576*z0 + z1 + 64*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_16', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf5', get_index_1, load, None)
        return store
buf5 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8192, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 8192
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 64
        y1 = (yindex // 64)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)


buf6: SchedulerNode(ComputedBuffer)
buf6.writes = [MemoryDep('buf6', 1152*c0 + c1 + 128*c2, {c0: 128, c1: 128, c2: 9}, None)]
buf6.unmet_dependencies = []
buf6.met_dependencies = [MemoryDep('primals_19', c0, {c0: 147456}, None)]
buf6.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf92'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf6.group.device = cuda:0
buf6.group.iteration = (147456, 1)
buf6.sizes = ([128, 128, 9], [])
primals_19_layout = FixedLayout('cuda', torch.float32, size=[128, 128, 3, 3], stride=[1152, 9, 3, 1])
buf6_layout = FixedLayout('cuda', torch.float32, size=[128, 128, 3, 3], stride=[1152, 1, 384, 128])
class buf6_loop_body:
    var_ranges = {z0: 128, z1: 128, z2: 9}
    index0 = 1152*z0 + 9*z1 + z2
    index1 = 1152*z0 + z1 + 128*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_19', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf6', get_index_1, load, None)
        return store
buf6 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[16384, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 16384
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 128
        y1 = (yindex // 128)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (128*x2) + (1152*y1)), tmp0, xmask)


buf7: SchedulerNode(ComputedBuffer)
buf7.writes = [MemoryDep('buf7', 1152*c0 + c1 + 128*c2, {c0: 128, c1: 128, c2: 9}, None)]
buf7.unmet_dependencies = []
buf7.met_dependencies = [MemoryDep('primals_25', c0, {c0: 147456}, None)]
buf7.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf116'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf7.group.device = cuda:0
buf7.group.iteration = (147456, 1)
buf7.sizes = ([128, 128, 9], [])
primals_25_layout = FixedLayout('cuda', torch.float32, size=[128, 128, 3, 3], stride=[1152, 9, 3, 1])
buf7_layout = FixedLayout('cuda', torch.float32, size=[128, 128, 3, 3], stride=[1152, 1, 384, 128])
class buf7_loop_body:
    var_ranges = {z0: 128, z1: 128, z2: 9}
    index0 = 1152*z0 + 9*z1 + z2
    index1 = 1152*z0 + z1 + 128*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_25', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf7', get_index_1, load, None)
        return store
buf7 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[16384, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 16384
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 128
        y1 = (yindex // 128)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (128*x2) + (1152*y1)), tmp0, xmask)


buf8: SchedulerNode(ComputedBuffer)
buf8.writes = [MemoryDep('buf8', 1152*c0 + c1 + 128*c2, {c0: 128, c1: 128, c2: 9}, None)]
buf8.unmet_dependencies = []
buf8.met_dependencies = [MemoryDep('primals_28', c0, {c0: 147456}, None)]
buf8.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf128'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf8.group.device = cuda:0
buf8.group.iteration = (147456, 1)
buf8.sizes = ([128, 128, 9], [])
primals_28_layout = FixedLayout('cuda', torch.float32, size=[128, 128, 3, 3], stride=[1152, 9, 3, 1])
buf8_layout = FixedLayout('cuda', torch.float32, size=[128, 128, 3, 3], stride=[1152, 1, 384, 128])
class buf8_loop_body:
    var_ranges = {z0: 128, z1: 128, z2: 9}
    index0 = 1152*z0 + 9*z1 + z2
    index1 = 1152*z0 + z1 + 128*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_28', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf8', get_index_1, load, None)
        return store
buf8 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[16384, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 16384
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 128
        y1 = (yindex // 128)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (128*x2) + (1152*y1)), tmp0, xmask)


buf9: SchedulerNode(ComputedBuffer)
buf9.writes = [MemoryDep('buf9', 1152*c0 + c1 + 128*c2, {c0: 256, c1: 128, c2: 9}, None)]
buf9.unmet_dependencies = []
buf9.met_dependencies = [MemoryDep('primals_31', c0, {c0: 294912}, None)]
buf9.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf140'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf9.group.device = cuda:0
buf9.group.iteration = (294912, 1)
buf9.sizes = ([256, 128, 9], [])
primals_31_layout = FixedLayout('cuda', torch.float32, size=[256, 128, 3, 3], stride=[1152, 9, 3, 1])
buf9_layout = FixedLayout('cuda', torch.float32, size=[256, 128, 3, 3], stride=[1152, 1, 384, 128])
class buf9_loop_body:
    var_ranges = {z0: 256, z1: 128, z2: 9}
    index0 = 1152*z0 + 9*z1 + z2
    index1 = 1152*z0 + z1 + 128*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_31', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf9', get_index_1, load, None)
        return store
buf9 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[32768, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 32768
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 128
        y1 = (yindex // 128)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (128*x2) + (1152*y1)), tmp0, xmask)


buf10: SchedulerNode(ComputedBuffer)
buf10.writes = [MemoryDep('buf10', 2304*c0 + c1 + 256*c2, {c0: 256, c1: 256, c2: 9}, None)]
buf10.unmet_dependencies = []
buf10.met_dependencies = [MemoryDep('primals_34', c0, {c0: 589824}, None)]
buf10.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf149'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf10.group.device = cuda:0
buf10.group.iteration = (589824, 1)
buf10.sizes = ([256, 256, 9], [])
primals_34_layout = FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 9, 3, 1])
buf10_layout = FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 1, 768, 256])
class buf10_loop_body:
    var_ranges = {z0: 256, z1: 256, z2: 9}
    index0 = 2304*z0 + 9*z1 + z2
    index1 = 2304*z0 + z1 + 256*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_34', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf10', get_index_1, load, None)
        return store
buf10 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[65536, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 65536
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 256
        y1 = (yindex // 256)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (256*x2) + (2304*y1)), tmp0, xmask)


buf11: SchedulerNode(ComputedBuffer)
buf11.writes = [MemoryDep('buf11', 2304*c0 + c1 + 256*c2, {c0: 256, c1: 256, c2: 9}, None)]
buf11.unmet_dependencies = []
buf11.met_dependencies = [MemoryDep('primals_40', c0, {c0: 589824}, None)]
buf11.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf167'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf11.group.device = cuda:0
buf11.group.iteration = (589824, 1)
buf11.sizes = ([256, 256, 9], [])
primals_40_layout = FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 9, 3, 1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 1, 768, 256])
class buf11_loop_body:
    var_ranges = {z0: 256, z1: 256, z2: 9}
    index0 = 2304*z0 + 9*z1 + z2
    index1 = 2304*z0 + z1 + 256*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_40', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf11', get_index_1, load, None)
        return store
buf11 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[65536, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 65536
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 256
        y1 = (yindex // 256)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (256*x2) + (2304*y1)), tmp0, xmask)


buf12: SchedulerNode(ComputedBuffer)
buf12.writes = [MemoryDep('buf12', 2304*c0 + c1 + 256*c2, {c0: 256, c1: 256, c2: 9}, None)]
buf12.unmet_dependencies = []
buf12.met_dependencies = [MemoryDep('primals_43', c0, {c0: 589824}, None)]
buf12.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf176'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf12.group.device = cuda:0
buf12.group.iteration = (589824, 1)
buf12.sizes = ([256, 256, 9], [])
primals_43_layout = FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 9, 3, 1])
buf12_layout = FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 1, 768, 256])
class buf12_loop_body:
    var_ranges = {z0: 256, z1: 256, z2: 9}
    index0 = 2304*z0 + 9*z1 + z2
    index1 = 2304*z0 + z1 + 256*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_43', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf12', get_index_1, load, None)
        return store
buf12 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[65536, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 65536
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 256
        y1 = (yindex // 256)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (256*x2) + (2304*y1)), tmp0, xmask)


buf13: SchedulerNode(ComputedBuffer)
buf13.writes = [MemoryDep('buf13', 2304*c0 + c1 + 256*c2, {c0: 512, c1: 256, c2: 9}, None)]
buf13.unmet_dependencies = []
buf13.met_dependencies = [MemoryDep('primals_46', c0, {c0: 1179648}, None)]
buf13.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf185'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf13.group.device = cuda:0
buf13.group.iteration = (1179648, 1)
buf13.sizes = ([512, 256, 9], [])
primals_46_layout = FixedLayout('cuda', torch.float32, size=[512, 256, 3, 3], stride=[2304, 9, 3, 1])
buf13_layout = FixedLayout('cuda', torch.float32, size=[512, 256, 3, 3], stride=[2304, 1, 768, 256])
class buf13_loop_body:
    var_ranges = {z0: 512, z1: 256, z2: 9}
    index0 = 2304*z0 + 9*z1 + z2
    index1 = 2304*z0 + z1 + 256*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_46', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf13', get_index_1, load, None)
        return store
buf13 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[131072, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 131072
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 256
        y1 = (yindex // 256)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (256*x2) + (2304*y1)), tmp0, xmask)


buf14: SchedulerNode(ComputedBuffer)
buf14.writes = [MemoryDep('buf14', 4608*c0 + c1 + 512*c2, {c0: 512, c1: 512, c2: 9}, None)]
buf14.unmet_dependencies = []
buf14.met_dependencies = [MemoryDep('primals_49', c0, {c0: 2359296}, None)]
buf14.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf194'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf14.group.device = cuda:0
buf14.group.iteration = (2359296, 1)
buf14.sizes = ([512, 512, 9], [])
primals_49_layout = FixedLayout('cuda', torch.float32, size=[512, 512, 3, 3], stride=[4608, 9, 3, 1])
buf14_layout = FixedLayout('cuda', torch.float32, size=[512, 512, 3, 3], stride=[4608, 1, 1536, 512])
class buf14_loop_body:
    var_ranges = {z0: 512, z1: 512, z2: 9}
    index0 = 4608*z0 + 9*z1 + z2
    index1 = 4608*z0 + z1 + 512*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_49', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf14', get_index_1, load, None)
        return store
buf14 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[262144, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 262144
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 512
        y1 = (yindex // 512)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (512*x2) + (4608*y1)), tmp0, xmask)


buf15: SchedulerNode(ComputedBuffer)
buf15.writes = [MemoryDep('buf15', 4608*c0 + c1 + 512*c2, {c0: 512, c1: 512, c2: 9}, None)]
buf15.unmet_dependencies = []
buf15.met_dependencies = [MemoryDep('primals_55', c0, {c0: 2359296}, None)]
buf15.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf212'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf15.group.device = cuda:0
buf15.group.iteration = (2359296, 1)
buf15.sizes = ([512, 512, 9], [])
primals_55_layout = FixedLayout('cuda', torch.float32, size=[512, 512, 3, 3], stride=[4608, 9, 3, 1])
buf15_layout = FixedLayout('cuda', torch.float32, size=[512, 512, 3, 3], stride=[4608, 1, 1536, 512])
class buf15_loop_body:
    var_ranges = {z0: 512, z1: 512, z2: 9}
    index0 = 4608*z0 + 9*z1 + z2
    index1 = 4608*z0 + z1 + 512*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_55', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf15', get_index_1, load, None)
        return store
buf15 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[262144, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 262144
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 512
        y1 = (yindex // 512)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (512*x2) + (4608*y1)), tmp0, xmask)


buf16: SchedulerNode(ComputedBuffer)
buf16.writes = [MemoryDep('buf16', 4608*c0 + c1 + 512*c2, {c0: 512, c1: 512, c2: 9}, None)]
buf16.unmet_dependencies = []
buf16.met_dependencies = [MemoryDep('primals_58', c0, {c0: 2359296}, None)]
buf16.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf221'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf16.group.device = cuda:0
buf16.group.iteration = (2359296, 1)
buf16.sizes = ([512, 512, 9], [])
primals_58_layout = FixedLayout('cuda', torch.float32, size=[512, 512, 3, 3], stride=[4608, 9, 3, 1])
buf16_layout = FixedLayout('cuda', torch.float32, size=[512, 512, 3, 3], stride=[4608, 1, 1536, 512])
class buf16_loop_body:
    var_ranges = {z0: 512, z1: 512, z2: 9}
    index0 = 4608*z0 + 9*z1 + z2
    index1 = 4608*z0 + z1 + 512*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_58', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf16', get_index_1, load, None)
        return store
buf16 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[262144, 16], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 262144
        xnumel = 9
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 512
        y1 = (yindex // 512)
        tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (512*x2) + (4608*y1)), tmp0, xmask)


buf17: SchedulerNode(ComputedBuffer)
buf17.writes = [MemoryDep('buf17', 150528*c0 + c1 + 3*c2, {c0: 32, c1: 3, c2: 50176}, None)]
buf17.unmet_dependencies = []
buf17.met_dependencies = [MemoryDep('primals_123', c0, {c0: 4816896}, None)]
buf17.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf18'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf17.group.device = cuda:0
buf17.group.iteration = (4816896, 1)
buf17.sizes = ([32, 3, 50176], [])
primals_123_layout = FixedLayout('cuda', torch.float32, size=[32, 3, 224, 224], stride=[150528, 50176, 224, 1])
buf17_layout = FixedLayout('cuda', torch.float32, size=[32, 3, 224, 224], stride=[150528, 1, 672, 3])
class buf17_loop_body:
    var_ranges = {z0: 32, z1: 3, z2: 50176}
    index0 = 150528*z0 + 50176*z1 + z2
    index1 = 150528*z0 + z1 + 3*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_123', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf17', get_index_1, load, None)
        return store
buf17 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128, 65536], tile_hint=TileHint.SQUARE,
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 96
        xnumel = 50176
        yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = yindex < ynumel
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y3 = yindex
        y0 = yindex % 3
        y1 = (yindex // 3)
        tmp0 = tl.load(in_ptr0 + (x2 + (50176*y3)), xmask & ymask, eviction_policy='evict_last')
        tl.store(out_ptr0 + (y0 + (3*x2) + (150528*y1)), tmp0, xmask & ymask)


buf18: ExternKernelSchedulerNode(ExternKernelAlloc)
buf18.writes = [StarDep(name='buf18', mode=None)]
buf18.unmet_dependencies = [StarDep(name='buf0', mode=None), StarDep(name='buf17', mode=None)]
buf18.met_dependencies = []
buf18.users = [NodeUser(node=SchedulerNode(name='buf19'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf20'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf21'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf29'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf18.node.kernel = extern_kernels.convolution


buf19_buf20_buf21: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf19_buf20_buf21.writes = 
    [   MemoryDep('buf19', c0, {c0: 32768}, None),
        MemoryDep('buf20', c0, {c0: 32768}, None),
        MemoryDep('buf21', c0, {c0: 32768}, None)]
buf19_buf20_buf21.unmet_dependencies = [   MemoryDep('buf18', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None)]
buf19_buf20_buf21.met_dependencies = []
buf19_buf20_buf21.users = []
    buf19_buf20_buf21.snodes[0] =
    buf19: SchedulerNode(ComputedBuffer)
    buf19.writes = [MemoryDep('buf19', c0, {c0: 32768}, None)]
    buf19.unmet_dependencies = [   MemoryDep('buf18', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None)]
    buf19.met_dependencies = []
    buf19.users = [NodeUser(node=SchedulerNode(name='buf22'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf23'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf24'), can_inplace=False, is_weak=False)]
    buf19.group.device = cuda:0
    buf19.group.iteration = (32768, 784)
    buf19.sizes = ([512, 64], [784])
    buf18_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf19_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf19_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 784}
        index0 = z1 + 7168*(((784*z0 + z2)//112)) + 64*ModularIndexing(z2, 1, 112)
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf18', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf19', get_index_1, getitem)
            return store_reduction
    buf19 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 1024],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 784
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
    buf19_buf20_buf21.snodes[1] =
    buf20: SchedulerNode(ComputedBuffer)
    buf20.writes = [MemoryDep('buf20', c0, {c0: 32768}, None)]
    buf20.unmet_dependencies = [   MemoryDep('buf18', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None)]
    buf20.met_dependencies = []
    buf20.users = [NodeUser(node=SchedulerNode(name='buf22'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf23'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf24'), can_inplace=False, is_weak=False)]
    buf20.group.device = cuda:0
    buf20.group.iteration = (32768, 784)
    buf20.sizes = ([512, 64], [784])
    buf18_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf20_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf20_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 784}
        index0 = z1 + 7168*(((784*z0 + z2)//112)) + 64*ModularIndexing(z2, 1, 112)
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf18', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf20', get_index_1, getitem_1)
            return store_reduction
    buf20 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 1024],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 784
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, None)
    buf19_buf20_buf21.snodes[2] =
    buf21: SchedulerNode(ComputedBuffer)
    buf21.writes = [MemoryDep('buf21', c0, {c0: 32768}, None)]
    buf21.unmet_dependencies = [   MemoryDep('buf18', c1 + 7168*(((784*c0 + c2)//112)) + 64*ModularIndexing(c2, 1, 112), {c0: 512, c1: 64, c2: 784}, None)]
    buf21.met_dependencies = []
    buf21.users = [NodeUser(node=SchedulerNode(name='buf22'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf23'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf24'), can_inplace=False, is_weak=False)]
    buf21.group.device = cuda:0
    buf21.group.iteration = (32768, 784)
    buf21.sizes = ([512, 64], [784])
    buf18_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf21_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf21_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 784}
        index0 = z1 + 7168*(((784*z0 + z2)//112)) + 64*ModularIndexing(z2, 1, 112)
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf18', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf21', get_index_1, getitem_2)
            return store_reduction
    buf21 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 1024],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 784
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, None)
    buf19_buf20_buf21 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 1024],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 784
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*(r2 % 112)) + (7168*((r2 + (784*x1)) // 112))), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
            tl.store(out_ptr1 + (x3), tmp3, None)
            tl.store(out_ptr2 + (x3), tmp4, None)


buf22_buf23_buf24: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf22_buf23_buf24.writes = 
    [   MemoryDep('buf22', c0, {c0: 256}, None),
        MemoryDep('buf23', c0, {c0: 256}, None),
        MemoryDep('buf24', c0, {c0: 256}, None)]
buf22_buf23_buf24.unmet_dependencies = 
    [   MemoryDep('buf19', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf20', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf21', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
buf22_buf23_buf24.met_dependencies = []
buf22_buf23_buf24.users = []
    buf22_buf23_buf24.snodes[0] =
    buf22: SchedulerNode(ComputedBuffer)
    buf22.writes = [MemoryDep('buf22', c0, {c0: 256}, None)]
    buf22.unmet_dependencies = 
        [   MemoryDep('buf19', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf20', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf21', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf22.met_dependencies = []
    buf22.users = [NodeUser(node=SchedulerNode(name='buf25'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf26'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf27'), can_inplace=False, is_weak=False)]
    buf22.group.device = cuda:0
    buf22.group.iteration = (256, 128)
    buf22.sizes = ([4, 64], [128])
    buf19_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf20_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf21_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf22_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf22_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf19', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf20', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf21', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf22', get_index_3, getitem)
            return store_reduction
    buf22 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf22_buf23_buf24.snodes[1] =
    buf23: SchedulerNode(ComputedBuffer)
    buf23.writes = [MemoryDep('buf23', c0, {c0: 256}, None)]
    buf23.unmet_dependencies = 
        [   MemoryDep('buf19', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf20', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf21', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf23.met_dependencies = []
    buf23.users = [NodeUser(node=SchedulerNode(name='buf25'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf26'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf27'), can_inplace=False, is_weak=False)]
    buf23.group.device = cuda:0
    buf23.group.iteration = (256, 128)
    buf23.sizes = ([4, 64], [128])
    buf19_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf20_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf21_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf23_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf23_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf19', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf20', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf21', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf23', get_index_3, getitem_1)
            return store_reduction
    buf23 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf22_buf23_buf24.snodes[2] =
    buf24: SchedulerNode(ComputedBuffer)
    buf24.writes = [MemoryDep('buf24', c0, {c0: 256}, None)]
    buf24.unmet_dependencies = 
        [   MemoryDep('buf19', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf20', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf21', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf24.met_dependencies = []
    buf24.users = [NodeUser(node=SchedulerNode(name='buf25'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf26'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf27'), can_inplace=False, is_weak=False)]
    buf24.group.device = cuda:0
    buf24.group.iteration = (256, 128)
    buf24.sizes = ([4, 64], [128])
    buf19_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf20_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf21_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf24_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf24_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf19', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf20', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf21', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf24', get_index_3, getitem_2)
            return store_reduction
    buf24 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf22_buf23_buf24 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf25_buf26_buf28_buf235_buf236_buf238_buf239: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf25_buf26_buf28_buf235_buf236_buf238_buf239.writes = 
    [   MemoryDep('buf235', c0, {c0: 64}, None),
        MemoryDep('buf236', c0, {c0: 64}, None),
        MemoryDep('buf238', c0, {c0: 64}, None),
        MemoryDep('buf239', c0, {c0: 64}, None),
        MemoryDep('buf25', c0, {c0: 64}, None),
        MemoryDep('buf26', c0, {c0: 64}, None),
        MemoryDep('buf28', c0, {c0: 64}, None)]
buf25_buf26_buf28_buf235_buf236_buf238_buf239.unmet_dependencies = 
    [   MemoryDep('buf22', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf23', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf24', c0 + 64*c1, {c0: 64, c1: 4}, None)]
buf25_buf26_buf28_buf235_buf236_buf238_buf239.met_dependencies = 
    [   MemoryDep('primals_63', c0, {c0: 64}, None),
        MemoryDep('primals_64', c0, {c0: 64}, None),
        StarDep(name='primals_63', mode=None),
        StarDep(name='primals_64', mode=None)]
buf25_buf26_buf28_buf235_buf236_buf238_buf239.users = []
    buf25_buf26_buf28_buf235_buf236_buf238_buf239.snodes[0] =
    buf25: SchedulerNode(ComputedBuffer)
    buf25.writes = [MemoryDep('buf25', c0, {c0: 64}, None)]
    buf25.unmet_dependencies = 
        [   MemoryDep('buf22', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf23', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf24', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf25.met_dependencies = []
    buf25.users = [NodeUser(node=SchedulerNode(name='buf29'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf235'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf25.group.device = cuda:0
    buf25.group.iteration = (64, 4)
    buf25.sizes = ([64], [4])
    buf22_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf24_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf23_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf25_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf25_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf22', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf23', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf24', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf25', get_index_3, getitem)
            return store_reduction
    buf25 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf25_buf26_buf28_buf235_buf236_buf238_buf239.snodes[1] =
    buf26: SchedulerNode(ComputedBuffer)
    buf26.writes = [MemoryDep('buf26', c0, {c0: 64}, None)]
    buf26.unmet_dependencies = 
        [   MemoryDep('buf22', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf23', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf24', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf26.met_dependencies = []
    buf26.users = [NodeUser(node=SchedulerNode(name='buf28'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf29'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf238'), can_inplace=True, is_weak=False)]
    buf26.group.device = cuda:0
    buf26.group.iteration = (64, 4)
    buf26.sizes = ([64], [4])
    buf22_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf24_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf23_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf26_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf26_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf22', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf23', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf24', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf26', get_index_3, getitem_1)
            return store_reduction
    buf26 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf25_buf26_buf28_buf235_buf236_buf238_buf239.snodes[2] =
    buf28: SchedulerNode(ComputedBuffer)
    buf28.writes = [MemoryDep('buf28', c0, {c0: 64}, None)]
    buf28.unmet_dependencies = [MemoryDep('buf26', c0, {c0: 64}, None)]
    buf28.met_dependencies = []
    buf28.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf28.group.device = cuda:0
    buf28.group.iteration = (64, 1)
    buf28.sizes = ([64], [])
    buf26_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf28_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf28_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf26', get_index)
            constant = ops.constant(401408.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf28', get_index_1, rsqrt, None)
            return store
    buf28 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 401408.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf25_buf26_buf28_buf235_buf236_buf238_buf239.snodes[3] =
    buf235: SchedulerNode(ComputedBuffer)
    buf235.writes = [MemoryDep('buf235', c0, {c0: 64}, None)]
    buf235.unmet_dependencies = [MemoryDep('buf25', c0, {c0: 64}, None)]
    buf235.met_dependencies = [MemoryDep('primals_63', c0, {c0: 64}, None)]
    buf235.users = [NodeUser(node=SchedulerNode(name='buf236'), can_inplace=True, is_weak=False)]
    buf235.group.device = cuda:0
    buf235.group.iteration = (64, 1)
    buf235.sizes = ([64], [])
    primals_63_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf25_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf235_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf235_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf25', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_63', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf235', get_index_2, add, None)
            return store
    buf235 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf25_buf26_buf28_buf235_buf236_buf238_buf239.snodes[4] =
    buf236: SchedulerNode(ComputedBuffer)
    buf236.writes = [MemoryDep('buf236', c0, {c0: 64}, None)]
    buf236.unmet_dependencies = [MemoryDep('buf235', c0, {c0: 64}, None)]
    buf236.met_dependencies = [StarDep(name='primals_63', mode=None)]
    buf236.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf236.group.device = cuda:0
    buf236.group.iteration = (64, 1)
    buf236.sizes = ([64], [])
    buf235_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    primals_63_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf236_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf236.mutations = ['primals_63']
    class buf236_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf235', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf236', get_index_1, load, None)
            return store
    buf236 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf25_buf26_buf28_buf235_buf236_buf238_buf239.snodes[5] =
    buf238: SchedulerNode(ComputedBuffer)
    buf238.writes = [MemoryDep('buf238', c0, {c0: 64}, None)]
    buf238.unmet_dependencies = [MemoryDep('buf26', c0, {c0: 64}, None)]
    buf238.met_dependencies = [MemoryDep('primals_64', c0, {c0: 64}, None)]
    buf238.users = [NodeUser(node=SchedulerNode(name='buf239'), can_inplace=True, is_weak=False)]
    buf238.group.device = cuda:0
    buf238.group.iteration = (64, 1)
    buf238.sizes = ([64], [])
    buf26_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    primals_64_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf238_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf238_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf26', get_index)
            constant = ops.constant(401408.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0000024912370735, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_64', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf238', get_index_2, add, None)
            return store
    buf238 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 401408.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0000024912370735
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf25_buf26_buf28_buf235_buf236_buf238_buf239.snodes[6] =
    buf239: SchedulerNode(ComputedBuffer)
    buf239.writes = [MemoryDep('buf239', c0, {c0: 64}, None)]
    buf239.unmet_dependencies = [MemoryDep('buf238', c0, {c0: 64}, None)]
    buf239.met_dependencies = [StarDep(name='primals_64', mode=None)]
    buf239.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf239.group.device = cuda:0
    buf239.group.iteration = (64, 1)
    buf239.sizes = ([64], [])
    primals_64_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf238_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf239_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf239.mutations = ['primals_64']
    class buf239_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf238', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf239', get_index_1, load, None)
            return store
    buf239 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf25_buf26_buf28_buf235_buf236_buf238_buf239 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 401408.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0000024912370735
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf29: SchedulerNode(ComputedBuffer)
buf29.writes = [MemoryDep('buf29', c0, {c0: 25690112}, None)]
buf29.unmet_dependencies = 
    [   MemoryDep('buf18', c0, {c0: 25690112}, None),
        MemoryDep('buf25', c1, {c0: 401408, c1: 64}, None),
        MemoryDep('buf26', c1, {c0: 401408, c1: 64}, None)]
buf29.met_dependencies = 
    [   MemoryDep('primals_2', c1, {c0: 401408, c1: 64}, None),
        MemoryDep('primals_3', c1, {c0: 401408, c1: 64}, None)]
buf29.users = [NodeUser(node=SchedulerNode(name='buf30'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf31'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf29.group.device = cuda:0
buf29.group.iteration = (25690112, 1)
buf29.sizes = ([401408, 64], [])
primals_3_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
primals_2_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf26_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
buf18_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
buf25_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
class buf29_loop_body:
    var_ranges = {z0: 401408, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf18', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf25', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf26', get_index_2)
        constant = ops.constant(401408.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_2', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_3', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf29', get_index_5, relu, None)
        return store
buf29 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[33554432], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 25690112
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 401408.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf30_buf31: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf30_buf31.writes = 
    [   MemoryDep('buf30', c0, {c0: 6422528}, None),
        MemoryDep('buf31', c0, {c0: 6422528}, None)]
buf30_buf31.unmet_dependencies = 
    [   MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 64, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7104, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7168, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7232, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 64, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7104, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7168, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7232, {c0: 1792, c1: 56, c2: 64}, None),
        MemoryDep('buf29', 14336*c0 + 128*c1 + c2, {c0: 1792, c1: 56, c2: 64}, None)]
buf30_buf31.met_dependencies = []
buf30_buf31.users = []
    buf30_buf31.snodes[0] =
    buf30: SchedulerNode(ComputedBuffer)
    buf30.writes = [MemoryDep('buf30', c0, {c0: 6422528}, None)]
    buf30.unmet_dependencies = 
        [   MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 64, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7104, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7168, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7232, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 64, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7104, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7168, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7232, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2, {c0: 1792, c1: 56, c2: 64}, None)]
    buf30.met_dependencies = []
    buf30.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf32'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf55'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf30.group.device = cuda:0
    buf30.group.iteration = (6422528, 1)
    buf30.sizes = ([32, 56, 56, 64], [])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf30_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    class buf30_loop_body:
        var_ranges = {z0: 32, z1: 56, z2: 56, z3: 64}
        index0 = 2*z1 - 1
        index1 = 2*z2 - 1
        index2 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 7232
        index3 = 2*z2
        index4 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 7168
        index5 = 2*z2 + 1
        index6 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 7104
        index7 = 2*z1
        index8 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 64
        index9 = 802816*z0 + 14336*z1 + 128*z2 + z3
        index10 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 64
        index11 = 2*z1 + 1
        index12 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 7104
        index13 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 7168
        index14 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 7232
        index15 = 200704*z0 + 3584*z1 + 64*z2 + z3
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int64)
            constant = ops.constant(0, torch.int64)
            ge = ops.ge(index_expr, constant)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int64)
            constant_1 = ops.constant(112, torch.int64)
            lt = ops.lt(index_expr_1, constant_1)
            and_ = ops.and_(ge, lt)
            get_index_2 = self.get_index('index1')
            index_expr_2 = ops.index_expr(get_index_2, torch.int64)
            constant_2 = ops.constant(0, torch.int64)
            ge_1 = ops.ge(index_expr_2, constant_2)
            get_index_3 = self.get_index('index1')
            index_expr_3 = ops.index_expr(get_index_3, torch.int64)
            constant_3 = ops.constant(112, torch.int64)
            lt_1 = ops.lt(index_expr_3, constant_3)
            and__1 = ops.and_(ge_1, lt_1)
            and__2 = ops.and_(and_, and__1)
            masked_subblock1 = self.masked_subblock1(and__2, -inf)
            get_index_4 = self.get_index('index0')
            index_expr_4 = ops.index_expr(get_index_4, torch.int64)
            constant_4 = ops.constant(0, torch.int64)
            ge_2 = ops.ge(index_expr_4, constant_4)
            get_index_5 = self.get_index('index0')
            index_expr_5 = ops.index_expr(get_index_5, torch.int64)
            constant_5 = ops.constant(112, torch.int64)
            lt_2 = ops.lt(index_expr_5, constant_5)
            and__3 = ops.and_(ge_2, lt_2)
            get_index_6 = self.get_index('index3')
            index_expr_6 = ops.index_expr(get_index_6, torch.int64)
            constant_6 = ops.constant(0, torch.int64)
            ge_3 = ops.ge(index_expr_6, constant_6)
            get_index_7 = self.get_index('index3')
            index_expr_7 = ops.index_expr(get_index_7, torch.int64)
            constant_7 = ops.constant(112, torch.int64)
            lt_3 = ops.lt(index_expr_7, constant_7)
            and__4 = ops.and_(ge_3, lt_3)
            and__5 = ops.and_(and__3, and__4)
            masked_subblock2 = self.masked_subblock2(and__5, -inf)
            maximum = ops.maximum(masked_subblock2, masked_subblock1)
            get_index_8 = self.get_index('index0')
            index_expr_8 = ops.index_expr(get_index_8, torch.int64)
            constant_8 = ops.constant(0, torch.int64)
            ge_4 = ops.ge(index_expr_8, constant_8)
            get_index_9 = self.get_index('index0')
            index_expr_9 = ops.index_expr(get_index_9, torch.int64)
            constant_9 = ops.constant(112, torch.int64)
            lt_4 = ops.lt(index_expr_9, constant_9)
            and__6 = ops.and_(ge_4, lt_4)
            get_index_10 = self.get_index('index5')
            index_expr_10 = ops.index_expr(get_index_10, torch.int64)
            constant_10 = ops.constant(0, torch.int64)
            ge_5 = ops.ge(index_expr_10, constant_10)
            get_index_11 = self.get_index('index5')
            index_expr_11 = ops.index_expr(get_index_11, torch.int64)
            constant_11 = ops.constant(112, torch.int64)
            lt_5 = ops.lt(index_expr_11, constant_11)
            and__7 = ops.and_(ge_5, lt_5)
            and__8 = ops.and_(and__6, and__7)
            masked_subblock3 = self.masked_subblock3(and__8, -inf)
            maximum_1 = ops.maximum(masked_subblock3, maximum)
            get_index_12 = self.get_index('index7')
            index_expr_12 = ops.index_expr(get_index_12, torch.int64)
            constant_12 = ops.constant(0, torch.int64)
            ge_6 = ops.ge(index_expr_12, constant_12)
            get_index_13 = self.get_index('index7')
            index_expr_13 = ops.index_expr(get_index_13, torch.int64)
            constant_13 = ops.constant(112, torch.int64)
            lt_6 = ops.lt(index_expr_13, constant_13)
            and__9 = ops.and_(ge_6, lt_6)
            get_index_14 = self.get_index('index1')
            index_expr_14 = ops.index_expr(get_index_14, torch.int64)
            constant_14 = ops.constant(0, torch.int64)
            ge_7 = ops.ge(index_expr_14, constant_14)
            get_index_15 = self.get_index('index1')
            index_expr_15 = ops.index_expr(get_index_15, torch.int64)
            constant_15 = ops.constant(112, torch.int64)
            lt_7 = ops.lt(index_expr_15, constant_15)
            and__10 = ops.and_(ge_7, lt_7)
            and__11 = ops.and_(and__9, and__10)
            masked_subblock4 = self.masked_subblock4(and__11, -inf)
            maximum_2 = ops.maximum(masked_subblock4, maximum_1)
            get_index_16 = self.get_index('index7')
            index_expr_16 = ops.index_expr(get_index_16, torch.int64)
            constant_16 = ops.constant(0, torch.int64)
            ge_8 = ops.ge(index_expr_16, constant_16)
            get_index_17 = self.get_index('index7')
            index_expr_17 = ops.index_expr(get_index_17, torch.int64)
            constant_17 = ops.constant(112, torch.int64)
            lt_8 = ops.lt(index_expr_17, constant_17)
            and__12 = ops.and_(ge_8, lt_8)
            get_index_18 = self.get_index('index3')
            index_expr_18 = ops.index_expr(get_index_18, torch.int64)
            constant_18 = ops.constant(0, torch.int64)
            ge_9 = ops.ge(index_expr_18, constant_18)
            get_index_19 = self.get_index('index3')
            index_expr_19 = ops.index_expr(get_index_19, torch.int64)
            constant_19 = ops.constant(112, torch.int64)
            lt_9 = ops.lt(index_expr_19, constant_19)
            and__13 = ops.and_(ge_9, lt_9)
            and__14 = ops.and_(and__12, and__13)
            masked_subblock5 = self.masked_subblock5(and__14, -inf)
            maximum_3 = ops.maximum(masked_subblock5, maximum_2)
            get_index_20 = self.get_index('index7')
            index_expr_20 = ops.index_expr(get_index_20, torch.int64)
            constant_20 = ops.constant(0, torch.int64)
            ge_10 = ops.ge(index_expr_20, constant_20)
            get_index_21 = self.get_index('index7')
            index_expr_21 = ops.index_expr(get_index_21, torch.int64)
            constant_21 = ops.constant(112, torch.int64)
            lt_10 = ops.lt(index_expr_21, constant_21)
            and__15 = ops.and_(ge_10, lt_10)
            get_index_22 = self.get_index('index5')
            index_expr_22 = ops.index_expr(get_index_22, torch.int64)
            constant_22 = ops.constant(0, torch.int64)
            ge_11 = ops.ge(index_expr_22, constant_22)
            get_index_23 = self.get_index('index5')
            index_expr_23 = ops.index_expr(get_index_23, torch.int64)
            constant_23 = ops.constant(112, torch.int64)
            lt_11 = ops.lt(index_expr_23, constant_23)
            and__16 = ops.and_(ge_11, lt_11)
            and__17 = ops.and_(and__15, and__16)
            masked_subblock6 = self.masked_subblock6(and__17, -inf)
            maximum_4 = ops.maximum(masked_subblock6, maximum_3)
            get_index_24 = self.get_index('index11')
            index_expr_24 = ops.index_expr(get_index_24, torch.int64)
            constant_24 = ops.constant(0, torch.int64)
            ge_12 = ops.ge(index_expr_24, constant_24)
            get_index_25 = self.get_index('index11')
            index_expr_25 = ops.index_expr(get_index_25, torch.int64)
            constant_25 = ops.constant(112, torch.int64)
            lt_12 = ops.lt(index_expr_25, constant_25)
            and__18 = ops.and_(ge_12, lt_12)
            get_index_26 = self.get_index('index1')
            index_expr_26 = ops.index_expr(get_index_26, torch.int64)
            constant_26 = ops.constant(0, torch.int64)
            ge_13 = ops.ge(index_expr_26, constant_26)
            get_index_27 = self.get_index('index1')
            index_expr_27 = ops.index_expr(get_index_27, torch.int64)
            constant_27 = ops.constant(112, torch.int64)
            lt_13 = ops.lt(index_expr_27, constant_27)
            and__19 = ops.and_(ge_13, lt_13)
            and__20 = ops.and_(and__18, and__19)
            masked_subblock7 = self.masked_subblock7(and__20, -inf)
            maximum_5 = ops.maximum(masked_subblock7, maximum_4)
            get_index_28 = self.get_index('index11')
            index_expr_28 = ops.index_expr(get_index_28, torch.int64)
            constant_28 = ops.constant(0, torch.int64)
            ge_14 = ops.ge(index_expr_28, constant_28)
            get_index_29 = self.get_index('index11')
            index_expr_29 = ops.index_expr(get_index_29, torch.int64)
            constant_29 = ops.constant(112, torch.int64)
            lt_14 = ops.lt(index_expr_29, constant_29)
            and__21 = ops.and_(ge_14, lt_14)
            get_index_30 = self.get_index('index3')
            index_expr_30 = ops.index_expr(get_index_30, torch.int64)
            constant_30 = ops.constant(0, torch.int64)
            ge_15 = ops.ge(index_expr_30, constant_30)
            get_index_31 = self.get_index('index3')
            index_expr_31 = ops.index_expr(get_index_31, torch.int64)
            constant_31 = ops.constant(112, torch.int64)
            lt_15 = ops.lt(index_expr_31, constant_31)
            and__22 = ops.and_(ge_15, lt_15)
            and__23 = ops.and_(and__21, and__22)
            masked_subblock8 = self.masked_subblock8(and__23, -inf)
            maximum_6 = ops.maximum(masked_subblock8, maximum_5)
            get_index_32 = self.get_index('index11')
            index_expr_32 = ops.index_expr(get_index_32, torch.int64)
            constant_32 = ops.constant(0, torch.int64)
            ge_16 = ops.ge(index_expr_32, constant_32)
            get_index_33 = self.get_index('index11')
            index_expr_33 = ops.index_expr(get_index_33, torch.int64)
            constant_33 = ops.constant(112, torch.int64)
            lt_16 = ops.lt(index_expr_33, constant_33)
            and__24 = ops.and_(ge_16, lt_16)
            get_index_34 = self.get_index('index5')
            index_expr_34 = ops.index_expr(get_index_34, torch.int64)
            constant_34 = ops.constant(0, torch.int64)
            ge_17 = ops.ge(index_expr_34, constant_34)
            get_index_35 = self.get_index('index5')
            index_expr_35 = ops.index_expr(get_index_35, torch.int64)
            constant_35 = ops.constant(112, torch.int64)
            lt_17 = ops.lt(index_expr_35, constant_35)
            and__25 = ops.and_(ge_17, lt_17)
            and__26 = ops.and_(and__24, and__25)
            masked_subblock9 = self.masked_subblock9(and__26, -inf)
            maximum_7 = ops.maximum(masked_subblock9, maximum_6)
            get_index_36 = self.get_index('index15')
            store = ops.store('buf30', get_index_36, maximum_7, None)
            return store
        def masked_subblock1(self, ops):
            get_index = self.get_index('index2')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock2(self, ops):
            get_index = self.get_index('index4')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock3(self, ops):
            get_index = self.get_index('index6')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock4(self, ops):
            get_index = self.get_index('index8')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock5(self, ops):
            get_index = self.get_index('index9')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock6(self, ops):
            get_index = self.get_index('index10')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock7(self, ops):
            get_index = self.get_index('index12')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock8(self, ops):
            get_index = self.get_index('index13')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock9(self, ops):
            get_index = self.get_index('index14')
            load = ops.load('buf29', get_index)
            return load
    buf30 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[8388608], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 6422528
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = (xindex // 3584) % 56
            x1 = (xindex // 64) % 56
            x0 = xindex % 64
            x5 = (xindex // 3584)
            x6 = xindex
            tmp0 = (-1) + (2*x2)
            tmp1 = tl.full([1], 0, tl.int64)
            tmp2 = tmp0 >= tmp1
            tmp3 = tl.full([1], 112, tl.int64)
            tmp4 = tmp0 < tmp3
            tmp5 = tmp2 & tmp4
            tmp6 = (-1) + (2*x1)
            tmp7 = tmp6 >= tmp1
            tmp8 = tmp6 < tmp3
            tmp9 = tmp7 & tmp8
            tmp10 = tmp5 & tmp9
            tmp11 = tl.load(in_ptr0 + ((-7232) + x0 + (128*x1) + (14336*x5)), tmp10, other=0.0)
            tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
            tmp13 = tl.where(tmp10, tmp11, tmp12)
            tmp14 = 2*x1
            tmp15 = tmp14 >= tmp1
            tmp16 = tmp14 < tmp3
            tmp17 = tmp15 & tmp16
            tmp18 = tmp5 & tmp17
            tmp19 = tl.load(in_ptr0 + ((-7168) + x0 + (128*x1) + (14336*x5)), tmp18, other=0.0)
            tmp20 = tl.full(tmp19.shape, float("-inf"), tmp19.dtype)
            tmp21 = tl.where(tmp18, tmp19, tmp20)
            tmp22 = triton_helpers.maximum(tmp21, tmp13)
            tmp23 = 1 + (2*x1)
            tmp24 = tmp23 >= tmp1
            tmp25 = tmp23 < tmp3
            tmp26 = tmp24 & tmp25
            tmp27 = tmp5 & tmp26
            tmp28 = tl.load(in_ptr0 + ((-7104) + x0 + (128*x1) + (14336*x5)), tmp27, other=0.0)
            tmp29 = tl.full(tmp28.shape, float("-inf"), tmp28.dtype)
            tmp30 = tl.where(tmp27, tmp28, tmp29)
            tmp31 = triton_helpers.maximum(tmp30, tmp22)
            tmp32 = 2*x2
            tmp33 = tmp32 >= tmp1
            tmp34 = tmp32 < tmp3
            tmp35 = tmp33 & tmp34
            tmp36 = tmp35 & tmp9
            tmp37 = tl.load(in_ptr0 + ((-64) + x0 + (128*x1) + (14336*x5)), tmp36, other=0.0)
            tmp38 = tl.full(tmp37.shape, float("-inf"), tmp37.dtype)
            tmp39 = tl.where(tmp36, tmp37, tmp38)
            tmp40 = triton_helpers.maximum(tmp39, tmp31)
            tmp41 = tmp35 & tmp17
            tmp42 = tl.load(in_ptr0 + (x0 + (128*x1) + (14336*x5)), tmp41, other=0.0)
            tmp43 = tl.full(tmp42.shape, float("-inf"), tmp42.dtype)
            tmp44 = tl.where(tmp41, tmp42, tmp43)
            tmp45 = triton_helpers.maximum(tmp44, tmp40)
            tmp46 = tmp35 & tmp26
            tmp47 = tl.load(in_ptr0 + (64 + x0 + (128*x1) + (14336*x5)), tmp46, other=0.0)
            tmp48 = tl.full(tmp47.shape, float("-inf"), tmp47.dtype)
            tmp49 = tl.where(tmp46, tmp47, tmp48)
            tmp50 = triton_helpers.maximum(tmp49, tmp45)
            tmp51 = 1 + (2*x2)
            tmp52 = tmp51 >= tmp1
            tmp53 = tmp51 < tmp3
            tmp54 = tmp52 & tmp53
            tmp55 = tmp54 & tmp9
            tmp56 = tl.load(in_ptr0 + (7104 + x0 + (128*x1) + (14336*x5)), tmp55, other=0.0)
            tmp57 = tl.full(tmp56.shape, float("-inf"), tmp56.dtype)
            tmp58 = tl.where(tmp55, tmp56, tmp57)
            tmp59 = triton_helpers.maximum(tmp58, tmp50)
            tmp60 = tmp54 & tmp17
            tmp61 = tl.load(in_ptr0 + (7168 + x0 + (128*x1) + (14336*x5)), tmp60, other=0.0)
            tmp62 = tl.full(tmp61.shape, float("-inf"), tmp61.dtype)
            tmp63 = tl.where(tmp60, tmp61, tmp62)
            tmp64 = triton_helpers.maximum(tmp63, tmp59)
            tmp65 = tmp54 & tmp26
            tmp66 = tl.load(in_ptr0 + (7232 + x0 + (128*x1) + (14336*x5)), tmp65, other=0.0)
            tmp67 = tl.full(tmp66.shape, float("-inf"), tmp66.dtype)
            tmp68 = tl.where(tmp65, tmp66, tmp67)
            tmp69 = triton_helpers.maximum(tmp68, tmp64)
            tl.store(out_ptr0 + (x6), tmp69, None)
    buf30_buf31.snodes[1] =
    buf31: SchedulerNode(ComputedBuffer)
    buf31.writes = [MemoryDep('buf31', c0, {c0: 6422528}, None)]
    buf31.unmet_dependencies = 
        [   MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 64, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7104, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7168, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 + 7232, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 64, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7104, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7168, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2 - 7232, {c0: 1792, c1: 56, c2: 64}, None),
            MemoryDep('buf29', 14336*c0 + 128*c1 + c2, {c0: 1792, c1: 56, c2: 64}, None)]
    buf31.met_dependencies = []
    buf31.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf31.group.device = cuda:0
    buf31.group.iteration = (6422528, 1)
    buf31.sizes = ([32, 56, 56, 64], [])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf29_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 112, 112], stride=[802816, 1, 7168, 64])
    buf31_layout = FixedLayout('cuda', torch.int8, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    class buf31_loop_body:
        var_ranges = {z0: 32, z1: 56, z2: 56, z3: 64}
        index0 = 2*z1 - 1
        index1 = 2*z2 - 1
        index2 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 7232
        index3 = 2*z2
        index4 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 7168
        index5 = 2*z2 + 1
        index6 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 7104
        index7 = 2*z1
        index8 = 802816*z0 + 14336*z1 + 128*z2 + z3 - 64
        index9 = 802816*z0 + 14336*z1 + 128*z2 + z3
        index10 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 64
        index11 = 2*z1 + 1
        index12 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 7104
        index13 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 7168
        index14 = 802816*z0 + 14336*z1 + 128*z2 + z3 + 7232
        index15 = 200704*z0 + 3584*z1 + 64*z2 + z3
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int64)
            constant = ops.constant(0, torch.int64)
            ge = ops.ge(index_expr, constant)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int64)
            constant_1 = ops.constant(112, torch.int64)
            lt = ops.lt(index_expr_1, constant_1)
            and_ = ops.and_(ge, lt)
            get_index_2 = self.get_index('index1')
            index_expr_2 = ops.index_expr(get_index_2, torch.int64)
            constant_2 = ops.constant(0, torch.int64)
            ge_1 = ops.ge(index_expr_2, constant_2)
            get_index_3 = self.get_index('index1')
            index_expr_3 = ops.index_expr(get_index_3, torch.int64)
            constant_3 = ops.constant(112, torch.int64)
            lt_1 = ops.lt(index_expr_3, constant_3)
            and__1 = ops.and_(ge_1, lt_1)
            and__2 = ops.and_(and_, and__1)
            masked_subblock1 = self.masked_subblock1(and__2, -inf)
            get_index_4 = self.get_index('index0')
            index_expr_4 = ops.index_expr(get_index_4, torch.int64)
            constant_4 = ops.constant(0, torch.int64)
            ge_2 = ops.ge(index_expr_4, constant_4)
            get_index_5 = self.get_index('index0')
            index_expr_5 = ops.index_expr(get_index_5, torch.int64)
            constant_5 = ops.constant(112, torch.int64)
            lt_2 = ops.lt(index_expr_5, constant_5)
            and__3 = ops.and_(ge_2, lt_2)
            get_index_6 = self.get_index('index3')
            index_expr_6 = ops.index_expr(get_index_6, torch.int64)
            constant_6 = ops.constant(0, torch.int64)
            ge_3 = ops.ge(index_expr_6, constant_6)
            get_index_7 = self.get_index('index3')
            index_expr_7 = ops.index_expr(get_index_7, torch.int64)
            constant_7 = ops.constant(112, torch.int64)
            lt_3 = ops.lt(index_expr_7, constant_7)
            and__4 = ops.and_(ge_3, lt_3)
            and__5 = ops.and_(and__3, and__4)
            masked_subblock2 = self.masked_subblock2(and__5, -inf)
            gt = ops.gt(masked_subblock2, masked_subblock1)
            constant_8 = ops.constant(1, torch.int8)
            constant_9 = ops.constant(0, torch.int8)
            where = ops.where(gt, constant_8, constant_9)
            maximum = ops.maximum(masked_subblock2, masked_subblock1)
            get_index_8 = self.get_index('index0')
            index_expr_8 = ops.index_expr(get_index_8, torch.int64)
            constant_10 = ops.constant(0, torch.int64)
            ge_4 = ops.ge(index_expr_8, constant_10)
            get_index_9 = self.get_index('index0')
            index_expr_9 = ops.index_expr(get_index_9, torch.int64)
            constant_11 = ops.constant(112, torch.int64)
            lt_4 = ops.lt(index_expr_9, constant_11)
            and__6 = ops.and_(ge_4, lt_4)
            get_index_10 = self.get_index('index5')
            index_expr_10 = ops.index_expr(get_index_10, torch.int64)
            constant_12 = ops.constant(0, torch.int64)
            ge_5 = ops.ge(index_expr_10, constant_12)
            get_index_11 = self.get_index('index5')
            index_expr_11 = ops.index_expr(get_index_11, torch.int64)
            constant_13 = ops.constant(112, torch.int64)
            lt_5 = ops.lt(index_expr_11, constant_13)
            and__7 = ops.and_(ge_5, lt_5)
            and__8 = ops.and_(and__6, and__7)
            masked_subblock3 = self.masked_subblock3(and__8, -inf)
            gt_1 = ops.gt(masked_subblock3, maximum)
            constant_14 = ops.constant(2, torch.int8)
            where_1 = ops.where(gt_1, constant_14, where)
            maximum_1 = ops.maximum(masked_subblock3, maximum)
            get_index_12 = self.get_index('index7')
            index_expr_12 = ops.index_expr(get_index_12, torch.int64)
            constant_15 = ops.constant(0, torch.int64)
            ge_6 = ops.ge(index_expr_12, constant_15)
            get_index_13 = self.get_index('index7')
            index_expr_13 = ops.index_expr(get_index_13, torch.int64)
            constant_16 = ops.constant(112, torch.int64)
            lt_6 = ops.lt(index_expr_13, constant_16)
            and__9 = ops.and_(ge_6, lt_6)
            get_index_14 = self.get_index('index1')
            index_expr_14 = ops.index_expr(get_index_14, torch.int64)
            constant_17 = ops.constant(0, torch.int64)
            ge_7 = ops.ge(index_expr_14, constant_17)
            get_index_15 = self.get_index('index1')
            index_expr_15 = ops.index_expr(get_index_15, torch.int64)
            constant_18 = ops.constant(112, torch.int64)
            lt_7 = ops.lt(index_expr_15, constant_18)
            and__10 = ops.and_(ge_7, lt_7)
            and__11 = ops.and_(and__9, and__10)
            masked_subblock4 = self.masked_subblock4(and__11, -inf)
            gt_2 = ops.gt(masked_subblock4, maximum_1)
            constant_19 = ops.constant(3, torch.int8)
            where_2 = ops.where(gt_2, constant_19, where_1)
            maximum_2 = ops.maximum(masked_subblock4, maximum_1)
            get_index_16 = self.get_index('index7')
            index_expr_16 = ops.index_expr(get_index_16, torch.int64)
            constant_20 = ops.constant(0, torch.int64)
            ge_8 = ops.ge(index_expr_16, constant_20)
            get_index_17 = self.get_index('index7')
            index_expr_17 = ops.index_expr(get_index_17, torch.int64)
            constant_21 = ops.constant(112, torch.int64)
            lt_8 = ops.lt(index_expr_17, constant_21)
            and__12 = ops.and_(ge_8, lt_8)
            get_index_18 = self.get_index('index3')
            index_expr_18 = ops.index_expr(get_index_18, torch.int64)
            constant_22 = ops.constant(0, torch.int64)
            ge_9 = ops.ge(index_expr_18, constant_22)
            get_index_19 = self.get_index('index3')
            index_expr_19 = ops.index_expr(get_index_19, torch.int64)
            constant_23 = ops.constant(112, torch.int64)
            lt_9 = ops.lt(index_expr_19, constant_23)
            and__13 = ops.and_(ge_9, lt_9)
            and__14 = ops.and_(and__12, and__13)
            masked_subblock5 = self.masked_subblock5(and__14, -inf)
            gt_3 = ops.gt(masked_subblock5, maximum_2)
            constant_24 = ops.constant(4, torch.int8)
            where_3 = ops.where(gt_3, constant_24, where_2)
            maximum_3 = ops.maximum(masked_subblock5, maximum_2)
            get_index_20 = self.get_index('index7')
            index_expr_20 = ops.index_expr(get_index_20, torch.int64)
            constant_25 = ops.constant(0, torch.int64)
            ge_10 = ops.ge(index_expr_20, constant_25)
            get_index_21 = self.get_index('index7')
            index_expr_21 = ops.index_expr(get_index_21, torch.int64)
            constant_26 = ops.constant(112, torch.int64)
            lt_10 = ops.lt(index_expr_21, constant_26)
            and__15 = ops.and_(ge_10, lt_10)
            get_index_22 = self.get_index('index5')
            index_expr_22 = ops.index_expr(get_index_22, torch.int64)
            constant_27 = ops.constant(0, torch.int64)
            ge_11 = ops.ge(index_expr_22, constant_27)
            get_index_23 = self.get_index('index5')
            index_expr_23 = ops.index_expr(get_index_23, torch.int64)
            constant_28 = ops.constant(112, torch.int64)
            lt_11 = ops.lt(index_expr_23, constant_28)
            and__16 = ops.and_(ge_11, lt_11)
            and__17 = ops.and_(and__15, and__16)
            masked_subblock6 = self.masked_subblock6(and__17, -inf)
            gt_4 = ops.gt(masked_subblock6, maximum_3)
            constant_29 = ops.constant(5, torch.int8)
            where_4 = ops.where(gt_4, constant_29, where_3)
            maximum_4 = ops.maximum(masked_subblock6, maximum_3)
            get_index_24 = self.get_index('index11')
            index_expr_24 = ops.index_expr(get_index_24, torch.int64)
            constant_30 = ops.constant(0, torch.int64)
            ge_12 = ops.ge(index_expr_24, constant_30)
            get_index_25 = self.get_index('index11')
            index_expr_25 = ops.index_expr(get_index_25, torch.int64)
            constant_31 = ops.constant(112, torch.int64)
            lt_12 = ops.lt(index_expr_25, constant_31)
            and__18 = ops.and_(ge_12, lt_12)
            get_index_26 = self.get_index('index1')
            index_expr_26 = ops.index_expr(get_index_26, torch.int64)
            constant_32 = ops.constant(0, torch.int64)
            ge_13 = ops.ge(index_expr_26, constant_32)
            get_index_27 = self.get_index('index1')
            index_expr_27 = ops.index_expr(get_index_27, torch.int64)
            constant_33 = ops.constant(112, torch.int64)
            lt_13 = ops.lt(index_expr_27, constant_33)
            and__19 = ops.and_(ge_13, lt_13)
            and__20 = ops.and_(and__18, and__19)
            masked_subblock7 = self.masked_subblock7(and__20, -inf)
            gt_5 = ops.gt(masked_subblock7, maximum_4)
            constant_34 = ops.constant(6, torch.int8)
            where_5 = ops.where(gt_5, constant_34, where_4)
            maximum_5 = ops.maximum(masked_subblock7, maximum_4)
            get_index_28 = self.get_index('index11')
            index_expr_28 = ops.index_expr(get_index_28, torch.int64)
            constant_35 = ops.constant(0, torch.int64)
            ge_14 = ops.ge(index_expr_28, constant_35)
            get_index_29 = self.get_index('index11')
            index_expr_29 = ops.index_expr(get_index_29, torch.int64)
            constant_36 = ops.constant(112, torch.int64)
            lt_14 = ops.lt(index_expr_29, constant_36)
            and__21 = ops.and_(ge_14, lt_14)
            get_index_30 = self.get_index('index3')
            index_expr_30 = ops.index_expr(get_index_30, torch.int64)
            constant_37 = ops.constant(0, torch.int64)
            ge_15 = ops.ge(index_expr_30, constant_37)
            get_index_31 = self.get_index('index3')
            index_expr_31 = ops.index_expr(get_index_31, torch.int64)
            constant_38 = ops.constant(112, torch.int64)
            lt_15 = ops.lt(index_expr_31, constant_38)
            and__22 = ops.and_(ge_15, lt_15)
            and__23 = ops.and_(and__21, and__22)
            masked_subblock8 = self.masked_subblock8(and__23, -inf)
            gt_6 = ops.gt(masked_subblock8, maximum_5)
            constant_39 = ops.constant(7, torch.int8)
            where_6 = ops.where(gt_6, constant_39, where_5)
            maximum_6 = ops.maximum(masked_subblock8, maximum_5)
            get_index_32 = self.get_index('index11')
            index_expr_32 = ops.index_expr(get_index_32, torch.int64)
            constant_40 = ops.constant(0, torch.int64)
            ge_16 = ops.ge(index_expr_32, constant_40)
            get_index_33 = self.get_index('index11')
            index_expr_33 = ops.index_expr(get_index_33, torch.int64)
            constant_41 = ops.constant(112, torch.int64)
            lt_16 = ops.lt(index_expr_33, constant_41)
            and__24 = ops.and_(ge_16, lt_16)
            get_index_34 = self.get_index('index5')
            index_expr_34 = ops.index_expr(get_index_34, torch.int64)
            constant_42 = ops.constant(0, torch.int64)
            ge_17 = ops.ge(index_expr_34, constant_42)
            get_index_35 = self.get_index('index5')
            index_expr_35 = ops.index_expr(get_index_35, torch.int64)
            constant_43 = ops.constant(112, torch.int64)
            lt_17 = ops.lt(index_expr_35, constant_43)
            and__25 = ops.and_(ge_17, lt_17)
            and__26 = ops.and_(and__24, and__25)
            masked_subblock9 = self.masked_subblock9(and__26, -inf)
            gt_7 = ops.gt(masked_subblock9, maximum_6)
            constant_44 = ops.constant(8, torch.int8)
            where_7 = ops.where(gt_7, constant_44, where_6)
            maximum_7 = ops.maximum(masked_subblock9, maximum_6)
            get_index_36 = self.get_index('index15')
            store = ops.store('buf31', get_index_36, where_7, None)
            return store
        def masked_subblock1(self, ops):
            get_index = self.get_index('index2')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock2(self, ops):
            get_index = self.get_index('index4')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock3(self, ops):
            get_index = self.get_index('index6')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock4(self, ops):
            get_index = self.get_index('index8')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock5(self, ops):
            get_index = self.get_index('index9')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock6(self, ops):
            get_index = self.get_index('index10')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock7(self, ops):
            get_index = self.get_index('index12')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock8(self, ops):
            get_index = self.get_index('index13')
            load = ops.load('buf29', get_index)
            return load
        def masked_subblock9(self, ops):
            get_index = self.get_index('index14')
            load = ops.load('buf29', get_index)
            return load
    buf31 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[8388608], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*i8', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 6422528
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = (xindex // 3584) % 56
            x1 = (xindex // 64) % 56
            x0 = xindex % 64
            x5 = (xindex // 3584)
            x6 = xindex
            tmp0 = (-1) + (2*x2)
            tmp1 = tl.full([1], 0, tl.int64)
            tmp2 = tmp0 >= tmp1
            tmp3 = tl.full([1], 112, tl.int64)
            tmp4 = tmp0 < tmp3
            tmp5 = tmp2 & tmp4
            tmp6 = (-1) + (2*x1)
            tmp7 = tmp6 >= tmp1
            tmp8 = tmp6 < tmp3
            tmp9 = tmp7 & tmp8
            tmp10 = tmp5 & tmp9
            tmp11 = tl.load(in_ptr0 + ((-7232) + x0 + (128*x1) + (14336*x5)), tmp10, other=0.0)
            tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
            tmp13 = tl.where(tmp10, tmp11, tmp12)
            tmp14 = 2*x1
            tmp15 = tmp14 >= tmp1
            tmp16 = tmp14 < tmp3
            tmp17 = tmp15 & tmp16
            tmp18 = tmp5 & tmp17
            tmp19 = tl.load(in_ptr0 + ((-7168) + x0 + (128*x1) + (14336*x5)), tmp18, other=0.0)
            tmp20 = tl.full(tmp19.shape, float("-inf"), tmp19.dtype)
            tmp21 = tl.where(tmp18, tmp19, tmp20)
            tmp22 = tmp21 > tmp13
            tmp23 = tl.full([1], 1, tl.int8)
            tmp24 = tl.full([1], 0, tl.int8)
            tmp25 = tl.where(tmp22, tmp23, tmp24)
            tmp26 = triton_helpers.maximum(tmp21, tmp13)
            tmp27 = 1 + (2*x1)
            tmp28 = tmp27 >= tmp1
            tmp29 = tmp27 < tmp3
            tmp30 = tmp28 & tmp29
            tmp31 = tmp5 & tmp30
            tmp32 = tl.load(in_ptr0 + ((-7104) + x0 + (128*x1) + (14336*x5)), tmp31, other=0.0)
            tmp33 = tl.full(tmp32.shape, float("-inf"), tmp32.dtype)
            tmp34 = tl.where(tmp31, tmp32, tmp33)
            tmp35 = tmp34 > tmp26
            tmp36 = tl.full([1], 2, tl.int8)
            tmp37 = tl.where(tmp35, tmp36, tmp25)
            tmp38 = triton_helpers.maximum(tmp34, tmp26)
            tmp39 = 2*x2
            tmp40 = tmp39 >= tmp1
            tmp41 = tmp39 < tmp3
            tmp42 = tmp40 & tmp41
            tmp43 = tmp42 & tmp9
            tmp44 = tl.load(in_ptr0 + ((-64) + x0 + (128*x1) + (14336*x5)), tmp43, other=0.0)
            tmp45 = tl.full(tmp44.shape, float("-inf"), tmp44.dtype)
            tmp46 = tl.where(tmp43, tmp44, tmp45)
            tmp47 = tmp46 > tmp38
            tmp48 = tl.full([1], 3, tl.int8)
            tmp49 = tl.where(tmp47, tmp48, tmp37)
            tmp50 = triton_helpers.maximum(tmp46, tmp38)
            tmp51 = tmp42 & tmp17
            tmp52 = tl.load(in_ptr0 + (x0 + (128*x1) + (14336*x5)), tmp51, other=0.0)
            tmp53 = tl.full(tmp52.shape, float("-inf"), tmp52.dtype)
            tmp54 = tl.where(tmp51, tmp52, tmp53)
            tmp55 = tmp54 > tmp50
            tmp56 = tl.full([1], 4, tl.int8)
            tmp57 = tl.where(tmp55, tmp56, tmp49)
            tmp58 = triton_helpers.maximum(tmp54, tmp50)
            tmp59 = tmp42 & tmp30
            tmp60 = tl.load(in_ptr0 + (64 + x0 + (128*x1) + (14336*x5)), tmp59, other=0.0)
            tmp61 = tl.full(tmp60.shape, float("-inf"), tmp60.dtype)
            tmp62 = tl.where(tmp59, tmp60, tmp61)
            tmp63 = tmp62 > tmp58
            tmp64 = tl.full([1], 5, tl.int8)
            tmp65 = tl.where(tmp63, tmp64, tmp57)
            tmp66 = triton_helpers.maximum(tmp62, tmp58)
            tmp67 = 1 + (2*x2)
            tmp68 = tmp67 >= tmp1
            tmp69 = tmp67 < tmp3
            tmp70 = tmp68 & tmp69
            tmp71 = tmp70 & tmp9
            tmp72 = tl.load(in_ptr0 + (7104 + x0 + (128*x1) + (14336*x5)), tmp71, other=0.0)
            tmp73 = tl.full(tmp72.shape, float("-inf"), tmp72.dtype)
            tmp74 = tl.where(tmp71, tmp72, tmp73)
            tmp75 = tmp74 > tmp66
            tmp76 = tl.full([1], 6, tl.int8)
            tmp77 = tl.where(tmp75, tmp76, tmp65)
            tmp78 = triton_helpers.maximum(tmp74, tmp66)
            tmp79 = tmp70 & tmp17
            tmp80 = tl.load(in_ptr0 + (7168 + x0 + (128*x1) + (14336*x5)), tmp79, other=0.0)
            tmp81 = tl.full(tmp80.shape, float("-inf"), tmp80.dtype)
            tmp82 = tl.where(tmp79, tmp80, tmp81)
            tmp83 = tmp82 > tmp78
            tmp84 = tl.full([1], 7, tl.int8)
            tmp85 = tl.where(tmp83, tmp84, tmp77)
            tmp86 = triton_helpers.maximum(tmp82, tmp78)
            tmp87 = tmp70 & tmp30
            tmp88 = tl.load(in_ptr0 + (7232 + x0 + (128*x1) + (14336*x5)), tmp87, other=0.0)
            tmp89 = tl.full(tmp88.shape, float("-inf"), tmp88.dtype)
            tmp90 = tl.where(tmp87, tmp88, tmp89)
            tmp91 = tmp90 > tmp86
            tmp92 = tl.full([1], 8, tl.int8)
            tmp93 = tl.where(tmp91, tmp92, tmp85)
            tmp94 = triton_helpers.maximum(tmp90, tmp86)
            tl.store(out_ptr0 + (x6), tmp93, None)
    buf30_buf31 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[8388608], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i8', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 6422528
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = (xindex // 3584) % 56
            x1 = (xindex // 64) % 56
            x0 = xindex % 64
            x5 = (xindex // 3584)
            x6 = xindex
            tmp0 = (-1) + (2*x2)
            tmp1 = tl.full([1], 0, tl.int64)
            tmp2 = tmp0 >= tmp1
            tmp3 = tl.full([1], 112, tl.int64)
            tmp4 = tmp0 < tmp3
            tmp5 = tmp2 & tmp4
            tmp6 = (-1) + (2*x1)
            tmp7 = tmp6 >= tmp1
            tmp8 = tmp6 < tmp3
            tmp9 = tmp7 & tmp8
            tmp10 = tmp5 & tmp9
            tmp11 = tl.load(in_ptr0 + ((-7232) + x0 + (128*x1) + (14336*x5)), tmp10, other=0.0)
            tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
            tmp13 = tl.where(tmp10, tmp11, tmp12)
            tmp14 = 2*x1
            tmp15 = tmp14 >= tmp1
            tmp16 = tmp14 < tmp3
            tmp17 = tmp15 & tmp16
            tmp18 = tmp5 & tmp17
            tmp19 = tl.load(in_ptr0 + ((-7168) + x0 + (128*x1) + (14336*x5)), tmp18, other=0.0)
            tmp20 = tl.full(tmp19.shape, float("-inf"), tmp19.dtype)
            tmp21 = tl.where(tmp18, tmp19, tmp20)
            tmp22 = triton_helpers.maximum(tmp21, tmp13)
            tmp23 = 1 + (2*x1)
            tmp24 = tmp23 >= tmp1
            tmp25 = tmp23 < tmp3
            tmp26 = tmp24 & tmp25
            tmp27 = tmp5 & tmp26
            tmp28 = tl.load(in_ptr0 + ((-7104) + x0 + (128*x1) + (14336*x5)), tmp27, other=0.0)
            tmp29 = tl.full(tmp28.shape, float("-inf"), tmp28.dtype)
            tmp30 = tl.where(tmp27, tmp28, tmp29)
            tmp31 = triton_helpers.maximum(tmp30, tmp22)
            tmp32 = 2*x2
            tmp33 = tmp32 >= tmp1
            tmp34 = tmp32 < tmp3
            tmp35 = tmp33 & tmp34
            tmp36 = tmp35 & tmp9
            tmp37 = tl.load(in_ptr0 + ((-64) + x0 + (128*x1) + (14336*x5)), tmp36, other=0.0)
            tmp38 = tl.full(tmp37.shape, float("-inf"), tmp37.dtype)
            tmp39 = tl.where(tmp36, tmp37, tmp38)
            tmp40 = triton_helpers.maximum(tmp39, tmp31)
            tmp41 = tmp35 & tmp17
            tmp42 = tl.load(in_ptr0 + (x0 + (128*x1) + (14336*x5)), tmp41, other=0.0)
            tmp43 = tl.full(tmp42.shape, float("-inf"), tmp42.dtype)
            tmp44 = tl.where(tmp41, tmp42, tmp43)
            tmp45 = triton_helpers.maximum(tmp44, tmp40)
            tmp46 = tmp35 & tmp26
            tmp47 = tl.load(in_ptr0 + (64 + x0 + (128*x1) + (14336*x5)), tmp46, other=0.0)
            tmp48 = tl.full(tmp47.shape, float("-inf"), tmp47.dtype)
            tmp49 = tl.where(tmp46, tmp47, tmp48)
            tmp50 = triton_helpers.maximum(tmp49, tmp45)
            tmp51 = 1 + (2*x2)
            tmp52 = tmp51 >= tmp1
            tmp53 = tmp51 < tmp3
            tmp54 = tmp52 & tmp53
            tmp55 = tmp54 & tmp9
            tmp56 = tl.load(in_ptr0 + (7104 + x0 + (128*x1) + (14336*x5)), tmp55, other=0.0)
            tmp57 = tl.full(tmp56.shape, float("-inf"), tmp56.dtype)
            tmp58 = tl.where(tmp55, tmp56, tmp57)
            tmp59 = triton_helpers.maximum(tmp58, tmp50)
            tmp60 = tmp54 & tmp17
            tmp61 = tl.load(in_ptr0 + (7168 + x0 + (128*x1) + (14336*x5)), tmp60, other=0.0)
            tmp62 = tl.full(tmp61.shape, float("-inf"), tmp61.dtype)
            tmp63 = tl.where(tmp60, tmp61, tmp62)
            tmp64 = triton_helpers.maximum(tmp63, tmp59)
            tmp65 = tmp54 & tmp26
            tmp66 = tl.load(in_ptr0 + (7232 + x0 + (128*x1) + (14336*x5)), tmp65, other=0.0)
            tmp67 = tl.full(tmp66.shape, float("-inf"), tmp66.dtype)
            tmp68 = tl.where(tmp65, tmp66, tmp67)
            tmp69 = triton_helpers.maximum(tmp68, tmp64)
            tmp70 = tmp21 > tmp13
            tmp71 = tl.full([1], 1, tl.int8)
            tmp72 = tl.full([1], 0, tl.int8)
            tmp73 = tl.where(tmp70, tmp71, tmp72)
            tmp74 = tmp30 > tmp22
            tmp75 = tl.full([1], 2, tl.int8)
            tmp76 = tl.where(tmp74, tmp75, tmp73)
            tmp77 = tmp39 > tmp31
            tmp78 = tl.full([1], 3, tl.int8)
            tmp79 = tl.where(tmp77, tmp78, tmp76)
            tmp80 = tmp44 > tmp40
            tmp81 = tl.full([1], 4, tl.int8)
            tmp82 = tl.where(tmp80, tmp81, tmp79)
            tmp83 = tmp49 > tmp45
            tmp84 = tl.full([1], 5, tl.int8)
            tmp85 = tl.where(tmp83, tmp84, tmp82)
            tmp86 = tmp58 > tmp50
            tmp87 = tl.full([1], 6, tl.int8)
            tmp88 = tl.where(tmp86, tmp87, tmp85)
            tmp89 = tmp63 > tmp59
            tmp90 = tl.full([1], 7, tl.int8)
            tmp91 = tl.where(tmp89, tmp90, tmp88)
            tmp92 = tmp68 > tmp64
            tmp93 = tl.full([1], 8, tl.int8)
            tmp94 = tl.where(tmp92, tmp93, tmp91)
            tl.store(out_ptr0 + (x6), tmp69, None)
            tl.store(out_ptr1 + (x6), tmp94, None)


buf32: ExternKernelSchedulerNode(ExternKernelAlloc)
buf32.writes = [StarDep(name='buf32', mode=None)]
buf32.unmet_dependencies = [StarDep(name='buf1', mode=None), StarDep(name='buf30', mode=None)]
buf32.met_dependencies = []
buf32.users = [NodeUser(node=SchedulerNode(name='buf33'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf34'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf35'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf43'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf32.node.kernel = extern_kernels.convolution


buf33_buf34_buf35: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf33_buf34_buf35.writes = 
    [   MemoryDep('buf33', c0, {c0: 32768}, None),
        MemoryDep('buf34', c0, {c0: 32768}, None),
        MemoryDep('buf35', c0, {c0: 32768}, None)]
buf33_buf34_buf35.unmet_dependencies = [MemoryDep('buf32', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf33_buf34_buf35.met_dependencies = []
buf33_buf34_buf35.users = []
    buf33_buf34_buf35.snodes[0] =
    buf33: SchedulerNode(ComputedBuffer)
    buf33.writes = [MemoryDep('buf33', c0, {c0: 32768}, None)]
    buf33.unmet_dependencies = [MemoryDep('buf32', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf33.met_dependencies = []
    buf33.users = [NodeUser(node=SchedulerNode(name='buf36'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf37'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf38'), can_inplace=False, is_weak=False)]
    buf33.group.device = cuda:0
    buf33.group.iteration = (32768, 196)
    buf33.sizes = ([512, 64], [196])
    buf32_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf33_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf33_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf32', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf33', get_index_1, getitem)
            return store_reduction
    buf33 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
    buf33_buf34_buf35.snodes[1] =
    buf34: SchedulerNode(ComputedBuffer)
    buf34.writes = [MemoryDep('buf34', c0, {c0: 32768}, None)]
    buf34.unmet_dependencies = [MemoryDep('buf32', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf34.met_dependencies = []
    buf34.users = [NodeUser(node=SchedulerNode(name='buf36'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf37'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf38'), can_inplace=False, is_weak=False)]
    buf34.group.device = cuda:0
    buf34.group.iteration = (32768, 196)
    buf34.sizes = ([512, 64], [196])
    buf32_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf34_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf34_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf32', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf34', get_index_1, getitem_1)
            return store_reduction
    buf34 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, None)
    buf33_buf34_buf35.snodes[2] =
    buf35: SchedulerNode(ComputedBuffer)
    buf35.writes = [MemoryDep('buf35', c0, {c0: 32768}, None)]
    buf35.unmet_dependencies = [MemoryDep('buf32', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf35.met_dependencies = []
    buf35.users = [NodeUser(node=SchedulerNode(name='buf36'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf37'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf38'), can_inplace=False, is_weak=False)]
    buf35.group.device = cuda:0
    buf35.group.iteration = (32768, 196)
    buf35.sizes = ([512, 64], [196])
    buf32_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf35_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf35_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf32', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf35', get_index_1, getitem_2)
            return store_reduction
    buf35 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, None)
    buf33_buf34_buf35 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
            tl.store(out_ptr1 + (x3), tmp3, None)
            tl.store(out_ptr2 + (x3), tmp4, None)


buf36_buf37_buf38: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf36_buf37_buf38.writes = 
    [   MemoryDep('buf36', c0, {c0: 256}, None),
        MemoryDep('buf37', c0, {c0: 256}, None),
        MemoryDep('buf38', c0, {c0: 256}, None)]
buf36_buf37_buf38.unmet_dependencies = 
    [   MemoryDep('buf33', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf34', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf35', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
buf36_buf37_buf38.met_dependencies = []
buf36_buf37_buf38.users = []
    buf36_buf37_buf38.snodes[0] =
    buf36: SchedulerNode(ComputedBuffer)
    buf36.writes = [MemoryDep('buf36', c0, {c0: 256}, None)]
    buf36.unmet_dependencies = 
        [   MemoryDep('buf33', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf34', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf35', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf36.met_dependencies = []
    buf36.users = [NodeUser(node=SchedulerNode(name='buf39'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf40'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf41'), can_inplace=False, is_weak=False)]
    buf36.group.device = cuda:0
    buf36.group.iteration = (256, 128)
    buf36.sizes = ([4, 64], [128])
    buf33_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf35_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf34_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf36_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf36_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf33', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf34', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf35', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf36', get_index_3, getitem)
            return store_reduction
    buf36 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf36_buf37_buf38.snodes[1] =
    buf37: SchedulerNode(ComputedBuffer)
    buf37.writes = [MemoryDep('buf37', c0, {c0: 256}, None)]
    buf37.unmet_dependencies = 
        [   MemoryDep('buf33', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf34', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf35', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf37.met_dependencies = []
    buf37.users = [NodeUser(node=SchedulerNode(name='buf39'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf40'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf41'), can_inplace=False, is_weak=False)]
    buf37.group.device = cuda:0
    buf37.group.iteration = (256, 128)
    buf37.sizes = ([4, 64], [128])
    buf33_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf35_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf34_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf37_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf37_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf33', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf34', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf35', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf37', get_index_3, getitem_1)
            return store_reduction
    buf37 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf36_buf37_buf38.snodes[2] =
    buf38: SchedulerNode(ComputedBuffer)
    buf38.writes = [MemoryDep('buf38', c0, {c0: 256}, None)]
    buf38.unmet_dependencies = 
        [   MemoryDep('buf33', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf34', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf35', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf38.met_dependencies = []
    buf38.users = [NodeUser(node=SchedulerNode(name='buf39'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf40'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf41'), can_inplace=False, is_weak=False)]
    buf38.group.device = cuda:0
    buf38.group.iteration = (256, 128)
    buf38.sizes = ([4, 64], [128])
    buf33_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf35_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf34_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf38_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf38_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf33', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf34', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf35', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf38', get_index_3, getitem_2)
            return store_reduction
    buf38 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf36_buf37_buf38 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf39_buf40_buf42_buf243_buf244_buf246_buf247: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf39_buf40_buf42_buf243_buf244_buf246_buf247.writes = 
    [   MemoryDep('buf243', c0, {c0: 64}, None),
        MemoryDep('buf244', c0, {c0: 64}, None),
        MemoryDep('buf246', c0, {c0: 64}, None),
        MemoryDep('buf247', c0, {c0: 64}, None),
        MemoryDep('buf39', c0, {c0: 64}, None),
        MemoryDep('buf40', c0, {c0: 64}, None),
        MemoryDep('buf42', c0, {c0: 64}, None)]
buf39_buf40_buf42_buf243_buf244_buf246_buf247.unmet_dependencies = 
    [   MemoryDep('buf36', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf37', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf38', c0 + 64*c1, {c0: 64, c1: 4}, None)]
buf39_buf40_buf42_buf243_buf244_buf246_buf247.met_dependencies = 
    [   MemoryDep('primals_66', c0, {c0: 64}, None),
        MemoryDep('primals_67', c0, {c0: 64}, None),
        StarDep(name='primals_66', mode=None),
        StarDep(name='primals_67', mode=None)]
buf39_buf40_buf42_buf243_buf244_buf246_buf247.users = []
    buf39_buf40_buf42_buf243_buf244_buf246_buf247.snodes[0] =
    buf39: SchedulerNode(ComputedBuffer)
    buf39.writes = [MemoryDep('buf39', c0, {c0: 64}, None)]
    buf39.unmet_dependencies = 
        [   MemoryDep('buf36', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf37', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf38', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf39.met_dependencies = []
    buf39.users = [NodeUser(node=SchedulerNode(name='buf43'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf243'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf39.group.device = cuda:0
    buf39.group.iteration = (64, 4)
    buf39.sizes = ([64], [4])
    buf38_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf36_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf37_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf39_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf39_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf36', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf37', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf38', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf39', get_index_3, getitem)
            return store_reduction
    buf39 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf39_buf40_buf42_buf243_buf244_buf246_buf247.snodes[1] =
    buf40: SchedulerNode(ComputedBuffer)
    buf40.writes = [MemoryDep('buf40', c0, {c0: 64}, None)]
    buf40.unmet_dependencies = 
        [   MemoryDep('buf36', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf37', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf38', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf40.met_dependencies = []
    buf40.users = [NodeUser(node=SchedulerNode(name='buf42'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf43'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf246'), can_inplace=True, is_weak=False)]
    buf40.group.device = cuda:0
    buf40.group.iteration = (64, 4)
    buf40.sizes = ([64], [4])
    buf38_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf36_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf37_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf40_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf40_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf36', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf37', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf38', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf40', get_index_3, getitem_1)
            return store_reduction
    buf40 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf39_buf40_buf42_buf243_buf244_buf246_buf247.snodes[2] =
    buf42: SchedulerNode(ComputedBuffer)
    buf42.writes = [MemoryDep('buf42', c0, {c0: 64}, None)]
    buf42.unmet_dependencies = [MemoryDep('buf40', c0, {c0: 64}, None)]
    buf42.met_dependencies = []
    buf42.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf42.group.device = cuda:0
    buf42.group.iteration = (64, 1)
    buf42.sizes = ([64], [])
    buf40_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf42_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf42_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf40', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf42', get_index_1, rsqrt, None)
            return store
    buf42 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf39_buf40_buf42_buf243_buf244_buf246_buf247.snodes[3] =
    buf243: SchedulerNode(ComputedBuffer)
    buf243.writes = [MemoryDep('buf243', c0, {c0: 64}, None)]
    buf243.unmet_dependencies = [MemoryDep('buf39', c0, {c0: 64}, None)]
    buf243.met_dependencies = [MemoryDep('primals_66', c0, {c0: 64}, None)]
    buf243.users = [NodeUser(node=SchedulerNode(name='buf244'), can_inplace=True, is_weak=False)]
    buf243.group.device = cuda:0
    buf243.group.iteration = (64, 1)
    buf243.sizes = ([64], [])
    buf39_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    primals_66_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf243_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf243_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf39', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_66', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf243', get_index_2, add, None)
            return store
    buf243 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf39_buf40_buf42_buf243_buf244_buf246_buf247.snodes[4] =
    buf244: SchedulerNode(ComputedBuffer)
    buf244.writes = [MemoryDep('buf244', c0, {c0: 64}, None)]
    buf244.unmet_dependencies = [MemoryDep('buf243', c0, {c0: 64}, None)]
    buf244.met_dependencies = [StarDep(name='primals_66', mode=None)]
    buf244.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf244.group.device = cuda:0
    buf244.group.iteration = (64, 1)
    buf244.sizes = ([64], [])
    buf243_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    primals_66_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf244_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf244.mutations = ['primals_66']
    class buf244_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf243', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf244', get_index_1, load, None)
            return store
    buf244 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf39_buf40_buf42_buf243_buf244_buf246_buf247.snodes[5] =
    buf246: SchedulerNode(ComputedBuffer)
    buf246.writes = [MemoryDep('buf246', c0, {c0: 64}, None)]
    buf246.unmet_dependencies = [MemoryDep('buf40', c0, {c0: 64}, None)]
    buf246.met_dependencies = [MemoryDep('primals_67', c0, {c0: 64}, None)]
    buf246.users = [NodeUser(node=SchedulerNode(name='buf247'), can_inplace=True, is_weak=False)]
    buf246.group.device = cuda:0
    buf246.group.iteration = (64, 1)
    buf246.sizes = ([64], [])
    buf40_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    primals_67_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf246_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf246_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf40', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.00000996502277, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_67', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf246', get_index_2, add, None)
            return store
    buf246 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.00000996502277
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf39_buf40_buf42_buf243_buf244_buf246_buf247.snodes[6] =
    buf247: SchedulerNode(ComputedBuffer)
    buf247.writes = [MemoryDep('buf247', c0, {c0: 64}, None)]
    buf247.unmet_dependencies = [MemoryDep('buf246', c0, {c0: 64}, None)]
    buf247.met_dependencies = [StarDep(name='primals_67', mode=None)]
    buf247.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf247.group.device = cuda:0
    buf247.group.iteration = (64, 1)
    buf247.sizes = ([64], [])
    buf246_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    primals_67_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf247_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf247.mutations = ['primals_67']
    class buf247_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf246', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf247', get_index_1, load, None)
            return store
    buf247 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf39_buf40_buf42_buf243_buf244_buf246_buf247 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 100352.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.00000996502277
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf43: SchedulerNode(ComputedBuffer)
buf43.writes = [MemoryDep('buf43', c0, {c0: 6422528}, None)]
buf43.unmet_dependencies = 
    [   MemoryDep('buf32', c0, {c0: 6422528}, None),
        MemoryDep('buf39', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf40', c1, {c0: 100352, c1: 64}, None)]
buf43.met_dependencies = 
    [   MemoryDep('primals_5', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('primals_6', c1, {c0: 100352, c1: 64}, None)]
buf43.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf44'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf43.group.device = cuda:0
buf43.group.iteration = (6422528, 1)
buf43.sizes = ([100352, 64], [])
buf40_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
primals_6_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
primals_5_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
buf32_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf43_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf43_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf32', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf39', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf40', get_index_2)
        constant = ops.constant(100352.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_5', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_6', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf43', get_index_5, relu, None)
        return store
buf43 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 100352.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf44: ExternKernelSchedulerNode(ExternKernelAlloc)
buf44.writes = [StarDep(name='buf44', mode=None)]
buf44.unmet_dependencies = [StarDep(name='buf2', mode=None), StarDep(name='buf43', mode=None)]
buf44.met_dependencies = []
buf44.users = [NodeUser(node=SchedulerNode(name='buf45'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf46'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf47'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf55'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf44.node.kernel = extern_kernels.convolution


buf45_buf46_buf47: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf45_buf46_buf47.writes = 
    [   MemoryDep('buf45', c0, {c0: 32768}, None),
        MemoryDep('buf46', c0, {c0: 32768}, None),
        MemoryDep('buf47', c0, {c0: 32768}, None)]
buf45_buf46_buf47.unmet_dependencies = [MemoryDep('buf44', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf45_buf46_buf47.met_dependencies = []
buf45_buf46_buf47.users = []
    buf45_buf46_buf47.snodes[0] =
    buf45: SchedulerNode(ComputedBuffer)
    buf45.writes = [MemoryDep('buf45', c0, {c0: 32768}, None)]
    buf45.unmet_dependencies = [MemoryDep('buf44', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf45.met_dependencies = []
    buf45.users = [NodeUser(node=SchedulerNode(name='buf48'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf49'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf50'), can_inplace=False, is_weak=False)]
    buf45.group.device = cuda:0
    buf45.group.iteration = (32768, 196)
    buf45.sizes = ([512, 64], [196])
    buf44_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf45_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf45_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf44', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf45', get_index_1, getitem)
            return store_reduction
    buf45 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
    buf45_buf46_buf47.snodes[1] =
    buf46: SchedulerNode(ComputedBuffer)
    buf46.writes = [MemoryDep('buf46', c0, {c0: 32768}, None)]
    buf46.unmet_dependencies = [MemoryDep('buf44', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf46.met_dependencies = []
    buf46.users = [NodeUser(node=SchedulerNode(name='buf48'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf49'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf50'), can_inplace=False, is_weak=False)]
    buf46.group.device = cuda:0
    buf46.group.iteration = (32768, 196)
    buf46.sizes = ([512, 64], [196])
    buf44_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf46_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf46_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf44', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf46', get_index_1, getitem_1)
            return store_reduction
    buf46 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, None)
    buf45_buf46_buf47.snodes[2] =
    buf47: SchedulerNode(ComputedBuffer)
    buf47.writes = [MemoryDep('buf47', c0, {c0: 32768}, None)]
    buf47.unmet_dependencies = [MemoryDep('buf44', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf47.met_dependencies = []
    buf47.users = [NodeUser(node=SchedulerNode(name='buf48'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf49'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf50'), can_inplace=False, is_weak=False)]
    buf47.group.device = cuda:0
    buf47.group.iteration = (32768, 196)
    buf47.sizes = ([512, 64], [196])
    buf44_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf47_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf47_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf44', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf47', get_index_1, getitem_2)
            return store_reduction
    buf47 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, None)
    buf45_buf46_buf47 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
            tl.store(out_ptr1 + (x3), tmp3, None)
            tl.store(out_ptr2 + (x3), tmp4, None)


buf48_buf49_buf50: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf48_buf49_buf50.writes = 
    [   MemoryDep('buf48', c0, {c0: 256}, None),
        MemoryDep('buf49', c0, {c0: 256}, None),
        MemoryDep('buf50', c0, {c0: 256}, None)]
buf48_buf49_buf50.unmet_dependencies = 
    [   MemoryDep('buf45', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf46', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf47', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
buf48_buf49_buf50.met_dependencies = []
buf48_buf49_buf50.users = []
    buf48_buf49_buf50.snodes[0] =
    buf48: SchedulerNode(ComputedBuffer)
    buf48.writes = [MemoryDep('buf48', c0, {c0: 256}, None)]
    buf48.unmet_dependencies = 
        [   MemoryDep('buf45', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf46', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf47', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf48.met_dependencies = []
    buf48.users = [NodeUser(node=SchedulerNode(name='buf51'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf52'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf53'), can_inplace=False, is_weak=False)]
    buf48.group.device = cuda:0
    buf48.group.iteration = (256, 128)
    buf48.sizes = ([4, 64], [128])
    buf45_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf46_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf47_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf48_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf48_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf45', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf46', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf47', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf48', get_index_3, getitem)
            return store_reduction
    buf48 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf48_buf49_buf50.snodes[1] =
    buf49: SchedulerNode(ComputedBuffer)
    buf49.writes = [MemoryDep('buf49', c0, {c0: 256}, None)]
    buf49.unmet_dependencies = 
        [   MemoryDep('buf45', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf46', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf47', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf49.met_dependencies = []
    buf49.users = [NodeUser(node=SchedulerNode(name='buf51'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf52'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf53'), can_inplace=False, is_weak=False)]
    buf49.group.device = cuda:0
    buf49.group.iteration = (256, 128)
    buf49.sizes = ([4, 64], [128])
    buf45_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf46_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf47_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf49_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf49_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf45', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf46', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf47', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf49', get_index_3, getitem_1)
            return store_reduction
    buf49 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf48_buf49_buf50.snodes[2] =
    buf50: SchedulerNode(ComputedBuffer)
    buf50.writes = [MemoryDep('buf50', c0, {c0: 256}, None)]
    buf50.unmet_dependencies = 
        [   MemoryDep('buf45', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf46', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf47', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf50.met_dependencies = []
    buf50.users = [NodeUser(node=SchedulerNode(name='buf51'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf52'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf53'), can_inplace=False, is_weak=False)]
    buf50.group.device = cuda:0
    buf50.group.iteration = (256, 128)
    buf50.sizes = ([4, 64], [128])
    buf45_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf46_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf47_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf50_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf50_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf45', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf46', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf47', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf50', get_index_3, getitem_2)
            return store_reduction
    buf50 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf48_buf49_buf50 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf51_buf52_buf54_buf251_buf252_buf254_buf255: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf51_buf52_buf54_buf251_buf252_buf254_buf255.writes = 
    [   MemoryDep('buf251', c0, {c0: 64}, None),
        MemoryDep('buf252', c0, {c0: 64}, None),
        MemoryDep('buf254', c0, {c0: 64}, None),
        MemoryDep('buf255', c0, {c0: 64}, None),
        MemoryDep('buf51', c0, {c0: 64}, None),
        MemoryDep('buf52', c0, {c0: 64}, None),
        MemoryDep('buf54', c0, {c0: 64}, None)]
buf51_buf52_buf54_buf251_buf252_buf254_buf255.unmet_dependencies = 
    [   MemoryDep('buf48', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf49', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf50', c0 + 64*c1, {c0: 64, c1: 4}, None)]
buf51_buf52_buf54_buf251_buf252_buf254_buf255.met_dependencies = 
    [   MemoryDep('primals_69', c0, {c0: 64}, None),
        MemoryDep('primals_70', c0, {c0: 64}, None),
        StarDep(name='primals_69', mode=None),
        StarDep(name='primals_70', mode=None)]
buf51_buf52_buf54_buf251_buf252_buf254_buf255.users = []
    buf51_buf52_buf54_buf251_buf252_buf254_buf255.snodes[0] =
    buf51: SchedulerNode(ComputedBuffer)
    buf51.writes = [MemoryDep('buf51', c0, {c0: 64}, None)]
    buf51.unmet_dependencies = 
        [   MemoryDep('buf48', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf49', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf50', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf51.met_dependencies = []
    buf51.users = [NodeUser(node=SchedulerNode(name='buf55'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf251'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf51.group.device = cuda:0
    buf51.group.iteration = (64, 4)
    buf51.sizes = ([64], [4])
    buf48_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf49_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf50_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf51_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf51_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf48', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf49', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf50', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf51', get_index_3, getitem)
            return store_reduction
    buf51 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf51_buf52_buf54_buf251_buf252_buf254_buf255.snodes[1] =
    buf52: SchedulerNode(ComputedBuffer)
    buf52.writes = [MemoryDep('buf52', c0, {c0: 64}, None)]
    buf52.unmet_dependencies = 
        [   MemoryDep('buf48', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf49', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf50', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf52.met_dependencies = []
    buf52.users = [NodeUser(node=SchedulerNode(name='buf54'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf55'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf254'), can_inplace=True, is_weak=False)]
    buf52.group.device = cuda:0
    buf52.group.iteration = (64, 4)
    buf52.sizes = ([64], [4])
    buf48_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf49_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf50_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf52_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf52_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf48', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf49', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf50', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf52', get_index_3, getitem_1)
            return store_reduction
    buf52 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf51_buf52_buf54_buf251_buf252_buf254_buf255.snodes[2] =
    buf54: SchedulerNode(ComputedBuffer)
    buf54.writes = [MemoryDep('buf54', c0, {c0: 64}, None)]
    buf54.unmet_dependencies = [MemoryDep('buf52', c0, {c0: 64}, None)]
    buf54.met_dependencies = []
    buf54.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf54.group.device = cuda:0
    buf54.group.iteration = (64, 1)
    buf54.sizes = ([64], [])
    buf52_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf54_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf54_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf52', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf54', get_index_1, rsqrt, None)
            return store
    buf54 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf51_buf52_buf54_buf251_buf252_buf254_buf255.snodes[3] =
    buf251: SchedulerNode(ComputedBuffer)
    buf251.writes = [MemoryDep('buf251', c0, {c0: 64}, None)]
    buf251.unmet_dependencies = [MemoryDep('buf51', c0, {c0: 64}, None)]
    buf251.met_dependencies = [MemoryDep('primals_69', c0, {c0: 64}, None)]
    buf251.users = [NodeUser(node=SchedulerNode(name='buf252'), can_inplace=True, is_weak=False)]
    buf251.group.device = cuda:0
    buf251.group.iteration = (64, 1)
    buf251.sizes = ([64], [])
    primals_69_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf51_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf251_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf251_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf51', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_69', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf251', get_index_2, add, None)
            return store
    buf251 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf51_buf52_buf54_buf251_buf252_buf254_buf255.snodes[4] =
    buf252: SchedulerNode(ComputedBuffer)
    buf252.writes = [MemoryDep('buf252', c0, {c0: 64}, None)]
    buf252.unmet_dependencies = [MemoryDep('buf251', c0, {c0: 64}, None)]
    buf252.met_dependencies = [StarDep(name='primals_69', mode=None)]
    buf252.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf252.group.device = cuda:0
    buf252.group.iteration = (64, 1)
    buf252.sizes = ([64], [])
    buf251_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    primals_69_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf252_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf252.mutations = ['primals_69']
    class buf252_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf251', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf252', get_index_1, load, None)
            return store
    buf252 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf51_buf52_buf54_buf251_buf252_buf254_buf255.snodes[5] =
    buf254: SchedulerNode(ComputedBuffer)
    buf254.writes = [MemoryDep('buf254', c0, {c0: 64}, None)]
    buf254.unmet_dependencies = [MemoryDep('buf52', c0, {c0: 64}, None)]
    buf254.met_dependencies = [MemoryDep('primals_70', c0, {c0: 64}, None)]
    buf254.users = [NodeUser(node=SchedulerNode(name='buf255'), can_inplace=True, is_weak=False)]
    buf254.group.device = cuda:0
    buf254.group.iteration = (64, 1)
    buf254.sizes = ([64], [])
    buf52_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    primals_70_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf254_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf254_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf52', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.00000996502277, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_70', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf254', get_index_2, add, None)
            return store
    buf254 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.00000996502277
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf51_buf52_buf54_buf251_buf252_buf254_buf255.snodes[6] =
    buf255: SchedulerNode(ComputedBuffer)
    buf255.writes = [MemoryDep('buf255', c0, {c0: 64}, None)]
    buf255.unmet_dependencies = [MemoryDep('buf254', c0, {c0: 64}, None)]
    buf255.met_dependencies = [StarDep(name='primals_70', mode=None)]
    buf255.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf255.group.device = cuda:0
    buf255.group.iteration = (64, 1)
    buf255.sizes = ([64], [])
    primals_70_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf254_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf255_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf255.mutations = ['primals_70']
    class buf255_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf254', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf255', get_index_1, load, None)
            return store
    buf255 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf51_buf52_buf54_buf251_buf252_buf254_buf255 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 100352.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.00000996502277
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf55: SchedulerNode(ComputedBuffer)
buf55.writes = [MemoryDep('buf55', c0, {c0: 6422528}, None)]
buf55.unmet_dependencies = 
    [   MemoryDep('buf30', c0, {c0: 6422528}, None),
        MemoryDep('buf44', c0, {c0: 6422528}, None),
        MemoryDep('buf51', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf52', c1, {c0: 100352, c1: 64}, None)]
buf55.met_dependencies = 
    [   MemoryDep('primals_8', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('primals_9', c1, {c0: 100352, c1: 64}, None)]
buf55.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf56'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf79'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf55.group.device = cuda:0
buf55.group.iteration = (6422528, 1)
buf55.sizes = ([100352, 64], [])
primals_8_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf30_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf51_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
buf52_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
primals_9_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf44_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf55_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf55_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf44', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf51', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf52', get_index_2)
        constant = ops.constant(100352.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_8', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_9', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        get_index_5 = self.get_index('index0')
        load_5 = ops.load('buf30', get_index_5)
        add_2 = ops.add(add_1, load_5)
        relu = ops.relu(add_2)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf55', get_index_6, relu, None)
        return store
buf55 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp14 = tl.load(in_ptr5 + (x2), None)
        tmp2 = tmp0 - tmp1
        tmp4 = 100352.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp15 = tmp13 + tmp14
        tmp16 = tl.full([1], 0, tl.int32)
        tmp17 = triton_helpers.maximum(tmp16, tmp15)
        tl.store(out_ptr0 + (x2), tmp17, None)


buf56: ExternKernelSchedulerNode(ExternKernelAlloc)
buf56.writes = [StarDep(name='buf56', mode=None)]
buf56.unmet_dependencies = [StarDep(name='buf3', mode=None), StarDep(name='buf55', mode=None)]
buf56.met_dependencies = []
buf56.users = [NodeUser(node=SchedulerNode(name='buf57'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf58'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf59'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf67'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf56.node.kernel = extern_kernels.convolution


buf57_buf58_buf59: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf57_buf58_buf59.writes = 
    [   MemoryDep('buf57', c0, {c0: 32768}, None),
        MemoryDep('buf58', c0, {c0: 32768}, None),
        MemoryDep('buf59', c0, {c0: 32768}, None)]
buf57_buf58_buf59.unmet_dependencies = [MemoryDep('buf56', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf57_buf58_buf59.met_dependencies = []
buf57_buf58_buf59.users = []
    buf57_buf58_buf59.snodes[0] =
    buf57: SchedulerNode(ComputedBuffer)
    buf57.writes = [MemoryDep('buf57', c0, {c0: 32768}, None)]
    buf57.unmet_dependencies = [MemoryDep('buf56', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf57.met_dependencies = []
    buf57.users = [NodeUser(node=SchedulerNode(name='buf60'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf61'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf62'), can_inplace=False, is_weak=False)]
    buf57.group.device = cuda:0
    buf57.group.iteration = (32768, 196)
    buf57.sizes = ([512, 64], [196])
    buf56_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf57_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf57_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf56', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf57', get_index_1, getitem)
            return store_reduction
    buf57 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
    buf57_buf58_buf59.snodes[1] =
    buf58: SchedulerNode(ComputedBuffer)
    buf58.writes = [MemoryDep('buf58', c0, {c0: 32768}, None)]
    buf58.unmet_dependencies = [MemoryDep('buf56', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf58.met_dependencies = []
    buf58.users = [NodeUser(node=SchedulerNode(name='buf60'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf61'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf62'), can_inplace=False, is_weak=False)]
    buf58.group.device = cuda:0
    buf58.group.iteration = (32768, 196)
    buf58.sizes = ([512, 64], [196])
    buf56_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf58_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf58_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf56', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf58', get_index_1, getitem_1)
            return store_reduction
    buf58 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, None)
    buf57_buf58_buf59.snodes[2] =
    buf59: SchedulerNode(ComputedBuffer)
    buf59.writes = [MemoryDep('buf59', c0, {c0: 32768}, None)]
    buf59.unmet_dependencies = [MemoryDep('buf56', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf59.met_dependencies = []
    buf59.users = [NodeUser(node=SchedulerNode(name='buf60'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf61'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf62'), can_inplace=False, is_weak=False)]
    buf59.group.device = cuda:0
    buf59.group.iteration = (32768, 196)
    buf59.sizes = ([512, 64], [196])
    buf56_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf59_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf59_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf56', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf59', get_index_1, getitem_2)
            return store_reduction
    buf59 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, None)
    buf57_buf58_buf59 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
            tl.store(out_ptr1 + (x3), tmp3, None)
            tl.store(out_ptr2 + (x3), tmp4, None)


buf60_buf61_buf62: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf60_buf61_buf62.writes = 
    [   MemoryDep('buf60', c0, {c0: 256}, None),
        MemoryDep('buf61', c0, {c0: 256}, None),
        MemoryDep('buf62', c0, {c0: 256}, None)]
buf60_buf61_buf62.unmet_dependencies = 
    [   MemoryDep('buf57', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf58', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf59', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
buf60_buf61_buf62.met_dependencies = []
buf60_buf61_buf62.users = []
    buf60_buf61_buf62.snodes[0] =
    buf60: SchedulerNode(ComputedBuffer)
    buf60.writes = [MemoryDep('buf60', c0, {c0: 256}, None)]
    buf60.unmet_dependencies = 
        [   MemoryDep('buf57', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf58', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf59', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf60.met_dependencies = []
    buf60.users = [NodeUser(node=SchedulerNode(name='buf63'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf64'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf65'), can_inplace=False, is_weak=False)]
    buf60.group.device = cuda:0
    buf60.group.iteration = (256, 128)
    buf60.sizes = ([4, 64], [128])
    buf59_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf58_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf57_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf60_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf60_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf57', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf58', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf59', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf60', get_index_3, getitem)
            return store_reduction
    buf60 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf60_buf61_buf62.snodes[1] =
    buf61: SchedulerNode(ComputedBuffer)
    buf61.writes = [MemoryDep('buf61', c0, {c0: 256}, None)]
    buf61.unmet_dependencies = 
        [   MemoryDep('buf57', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf58', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf59', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf61.met_dependencies = []
    buf61.users = [NodeUser(node=SchedulerNode(name='buf63'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf64'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf65'), can_inplace=False, is_weak=False)]
    buf61.group.device = cuda:0
    buf61.group.iteration = (256, 128)
    buf61.sizes = ([4, 64], [128])
    buf59_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf58_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf57_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf61_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf61_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf57', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf58', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf59', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf61', get_index_3, getitem_1)
            return store_reduction
    buf61 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf60_buf61_buf62.snodes[2] =
    buf62: SchedulerNode(ComputedBuffer)
    buf62.writes = [MemoryDep('buf62', c0, {c0: 256}, None)]
    buf62.unmet_dependencies = 
        [   MemoryDep('buf57', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf58', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf59', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf62.met_dependencies = []
    buf62.users = [NodeUser(node=SchedulerNode(name='buf63'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf64'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf65'), can_inplace=False, is_weak=False)]
    buf62.group.device = cuda:0
    buf62.group.iteration = (256, 128)
    buf62.sizes = ([4, 64], [128])
    buf59_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf58_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf57_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf62_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf62_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf57', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf58', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf59', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf62', get_index_3, getitem_2)
            return store_reduction
    buf62 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf60_buf61_buf62 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf63_buf64_buf66_buf259_buf260_buf262_buf263: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf63_buf64_buf66_buf259_buf260_buf262_buf263.writes = 
    [   MemoryDep('buf259', c0, {c0: 64}, None),
        MemoryDep('buf260', c0, {c0: 64}, None),
        MemoryDep('buf262', c0, {c0: 64}, None),
        MemoryDep('buf263', c0, {c0: 64}, None),
        MemoryDep('buf63', c0, {c0: 64}, None),
        MemoryDep('buf64', c0, {c0: 64}, None),
        MemoryDep('buf66', c0, {c0: 64}, None)]
buf63_buf64_buf66_buf259_buf260_buf262_buf263.unmet_dependencies = 
    [   MemoryDep('buf60', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf61', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf62', c0 + 64*c1, {c0: 64, c1: 4}, None)]
buf63_buf64_buf66_buf259_buf260_buf262_buf263.met_dependencies = 
    [   MemoryDep('primals_72', c0, {c0: 64}, None),
        MemoryDep('primals_73', c0, {c0: 64}, None),
        StarDep(name='primals_72', mode=None),
        StarDep(name='primals_73', mode=None)]
buf63_buf64_buf66_buf259_buf260_buf262_buf263.users = []
    buf63_buf64_buf66_buf259_buf260_buf262_buf263.snodes[0] =
    buf63: SchedulerNode(ComputedBuffer)
    buf63.writes = [MemoryDep('buf63', c0, {c0: 64}, None)]
    buf63.unmet_dependencies = 
        [   MemoryDep('buf60', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf61', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf62', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf63.met_dependencies = []
    buf63.users = [NodeUser(node=SchedulerNode(name='buf67'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf259'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf63.group.device = cuda:0
    buf63.group.iteration = (64, 4)
    buf63.sizes = ([64], [4])
    buf61_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf62_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf60_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf63_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf63_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf60', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf61', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf62', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf63', get_index_3, getitem)
            return store_reduction
    buf63 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf63_buf64_buf66_buf259_buf260_buf262_buf263.snodes[1] =
    buf64: SchedulerNode(ComputedBuffer)
    buf64.writes = [MemoryDep('buf64', c0, {c0: 64}, None)]
    buf64.unmet_dependencies = 
        [   MemoryDep('buf60', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf61', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf62', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf64.met_dependencies = []
    buf64.users = [NodeUser(node=SchedulerNode(name='buf66'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf67'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf262'), can_inplace=True, is_weak=False)]
    buf64.group.device = cuda:0
    buf64.group.iteration = (64, 4)
    buf64.sizes = ([64], [4])
    buf61_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf62_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf60_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf64_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf64_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf60', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf61', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf62', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf64', get_index_3, getitem_1)
            return store_reduction
    buf64 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf63_buf64_buf66_buf259_buf260_buf262_buf263.snodes[2] =
    buf66: SchedulerNode(ComputedBuffer)
    buf66.writes = [MemoryDep('buf66', c0, {c0: 64}, None)]
    buf66.unmet_dependencies = [MemoryDep('buf64', c0, {c0: 64}, None)]
    buf66.met_dependencies = []
    buf66.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf66.group.device = cuda:0
    buf66.group.iteration = (64, 1)
    buf66.sizes = ([64], [])
    buf64_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf66_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf66_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf64', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf66', get_index_1, rsqrt, None)
            return store
    buf66 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf63_buf64_buf66_buf259_buf260_buf262_buf263.snodes[3] =
    buf259: SchedulerNode(ComputedBuffer)
    buf259.writes = [MemoryDep('buf259', c0, {c0: 64}, None)]
    buf259.unmet_dependencies = [MemoryDep('buf63', c0, {c0: 64}, None)]
    buf259.met_dependencies = [MemoryDep('primals_72', c0, {c0: 64}, None)]
    buf259.users = [NodeUser(node=SchedulerNode(name='buf260'), can_inplace=True, is_weak=False)]
    buf259.group.device = cuda:0
    buf259.group.iteration = (64, 1)
    buf259.sizes = ([64], [])
    buf63_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    primals_72_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf259_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf259_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf63', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_72', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf259', get_index_2, add, None)
            return store
    buf259 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf63_buf64_buf66_buf259_buf260_buf262_buf263.snodes[4] =
    buf260: SchedulerNode(ComputedBuffer)
    buf260.writes = [MemoryDep('buf260', c0, {c0: 64}, None)]
    buf260.unmet_dependencies = [MemoryDep('buf259', c0, {c0: 64}, None)]
    buf260.met_dependencies = [StarDep(name='primals_72', mode=None)]
    buf260.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf260.group.device = cuda:0
    buf260.group.iteration = (64, 1)
    buf260.sizes = ([64], [])
    primals_72_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf259_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf260_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf260.mutations = ['primals_72']
    class buf260_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf259', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf260', get_index_1, load, None)
            return store
    buf260 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf63_buf64_buf66_buf259_buf260_buf262_buf263.snodes[5] =
    buf262: SchedulerNode(ComputedBuffer)
    buf262.writes = [MemoryDep('buf262', c0, {c0: 64}, None)]
    buf262.unmet_dependencies = [MemoryDep('buf64', c0, {c0: 64}, None)]
    buf262.met_dependencies = [MemoryDep('primals_73', c0, {c0: 64}, None)]
    buf262.users = [NodeUser(node=SchedulerNode(name='buf263'), can_inplace=True, is_weak=False)]
    buf262.group.device = cuda:0
    buf262.group.iteration = (64, 1)
    buf262.sizes = ([64], [])
    primals_73_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf64_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf262_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf262_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf64', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.00000996502277, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_73', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf262', get_index_2, add, None)
            return store
    buf262 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.00000996502277
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf63_buf64_buf66_buf259_buf260_buf262_buf263.snodes[6] =
    buf263: SchedulerNode(ComputedBuffer)
    buf263.writes = [MemoryDep('buf263', c0, {c0: 64}, None)]
    buf263.unmet_dependencies = [MemoryDep('buf262', c0, {c0: 64}, None)]
    buf263.met_dependencies = [StarDep(name='primals_73', mode=None)]
    buf263.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf263.group.device = cuda:0
    buf263.group.iteration = (64, 1)
    buf263.sizes = ([64], [])
    buf262_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    primals_73_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf263_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf263.mutations = ['primals_73']
    class buf263_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf262', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf263', get_index_1, load, None)
            return store
    buf263 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf63_buf64_buf66_buf259_buf260_buf262_buf263 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 100352.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.00000996502277
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf67: SchedulerNode(ComputedBuffer)
buf67.writes = [MemoryDep('buf67', c0, {c0: 6422528}, None)]
buf67.unmet_dependencies = 
    [   MemoryDep('buf56', c0, {c0: 6422528}, None),
        MemoryDep('buf63', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf64', c1, {c0: 100352, c1: 64}, None)]
buf67.met_dependencies = 
    [   MemoryDep('primals_11', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('primals_12', c1, {c0: 100352, c1: 64}, None)]
buf67.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf68'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf67.group.device = cuda:0
buf67.group.iteration = (6422528, 1)
buf67.sizes = ([100352, 64], [])
primals_12_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf63_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
buf56_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
buf64_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
primals_11_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf67_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf67_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf56', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf63', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf64', get_index_2)
        constant = ops.constant(100352.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_11', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_12', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf67', get_index_5, relu, None)
        return store
buf67 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 100352.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf68: ExternKernelSchedulerNode(ExternKernelAlloc)
buf68.writes = [StarDep(name='buf68', mode=None)]
buf68.unmet_dependencies = [StarDep(name='buf4', mode=None), StarDep(name='buf67', mode=None)]
buf68.met_dependencies = []
buf68.users = [NodeUser(node=SchedulerNode(name='buf69'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf70'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf71'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf79'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf68.node.kernel = extern_kernels.convolution


buf69_buf70_buf71: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf69_buf70_buf71.writes = 
    [   MemoryDep('buf69', c0, {c0: 32768}, None),
        MemoryDep('buf70', c0, {c0: 32768}, None),
        MemoryDep('buf71', c0, {c0: 32768}, None)]
buf69_buf70_buf71.unmet_dependencies = [MemoryDep('buf68', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
buf69_buf70_buf71.met_dependencies = []
buf69_buf70_buf71.users = []
    buf69_buf70_buf71.snodes[0] =
    buf69: SchedulerNode(ComputedBuffer)
    buf69.writes = [MemoryDep('buf69', c0, {c0: 32768}, None)]
    buf69.unmet_dependencies = [MemoryDep('buf68', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf69.met_dependencies = []
    buf69.users = [NodeUser(node=SchedulerNode(name='buf72'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf73'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf74'), can_inplace=False, is_weak=False)]
    buf69.group.device = cuda:0
    buf69.group.iteration = (32768, 196)
    buf69.sizes = ([512, 64], [196])
    buf68_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf69_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf69_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf68', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf69', get_index_1, getitem)
            return store_reduction
    buf69 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
    buf69_buf70_buf71.snodes[1] =
    buf70: SchedulerNode(ComputedBuffer)
    buf70.writes = [MemoryDep('buf70', c0, {c0: 32768}, None)]
    buf70.unmet_dependencies = [MemoryDep('buf68', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf70.met_dependencies = []
    buf70.users = [NodeUser(node=SchedulerNode(name='buf72'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf73'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf74'), can_inplace=False, is_weak=False)]
    buf70.group.device = cuda:0
    buf70.group.iteration = (32768, 196)
    buf70.sizes = ([512, 64], [196])
    buf68_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf70_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf70_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf68', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf70', get_index_1, getitem_1)
            return store_reduction
    buf70 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, None)
    buf69_buf70_buf71.snodes[2] =
    buf71: SchedulerNode(ComputedBuffer)
    buf71.writes = [MemoryDep('buf71', c0, {c0: 32768}, None)]
    buf71.unmet_dependencies = [MemoryDep('buf68', 12544*c0 + c1 + 64*c2, {c0: 512, c1: 64, c2: 196}, None)]
    buf71.met_dependencies = []
    buf71.users = [NodeUser(node=SchedulerNode(name='buf72'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf73'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf74'), can_inplace=False, is_weak=False)]
    buf71.group.device = cuda:0
    buf71.group.iteration = (32768, 196)
    buf71.sizes = ([512, 64], [196])
    buf68_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
    buf71_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    class buf71_loop_body:
        var_ranges = {z0: 512, z1: 64, z2: 196}
        index0 = 12544*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf68', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf71', get_index_1, getitem_2)
            return store_reduction
    buf71 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, None)
    buf69_buf70_buf71 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 256],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 32768
            rnumel = 196
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (12544*x1)), rmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, None)
            tl.store(out_ptr1 + (x3), tmp3, None)
            tl.store(out_ptr2 + (x3), tmp4, None)


buf72_buf73_buf74: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf72_buf73_buf74.writes = 
    [   MemoryDep('buf72', c0, {c0: 256}, None),
        MemoryDep('buf73', c0, {c0: 256}, None),
        MemoryDep('buf74', c0, {c0: 256}, None)]
buf72_buf73_buf74.unmet_dependencies = 
    [   MemoryDep('buf69', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf70', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
        MemoryDep('buf71', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
buf72_buf73_buf74.met_dependencies = []
buf72_buf73_buf74.users = []
    buf72_buf73_buf74.snodes[0] =
    buf72: SchedulerNode(ComputedBuffer)
    buf72.writes = [MemoryDep('buf72', c0, {c0: 256}, None)]
    buf72.unmet_dependencies = 
        [   MemoryDep('buf69', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf70', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf71', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf72.met_dependencies = []
    buf72.users = [NodeUser(node=SchedulerNode(name='buf75'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf76'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf77'), can_inplace=False, is_weak=False)]
    buf72.group.device = cuda:0
    buf72.group.iteration = (256, 128)
    buf72.sizes = ([4, 64], [128])
    buf70_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf69_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf71_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf72_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf72_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf69', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf70', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf71', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf72', get_index_3, getitem)
            return store_reduction
    buf72 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf72_buf73_buf74.snodes[1] =
    buf73: SchedulerNode(ComputedBuffer)
    buf73.writes = [MemoryDep('buf73', c0, {c0: 256}, None)]
    buf73.unmet_dependencies = 
        [   MemoryDep('buf69', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf70', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf71', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf73.met_dependencies = []
    buf73.users = [NodeUser(node=SchedulerNode(name='buf75'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf76'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf77'), can_inplace=False, is_weak=False)]
    buf73.group.device = cuda:0
    buf73.group.iteration = (256, 128)
    buf73.sizes = ([4, 64], [128])
    buf70_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf69_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf71_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf73_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf73_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf69', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf70', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf71', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf73', get_index_3, getitem_1)
            return store_reduction
    buf73 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf72_buf73_buf74.snodes[2] =
    buf74: SchedulerNode(ComputedBuffer)
    buf74.writes = [MemoryDep('buf74', c0, {c0: 256}, None)]
    buf74.unmet_dependencies = 
        [   MemoryDep('buf69', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf70', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None),
            MemoryDep('buf71', 8192*c0 + c1 + 64*c2, {c0: 4, c1: 64, c2: 128}, None)]
    buf74.met_dependencies = []
    buf74.users = [NodeUser(node=SchedulerNode(name='buf75'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf76'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf77'), can_inplace=False, is_weak=False)]
    buf74.group.device = cuda:0
    buf74.group.iteration = (256, 128)
    buf74.sizes = ([4, 64], [128])
    buf70_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf69_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf71_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 512], stride=[32768, 1, 32768, 32768, 64])
    buf74_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    class buf74_loop_body:
        var_ranges = {z0: 4, z1: 64, z2: 128}
        index0 = 8192*z0 + z1 + 64*z2
        index1 = 64*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf69', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf70', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf71', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf74', get_index_3, getitem_2)
            return store_reduction
    buf74 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf72_buf73_buf74 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 64
            x1 = (xindex // 64)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf75_buf76_buf78_buf267_buf268_buf270_buf271: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf75_buf76_buf78_buf267_buf268_buf270_buf271.writes = 
    [   MemoryDep('buf267', c0, {c0: 64}, None),
        MemoryDep('buf268', c0, {c0: 64}, None),
        MemoryDep('buf270', c0, {c0: 64}, None),
        MemoryDep('buf271', c0, {c0: 64}, None),
        MemoryDep('buf75', c0, {c0: 64}, None),
        MemoryDep('buf76', c0, {c0: 64}, None),
        MemoryDep('buf78', c0, {c0: 64}, None)]
buf75_buf76_buf78_buf267_buf268_buf270_buf271.unmet_dependencies = 
    [   MemoryDep('buf72', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf73', c0 + 64*c1, {c0: 64, c1: 4}, None),
        MemoryDep('buf74', c0 + 64*c1, {c0: 64, c1: 4}, None)]
buf75_buf76_buf78_buf267_buf268_buf270_buf271.met_dependencies = 
    [   MemoryDep('primals_75', c0, {c0: 64}, None),
        MemoryDep('primals_76', c0, {c0: 64}, None),
        StarDep(name='primals_75', mode=None),
        StarDep(name='primals_76', mode=None)]
buf75_buf76_buf78_buf267_buf268_buf270_buf271.users = []
    buf75_buf76_buf78_buf267_buf268_buf270_buf271.snodes[0] =
    buf75: SchedulerNode(ComputedBuffer)
    buf75.writes = [MemoryDep('buf75', c0, {c0: 64}, None)]
    buf75.unmet_dependencies = 
        [   MemoryDep('buf72', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf73', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf74', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf75.met_dependencies = []
    buf75.users = [NodeUser(node=SchedulerNode(name='buf79'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf267'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf75.group.device = cuda:0
    buf75.group.iteration = (64, 4)
    buf75.sizes = ([64], [4])
    buf72_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf73_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf74_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf75_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf75_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf72', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf73', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf74', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf75', get_index_3, getitem)
            return store_reduction
    buf75 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf75_buf76_buf78_buf267_buf268_buf270_buf271.snodes[1] =
    buf76: SchedulerNode(ComputedBuffer)
    buf76.writes = [MemoryDep('buf76', c0, {c0: 64}, None)]
    buf76.unmet_dependencies = 
        [   MemoryDep('buf72', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf73', c0 + 64*c1, {c0: 64, c1: 4}, None),
            MemoryDep('buf74', c0 + 64*c1, {c0: 64, c1: 4}, None)]
    buf76.met_dependencies = []
    buf76.users = [NodeUser(node=SchedulerNode(name='buf78'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf79'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf270'), can_inplace=True, is_weak=False)]
    buf76.group.device = cuda:0
    buf76.group.iteration = (64, 4)
    buf76.sizes = ([64], [4])
    buf72_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf73_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf74_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1, 4], stride=[256, 1, 256, 256, 64])
    buf76_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf76_loop_body:
        var_ranges = {z0: 64, z1: 4}
        index0 = z0 + 64*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf72', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf73', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf74', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf76', get_index_3, getitem_1)
            return store_reduction
    buf76 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf75_buf76_buf78_buf267_buf268_buf270_buf271.snodes[2] =
    buf78: SchedulerNode(ComputedBuffer)
    buf78.writes = [MemoryDep('buf78', c0, {c0: 64}, None)]
    buf78.unmet_dependencies = [MemoryDep('buf76', c0, {c0: 64}, None)]
    buf78.met_dependencies = []
    buf78.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf78.group.device = cuda:0
    buf78.group.iteration = (64, 1)
    buf78.sizes = ([64], [])
    buf76_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf78_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    class buf78_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf76', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf78', get_index_1, rsqrt, None)
            return store
    buf78 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf75_buf76_buf78_buf267_buf268_buf270_buf271.snodes[3] =
    buf267: SchedulerNode(ComputedBuffer)
    buf267.writes = [MemoryDep('buf267', c0, {c0: 64}, None)]
    buf267.unmet_dependencies = [MemoryDep('buf75', c0, {c0: 64}, None)]
    buf267.met_dependencies = [MemoryDep('primals_75', c0, {c0: 64}, None)]
    buf267.users = [NodeUser(node=SchedulerNode(name='buf268'), can_inplace=True, is_weak=False)]
    buf267.group.device = cuda:0
    buf267.group.iteration = (64, 1)
    buf267.sizes = ([64], [])
    primals_75_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf75_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    buf267_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf267_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf75', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_75', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf267', get_index_2, add, None)
            return store
    buf267 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf75_buf76_buf78_buf267_buf268_buf270_buf271.snodes[4] =
    buf268: SchedulerNode(ComputedBuffer)
    buf268.writes = [MemoryDep('buf268', c0, {c0: 64}, None)]
    buf268.unmet_dependencies = [MemoryDep('buf267', c0, {c0: 64}, None)]
    buf268.met_dependencies = [StarDep(name='primals_75', mode=None)]
    buf268.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf268.group.device = cuda:0
    buf268.group.iteration = (64, 1)
    buf268.sizes = ([64], [])
    primals_75_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf267_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf268_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf268.mutations = ['primals_75']
    class buf268_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf267', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf268', get_index_1, load, None)
            return store
    buf268 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf75_buf76_buf78_buf267_buf268_buf270_buf271.snodes[5] =
    buf270: SchedulerNode(ComputedBuffer)
    buf270.writes = [MemoryDep('buf270', c0, {c0: 64}, None)]
    buf270.unmet_dependencies = [MemoryDep('buf76', c0, {c0: 64}, None)]
    buf270.met_dependencies = [MemoryDep('primals_76', c0, {c0: 64}, None)]
    buf270.users = [NodeUser(node=SchedulerNode(name='buf271'), can_inplace=True, is_weak=False)]
    buf270.group.device = cuda:0
    buf270.group.iteration = (64, 1)
    buf270.sizes = ([64], [])
    buf76_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
    primals_76_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf270_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    class buf270_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf76', get_index)
            constant = ops.constant(100352.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.00000996502277, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_76', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf270', get_index_2, add, None)
            return store
    buf270 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 100352.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.00000996502277
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf75_buf76_buf78_buf267_buf268_buf270_buf271.snodes[6] =
    buf271: SchedulerNode(ComputedBuffer)
    buf271.writes = [MemoryDep('buf271', c0, {c0: 64}, None)]
    buf271.unmet_dependencies = [MemoryDep('buf270', c0, {c0: 64}, None)]
    buf271.met_dependencies = [StarDep(name='primals_76', mode=None)]
    buf271.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf271.group.device = cuda:0
    buf271.group.iteration = (64, 1)
    buf271.sizes = ([64], [])
    buf270_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    primals_76_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
    buf271_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[64], stride=[1])
    buf271.mutations = ['primals_76']
    class buf271_loop_body:
        var_ranges = {z0: 64}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf270', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf271', get_index_1, load, None)
            return store
    buf271 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[64], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf75_buf76_buf78_buf267_buf268_buf270_buf271 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[64, 4],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 64
            rnumel = 4
            RBLOCK: tl.constexpr = 4
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 100352.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.00000996502277
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf79: SchedulerNode(ComputedBuffer)
buf79.writes = [MemoryDep('buf79', c0, {c0: 6422528}, None)]
buf79.unmet_dependencies = 
    [   MemoryDep('buf55', c0, {c0: 6422528}, None),
        MemoryDep('buf68', c0, {c0: 6422528}, None),
        MemoryDep('buf75', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('buf76', c1, {c0: 100352, c1: 64}, None)]
buf79.met_dependencies = 
    [   MemoryDep('primals_14', c1, {c0: 100352, c1: 64}, None),
        MemoryDep('primals_15', c1, {c0: 100352, c1: 64}, None)]
buf79.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf80'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf103'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf79.group.device = cuda:0
buf79.group.iteration = (6422528, 1)
buf79.sizes = ([100352, 64], [])
buf55_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
primals_14_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf68_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
primals_15_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf75_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
buf76_layout = FixedLayout('cuda', torch.float32, size=[1, 64, 1, 1], stride=[64, 1, 64, 64])
buf79_layout = FixedLayout('cuda', torch.float32, size=[32, 64, 56, 56], stride=[200704, 1, 3584, 64])
class buf79_loop_body:
    var_ranges = {z0: 100352, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf68', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf75', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf76', get_index_2)
        constant = ops.constant(100352.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_14', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_15', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        get_index_5 = self.get_index('index0')
        load_5 = ops.load('buf55', get_index_5)
        add_2 = ops.add(add_1, load_5)
        relu = ops.relu(add_2)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf79', get_index_6, relu, None)
        return store
buf79 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8388608], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 6422528
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 64
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp14 = tl.load(in_ptr5 + (x2), None)
        tmp2 = tmp0 - tmp1
        tmp4 = 100352.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp15 = tmp13 + tmp14
        tmp16 = tl.full([1], 0, tl.int32)
        tmp17 = triton_helpers.maximum(tmp16, tmp15)
        tl.store(out_ptr0 + (x2), tmp17, None)


buf80: ExternKernelSchedulerNode(ExternKernelAlloc)
buf80.writes = [StarDep(name='buf80', mode=None)]
buf80.unmet_dependencies = [StarDep(name='buf5', mode=None), StarDep(name='buf79', mode=None)]
buf80.met_dependencies = []
buf80.users = [NodeUser(node=SchedulerNode(name='buf81'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf82'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf83'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf91'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf80.node.kernel = extern_kernels.convolution


buf81_buf82_buf83: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf81_buf82_buf83.writes = 
    [   MemoryDep('buf81', c0, {c0: 25088}, None),
        MemoryDep('buf82', c0, {c0: 25088}, None),
        MemoryDep('buf83', c0, {c0: 25088}, None)]
buf81_buf82_buf83.unmet_dependencies = [MemoryDep('buf80', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf81_buf82_buf83.met_dependencies = []
buf81_buf82_buf83.users = []
    buf81_buf82_buf83.snodes[0] =
    buf81: SchedulerNode(ComputedBuffer)
    buf81.writes = [MemoryDep('buf81', c0, {c0: 25088}, None)]
    buf81.unmet_dependencies = [MemoryDep('buf80', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf81.met_dependencies = []
    buf81.users = [NodeUser(node=SchedulerNode(name='buf84'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf85'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf86'), can_inplace=False, is_weak=False)]
    buf81.group.device = cuda:0
    buf81.group.iteration = (25088, 128)
    buf81.sizes = ([196, 128], [128])
    buf80_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf81_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf81_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf80', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf81', get_index_1, getitem)
            return store_reduction
    buf81 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf81_buf82_buf83.snodes[1] =
    buf82: SchedulerNode(ComputedBuffer)
    buf82.writes = [MemoryDep('buf82', c0, {c0: 25088}, None)]
    buf82.unmet_dependencies = [MemoryDep('buf80', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf82.met_dependencies = []
    buf82.users = [NodeUser(node=SchedulerNode(name='buf84'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf85'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf86'), can_inplace=False, is_weak=False)]
    buf82.group.device = cuda:0
    buf82.group.iteration = (25088, 128)
    buf82.sizes = ([196, 128], [128])
    buf80_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf82_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf82_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf80', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf82', get_index_1, getitem_1)
            return store_reduction
    buf82 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf81_buf82_buf83.snodes[2] =
    buf83: SchedulerNode(ComputedBuffer)
    buf83.writes = [MemoryDep('buf83', c0, {c0: 25088}, None)]
    buf83.unmet_dependencies = [MemoryDep('buf80', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf83.met_dependencies = []
    buf83.users = [NodeUser(node=SchedulerNode(name='buf84'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf85'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf86'), can_inplace=False, is_weak=False)]
    buf83.group.device = cuda:0
    buf83.group.iteration = (25088, 128)
    buf83.sizes = ([196, 128], [128])
    buf80_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf83_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf83_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf80', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf83', get_index_1, getitem_2)
            return store_reduction
    buf83 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf81_buf82_buf83 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf84_buf85_buf86: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf84_buf85_buf86.writes = 
    [   MemoryDep('buf84', c0, {c0: 256}, None),
        MemoryDep('buf85', c0, {c0: 256}, None),
        MemoryDep('buf86', c0, {c0: 256}, None)]
buf84_buf85_buf86.unmet_dependencies = 
    [   MemoryDep('buf81', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf82', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf83', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
buf84_buf85_buf86.met_dependencies = []
buf84_buf85_buf86.users = []
    buf84_buf85_buf86.snodes[0] =
    buf84: SchedulerNode(ComputedBuffer)
    buf84.writes = [MemoryDep('buf84', c0, {c0: 256}, None)]
    buf84.unmet_dependencies = 
        [   MemoryDep('buf81', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf82', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf83', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf84.met_dependencies = []
    buf84.users = [NodeUser(node=SchedulerNode(name='buf87'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf88'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf89'), can_inplace=False, is_weak=False)]
    buf84.group.device = cuda:0
    buf84.group.iteration = (256, 98)
    buf84.sizes = ([2, 128], [98])
    buf82_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf83_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf81_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf84_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf84_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf81', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf82', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf83', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf84', get_index_3, getitem)
            return store_reduction
    buf84 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf84_buf85_buf86.snodes[1] =
    buf85: SchedulerNode(ComputedBuffer)
    buf85.writes = [MemoryDep('buf85', c0, {c0: 256}, None)]
    buf85.unmet_dependencies = 
        [   MemoryDep('buf81', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf82', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf83', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf85.met_dependencies = []
    buf85.users = [NodeUser(node=SchedulerNode(name='buf87'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf88'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf89'), can_inplace=False, is_weak=False)]
    buf85.group.device = cuda:0
    buf85.group.iteration = (256, 98)
    buf85.sizes = ([2, 128], [98])
    buf82_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf83_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf81_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf85_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf85_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf81', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf82', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf83', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf85', get_index_3, getitem_1)
            return store_reduction
    buf85 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf84_buf85_buf86.snodes[2] =
    buf86: SchedulerNode(ComputedBuffer)
    buf86.writes = [MemoryDep('buf86', c0, {c0: 256}, None)]
    buf86.unmet_dependencies = 
        [   MemoryDep('buf81', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf82', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf83', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf86.met_dependencies = []
    buf86.users = [NodeUser(node=SchedulerNode(name='buf87'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf88'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf89'), can_inplace=False, is_weak=False)]
    buf86.group.device = cuda:0
    buf86.group.iteration = (256, 98)
    buf86.sizes = ([2, 128], [98])
    buf82_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf83_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf81_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf86_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf86_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf81', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf82', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf83', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf86', get_index_3, getitem_2)
            return store_reduction
    buf86 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf84_buf85_buf86 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf87_buf88_buf90_buf275_buf276_buf278_buf279: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf87_buf88_buf90_buf275_buf276_buf278_buf279.writes = 
    [   MemoryDep('buf275', c0, {c0: 128}, None),
        MemoryDep('buf276', c0, {c0: 128}, None),
        MemoryDep('buf278', c0, {c0: 128}, None),
        MemoryDep('buf279', c0, {c0: 128}, None),
        MemoryDep('buf87', c0, {c0: 128}, None),
        MemoryDep('buf88', c0, {c0: 128}, None),
        MemoryDep('buf90', c0, {c0: 128}, None)]
buf87_buf88_buf90_buf275_buf276_buf278_buf279.unmet_dependencies = 
    [   MemoryDep('buf84', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf85', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf86', c0 + 128*c1, {c0: 128, c1: 2}, None)]
buf87_buf88_buf90_buf275_buf276_buf278_buf279.met_dependencies = 
    [   MemoryDep('primals_78', c0, {c0: 128}, None),
        MemoryDep('primals_79', c0, {c0: 128}, None),
        StarDep(name='primals_78', mode=None),
        StarDep(name='primals_79', mode=None)]
buf87_buf88_buf90_buf275_buf276_buf278_buf279.users = []
    buf87_buf88_buf90_buf275_buf276_buf278_buf279.snodes[0] =
    buf87: SchedulerNode(ComputedBuffer)
    buf87.writes = [MemoryDep('buf87', c0, {c0: 128}, None)]
    buf87.unmet_dependencies = 
        [   MemoryDep('buf84', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf85', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf86', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf87.met_dependencies = []
    buf87.users = [NodeUser(node=SchedulerNode(name='buf91'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf275'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf87.group.device = cuda:0
    buf87.group.iteration = (128, 2)
    buf87.sizes = ([128], [2])
    buf84_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf85_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf86_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf87_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf87_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf84', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf85', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf86', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf87', get_index_3, getitem)
            return store_reduction
    buf87 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf87_buf88_buf90_buf275_buf276_buf278_buf279.snodes[1] =
    buf88: SchedulerNode(ComputedBuffer)
    buf88.writes = [MemoryDep('buf88', c0, {c0: 128}, None)]
    buf88.unmet_dependencies = 
        [   MemoryDep('buf84', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf85', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf86', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf88.met_dependencies = []
    buf88.users = [NodeUser(node=SchedulerNode(name='buf90'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf91'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf278'), can_inplace=True, is_weak=False)]
    buf88.group.device = cuda:0
    buf88.group.iteration = (128, 2)
    buf88.sizes = ([128], [2])
    buf84_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf85_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf86_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf88_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf88_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf84', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf85', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf86', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf88', get_index_3, getitem_1)
            return store_reduction
    buf88 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf87_buf88_buf90_buf275_buf276_buf278_buf279.snodes[2] =
    buf90: SchedulerNode(ComputedBuffer)
    buf90.writes = [MemoryDep('buf90', c0, {c0: 128}, None)]
    buf90.unmet_dependencies = [MemoryDep('buf88', c0, {c0: 128}, None)]
    buf90.met_dependencies = []
    buf90.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf90.group.device = cuda:0
    buf90.group.iteration = (128, 1)
    buf90.sizes = ([128], [])
    buf88_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf90_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf90_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf88', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf90', get_index_1, rsqrt, None)
            return store
    buf90 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf87_buf88_buf90_buf275_buf276_buf278_buf279.snodes[3] =
    buf275: SchedulerNode(ComputedBuffer)
    buf275.writes = [MemoryDep('buf275', c0, {c0: 128}, None)]
    buf275.unmet_dependencies = [MemoryDep('buf87', c0, {c0: 128}, None)]
    buf275.met_dependencies = [MemoryDep('primals_78', c0, {c0: 128}, None)]
    buf275.users = [NodeUser(node=SchedulerNode(name='buf276'), can_inplace=True, is_weak=False)]
    buf275.group.device = cuda:0
    buf275.group.iteration = (128, 1)
    buf275.sizes = ([128], [])
    primals_78_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf87_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf275_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf275_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf87', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_78', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf275', get_index_2, add, None)
            return store
    buf275 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf87_buf88_buf90_buf275_buf276_buf278_buf279.snodes[4] =
    buf276: SchedulerNode(ComputedBuffer)
    buf276.writes = [MemoryDep('buf276', c0, {c0: 128}, None)]
    buf276.unmet_dependencies = [MemoryDep('buf275', c0, {c0: 128}, None)]
    buf276.met_dependencies = [StarDep(name='primals_78', mode=None)]
    buf276.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf276.group.device = cuda:0
    buf276.group.iteration = (128, 1)
    buf276.sizes = ([128], [])
    primals_78_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf275_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf276_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf276.mutations = ['primals_78']
    class buf276_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf275', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf276', get_index_1, load, None)
            return store
    buf276 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf87_buf88_buf90_buf275_buf276_buf278_buf279.snodes[5] =
    buf278: SchedulerNode(ComputedBuffer)
    buf278.writes = [MemoryDep('buf278', c0, {c0: 128}, None)]
    buf278.unmet_dependencies = [MemoryDep('buf88', c0, {c0: 128}, None)]
    buf278.met_dependencies = [MemoryDep('primals_79', c0, {c0: 128}, None)]
    buf278.users = [NodeUser(node=SchedulerNode(name='buf279'), can_inplace=True, is_weak=False)]
    buf278.group.device = cuda:0
    buf278.group.iteration = (128, 1)
    buf278.sizes = ([128], [])
    primals_79_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf88_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf278_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf278_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf88', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0000398612827361, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_79', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf278', get_index_2, add, None)
            return store
    buf278 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0000398612827361
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf87_buf88_buf90_buf275_buf276_buf278_buf279.snodes[6] =
    buf279: SchedulerNode(ComputedBuffer)
    buf279.writes = [MemoryDep('buf279', c0, {c0: 128}, None)]
    buf279.unmet_dependencies = [MemoryDep('buf278', c0, {c0: 128}, None)]
    buf279.met_dependencies = [StarDep(name='primals_79', mode=None)]
    buf279.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf279.group.device = cuda:0
    buf279.group.iteration = (128, 1)
    buf279.sizes = ([128], [])
    buf278_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    primals_79_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf279_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf279.mutations = ['primals_79']
    class buf279_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf278', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf279', get_index_1, load, None)
            return store
    buf279 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf87_buf88_buf90_buf275_buf276_buf278_buf279 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 25088.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0000398612827361
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf91: SchedulerNode(ComputedBuffer)
buf91.writes = [MemoryDep('buf91', c0, {c0: 3211264}, None)]
buf91.unmet_dependencies = 
    [   MemoryDep('buf80', c0, {c0: 3211264}, None),
        MemoryDep('buf87', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf88', c1, {c0: 25088, c1: 128}, None)]
buf91.met_dependencies = 
    [   MemoryDep('primals_17', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('primals_18', c1, {c0: 25088, c1: 128}, None)]
buf91.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf92'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf91.group.device = cuda:0
buf91.group.iteration = (3211264, 1)
buf91.sizes = ([25088, 128], [])
buf87_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
primals_18_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
primals_17_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf80_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf88_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
buf91_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf91_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf80', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf87', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf88', get_index_2)
        constant = ops.constant(25088.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_17', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_18', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf91', get_index_5, relu, None)
        return store
buf91 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 25088.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf92: ExternKernelSchedulerNode(ExternKernelAlloc)
buf92.writes = [StarDep(name='buf92', mode=None)]
buf92.unmet_dependencies = [StarDep(name='buf6', mode=None), StarDep(name='buf91', mode=None)]
buf92.met_dependencies = []
buf92.users = [NodeUser(node=SchedulerNode(name='buf93'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf94'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf95'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf114'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf92.node.kernel = extern_kernels.convolution


buf93_buf94_buf95: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf93_buf94_buf95.writes = 
    [   MemoryDep('buf93', c0, {c0: 25088}, None),
        MemoryDep('buf94', c0, {c0: 25088}, None),
        MemoryDep('buf95', c0, {c0: 25088}, None)]
buf93_buf94_buf95.unmet_dependencies = [MemoryDep('buf92', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf93_buf94_buf95.met_dependencies = []
buf93_buf94_buf95.users = []
    buf93_buf94_buf95.snodes[0] =
    buf93: SchedulerNode(ComputedBuffer)
    buf93.writes = [MemoryDep('buf93', c0, {c0: 25088}, None)]
    buf93.unmet_dependencies = [MemoryDep('buf92', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf93.met_dependencies = []
    buf93.users = [NodeUser(node=SchedulerNode(name='buf96'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf97'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf98'), can_inplace=False, is_weak=False)]
    buf93.group.device = cuda:0
    buf93.group.iteration = (25088, 128)
    buf93.sizes = ([196, 128], [128])
    buf92_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf93_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf93_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf92', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf93', get_index_1, getitem)
            return store_reduction
    buf93 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf93_buf94_buf95.snodes[1] =
    buf94: SchedulerNode(ComputedBuffer)
    buf94.writes = [MemoryDep('buf94', c0, {c0: 25088}, None)]
    buf94.unmet_dependencies = [MemoryDep('buf92', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf94.met_dependencies = []
    buf94.users = [NodeUser(node=SchedulerNode(name='buf96'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf97'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf98'), can_inplace=False, is_weak=False)]
    buf94.group.device = cuda:0
    buf94.group.iteration = (25088, 128)
    buf94.sizes = ([196, 128], [128])
    buf92_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf94_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf94_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf92', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf94', get_index_1, getitem_1)
            return store_reduction
    buf94 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf93_buf94_buf95.snodes[2] =
    buf95: SchedulerNode(ComputedBuffer)
    buf95.writes = [MemoryDep('buf95', c0, {c0: 25088}, None)]
    buf95.unmet_dependencies = [MemoryDep('buf92', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf95.met_dependencies = []
    buf95.users = [NodeUser(node=SchedulerNode(name='buf96'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf97'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf98'), can_inplace=False, is_weak=False)]
    buf95.group.device = cuda:0
    buf95.group.iteration = (25088, 128)
    buf95.sizes = ([196, 128], [128])
    buf92_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf95_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf95_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf92', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf95', get_index_1, getitem_2)
            return store_reduction
    buf95 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf93_buf94_buf95 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf96_buf97_buf98: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf96_buf97_buf98.writes = 
    [   MemoryDep('buf96', c0, {c0: 256}, None),
        MemoryDep('buf97', c0, {c0: 256}, None),
        MemoryDep('buf98', c0, {c0: 256}, None)]
buf96_buf97_buf98.unmet_dependencies = 
    [   MemoryDep('buf93', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf94', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf95', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
buf96_buf97_buf98.met_dependencies = []
buf96_buf97_buf98.users = []
    buf96_buf97_buf98.snodes[0] =
    buf96: SchedulerNode(ComputedBuffer)
    buf96.writes = [MemoryDep('buf96', c0, {c0: 256}, None)]
    buf96.unmet_dependencies = 
        [   MemoryDep('buf93', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf94', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf95', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf96.met_dependencies = []
    buf96.users = [NodeUser(node=SchedulerNode(name='buf99'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf100'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf101'), can_inplace=False, is_weak=False)]
    buf96.group.device = cuda:0
    buf96.group.iteration = (256, 98)
    buf96.sizes = ([2, 128], [98])
    buf95_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf93_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf94_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf96_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf96_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf93', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf94', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf95', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf96', get_index_3, getitem)
            return store_reduction
    buf96 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf96_buf97_buf98.snodes[1] =
    buf97: SchedulerNode(ComputedBuffer)
    buf97.writes = [MemoryDep('buf97', c0, {c0: 256}, None)]
    buf97.unmet_dependencies = 
        [   MemoryDep('buf93', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf94', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf95', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf97.met_dependencies = []
    buf97.users = [NodeUser(node=SchedulerNode(name='buf99'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf100'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf101'), can_inplace=False, is_weak=False)]
    buf97.group.device = cuda:0
    buf97.group.iteration = (256, 98)
    buf97.sizes = ([2, 128], [98])
    buf95_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf93_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf94_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf97_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf97_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf93', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf94', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf95', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf97', get_index_3, getitem_1)
            return store_reduction
    buf97 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf96_buf97_buf98.snodes[2] =
    buf98: SchedulerNode(ComputedBuffer)
    buf98.writes = [MemoryDep('buf98', c0, {c0: 256}, None)]
    buf98.unmet_dependencies = 
        [   MemoryDep('buf93', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf94', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf95', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf98.met_dependencies = []
    buf98.users = [NodeUser(node=SchedulerNode(name='buf99'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf100'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf101'), can_inplace=False, is_weak=False)]
    buf98.group.device = cuda:0
    buf98.group.iteration = (256, 98)
    buf98.sizes = ([2, 128], [98])
    buf95_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf93_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf94_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf98_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf98_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf93', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf94', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf95', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf98', get_index_3, getitem_2)
            return store_reduction
    buf98 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf96_buf97_buf98 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf99_buf100_buf102_buf283_buf284_buf286_buf287: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf99_buf100_buf102_buf283_buf284_buf286_buf287.writes = 
    [   MemoryDep('buf100', c0, {c0: 128}, None),
        MemoryDep('buf102', c0, {c0: 128}, None),
        MemoryDep('buf283', c0, {c0: 128}, None),
        MemoryDep('buf284', c0, {c0: 128}, None),
        MemoryDep('buf286', c0, {c0: 128}, None),
        MemoryDep('buf287', c0, {c0: 128}, None),
        MemoryDep('buf99', c0, {c0: 128}, None)]
buf99_buf100_buf102_buf283_buf284_buf286_buf287.unmet_dependencies = 
    [   MemoryDep('buf96', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf97', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf98', c0 + 128*c1, {c0: 128, c1: 2}, None)]
buf99_buf100_buf102_buf283_buf284_buf286_buf287.met_dependencies = 
    [   MemoryDep('primals_81', c0, {c0: 128}, None),
        MemoryDep('primals_82', c0, {c0: 128}, None),
        StarDep(name='primals_81', mode=None),
        StarDep(name='primals_82', mode=None)]
buf99_buf100_buf102_buf283_buf284_buf286_buf287.users = []
    buf99_buf100_buf102_buf283_buf284_buf286_buf287.snodes[0] =
    buf99: SchedulerNode(ComputedBuffer)
    buf99.writes = [MemoryDep('buf99', c0, {c0: 128}, None)]
    buf99.unmet_dependencies = 
        [   MemoryDep('buf96', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf97', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf98', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf99.met_dependencies = []
    buf99.users = [NodeUser(node=SchedulerNode(name='buf114'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf283'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf99.group.device = cuda:0
    buf99.group.iteration = (128, 2)
    buf99.sizes = ([128], [2])
    buf98_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf96_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf97_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf99_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf99_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf96', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf97', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf98', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf99', get_index_3, getitem)
            return store_reduction
    buf99 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf99_buf100_buf102_buf283_buf284_buf286_buf287.snodes[1] =
    buf100: SchedulerNode(ComputedBuffer)
    buf100.writes = [MemoryDep('buf100', c0, {c0: 128}, None)]
    buf100.unmet_dependencies = 
        [   MemoryDep('buf96', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf97', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf98', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf100.met_dependencies = []
    buf100.users = [NodeUser(node=SchedulerNode(name='buf102'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf114'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf286'), can_inplace=True, is_weak=False)]
    buf100.group.device = cuda:0
    buf100.group.iteration = (128, 2)
    buf100.sizes = ([128], [2])
    buf98_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf96_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf97_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf100_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf100_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf96', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf97', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf98', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf100', get_index_3, getitem_1)
            return store_reduction
    buf100 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf99_buf100_buf102_buf283_buf284_buf286_buf287.snodes[2] =
    buf102: SchedulerNode(ComputedBuffer)
    buf102.writes = [MemoryDep('buf102', c0, {c0: 128}, None)]
    buf102.unmet_dependencies = [MemoryDep('buf100', c0, {c0: 128}, None)]
    buf102.met_dependencies = []
    buf102.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf102.group.device = cuda:0
    buf102.group.iteration = (128, 1)
    buf102.sizes = ([128], [])
    buf100_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf102_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf102_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf100', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf102', get_index_1, rsqrt, None)
            return store
    buf102 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf99_buf100_buf102_buf283_buf284_buf286_buf287.snodes[3] =
    buf283: SchedulerNode(ComputedBuffer)
    buf283.writes = [MemoryDep('buf283', c0, {c0: 128}, None)]
    buf283.unmet_dependencies = [MemoryDep('buf99', c0, {c0: 128}, None)]
    buf283.met_dependencies = [MemoryDep('primals_81', c0, {c0: 128}, None)]
    buf283.users = [NodeUser(node=SchedulerNode(name='buf284'), can_inplace=True, is_weak=False)]
    buf283.group.device = cuda:0
    buf283.group.iteration = (128, 1)
    buf283.sizes = ([128], [])
    buf99_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    primals_81_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf283_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf283_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf99', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_81', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf283', get_index_2, add, None)
            return store
    buf283 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf99_buf100_buf102_buf283_buf284_buf286_buf287.snodes[4] =
    buf284: SchedulerNode(ComputedBuffer)
    buf284.writes = [MemoryDep('buf284', c0, {c0: 128}, None)]
    buf284.unmet_dependencies = [MemoryDep('buf283', c0, {c0: 128}, None)]
    buf284.met_dependencies = [StarDep(name='primals_81', mode=None)]
    buf284.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf284.group.device = cuda:0
    buf284.group.iteration = (128, 1)
    buf284.sizes = ([128], [])
    buf283_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    primals_81_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf284_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf284.mutations = ['primals_81']
    class buf284_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf283', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf284', get_index_1, load, None)
            return store
    buf284 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf99_buf100_buf102_buf283_buf284_buf286_buf287.snodes[5] =
    buf286: SchedulerNode(ComputedBuffer)
    buf286.writes = [MemoryDep('buf286', c0, {c0: 128}, None)]
    buf286.unmet_dependencies = [MemoryDep('buf100', c0, {c0: 128}, None)]
    buf286.met_dependencies = [MemoryDep('primals_82', c0, {c0: 128}, None)]
    buf286.users = [NodeUser(node=SchedulerNode(name='buf287'), can_inplace=True, is_weak=False)]
    buf286.group.device = cuda:0
    buf286.group.iteration = (128, 1)
    buf286.sizes = ([128], [])
    primals_82_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf100_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf286_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf286_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf100', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0000398612827361, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_82', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf286', get_index_2, add, None)
            return store
    buf286 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0000398612827361
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf99_buf100_buf102_buf283_buf284_buf286_buf287.snodes[6] =
    buf287: SchedulerNode(ComputedBuffer)
    buf287.writes = [MemoryDep('buf287', c0, {c0: 128}, None)]
    buf287.unmet_dependencies = [MemoryDep('buf286', c0, {c0: 128}, None)]
    buf287.met_dependencies = [StarDep(name='primals_82', mode=None)]
    buf287.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf287.group.device = cuda:0
    buf287.group.iteration = (128, 1)
    buf287.sizes = ([128], [])
    buf286_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    primals_82_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf287_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf287.mutations = ['primals_82']
    class buf287_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf286', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf287', get_index_1, load, None)
            return store
    buf287 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf99_buf100_buf102_buf283_buf284_buf286_buf287 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 25088.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0000398612827361
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf103: ExternKernelSchedulerNode(ExternKernelAlloc)
buf103.writes = [StarDep(name='buf103', mode=None)]
buf103.unmet_dependencies = [StarDep(name='buf79', mode=None)]
buf103.met_dependencies = [StarDep(name='primals_22', mode=None)]
buf103.users = [NodeUser(node=SchedulerNode(name='buf104'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf105'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf106'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf114'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf103.node.kernel = extern_kernels.convolution


buf104_buf105_buf106: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf104_buf105_buf106.writes = 
    [   MemoryDep('buf104', c0, {c0: 25088}, None),
        MemoryDep('buf105', c0, {c0: 25088}, None),
        MemoryDep('buf106', c0, {c0: 25088}, None)]
buf104_buf105_buf106.unmet_dependencies = [MemoryDep('buf103', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf104_buf105_buf106.met_dependencies = []
buf104_buf105_buf106.users = []
    buf104_buf105_buf106.snodes[0] =
    buf104: SchedulerNode(ComputedBuffer)
    buf104.writes = [MemoryDep('buf104', c0, {c0: 25088}, None)]
    buf104.unmet_dependencies = [MemoryDep('buf103', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf104.met_dependencies = []
    buf104.users = [NodeUser(node=SchedulerNode(name='buf107'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf108'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf109'), can_inplace=False, is_weak=False)]
    buf104.group.device = cuda:0
    buf104.group.iteration = (25088, 128)
    buf104.sizes = ([196, 128], [128])
    buf103_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf104_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf104_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf103', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf104', get_index_1, getitem)
            return store_reduction
    buf104 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf104_buf105_buf106.snodes[1] =
    buf105: SchedulerNode(ComputedBuffer)
    buf105.writes = [MemoryDep('buf105', c0, {c0: 25088}, None)]
    buf105.unmet_dependencies = [MemoryDep('buf103', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf105.met_dependencies = []
    buf105.users = [NodeUser(node=SchedulerNode(name='buf107'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf108'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf109'), can_inplace=False, is_weak=False)]
    buf105.group.device = cuda:0
    buf105.group.iteration = (25088, 128)
    buf105.sizes = ([196, 128], [128])
    buf103_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf105_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf105_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf103', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf105', get_index_1, getitem_1)
            return store_reduction
    buf105 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf104_buf105_buf106.snodes[2] =
    buf106: SchedulerNode(ComputedBuffer)
    buf106.writes = [MemoryDep('buf106', c0, {c0: 25088}, None)]
    buf106.unmet_dependencies = [MemoryDep('buf103', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf106.met_dependencies = []
    buf106.users = [NodeUser(node=SchedulerNode(name='buf107'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf108'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf109'), can_inplace=False, is_weak=False)]
    buf106.group.device = cuda:0
    buf106.group.iteration = (25088, 128)
    buf106.sizes = ([196, 128], [128])
    buf103_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf106_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf106_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf103', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf106', get_index_1, getitem_2)
            return store_reduction
    buf106 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf104_buf105_buf106 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf107_buf108_buf109: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf107_buf108_buf109.writes = 
    [   MemoryDep('buf107', c0, {c0: 256}, None),
        MemoryDep('buf108', c0, {c0: 256}, None),
        MemoryDep('buf109', c0, {c0: 256}, None)]
buf107_buf108_buf109.unmet_dependencies = 
    [   MemoryDep('buf104', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf105', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf106', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
buf107_buf108_buf109.met_dependencies = []
buf107_buf108_buf109.users = []
    buf107_buf108_buf109.snodes[0] =
    buf107: SchedulerNode(ComputedBuffer)
    buf107.writes = [MemoryDep('buf107', c0, {c0: 256}, None)]
    buf107.unmet_dependencies = 
        [   MemoryDep('buf104', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf105', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf106', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf107.met_dependencies = []
    buf107.users = [NodeUser(node=SchedulerNode(name='buf110'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf111'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf112'), can_inplace=False, is_weak=False)]
    buf107.group.device = cuda:0
    buf107.group.iteration = (256, 98)
    buf107.sizes = ([2, 128], [98])
    buf106_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf105_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf104_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf107_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf107_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf104', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf105', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf106', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf107', get_index_3, getitem)
            return store_reduction
    buf107 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf107_buf108_buf109.snodes[1] =
    buf108: SchedulerNode(ComputedBuffer)
    buf108.writes = [MemoryDep('buf108', c0, {c0: 256}, None)]
    buf108.unmet_dependencies = 
        [   MemoryDep('buf104', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf105', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf106', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf108.met_dependencies = []
    buf108.users = [NodeUser(node=SchedulerNode(name='buf110'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf111'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf112'), can_inplace=False, is_weak=False)]
    buf108.group.device = cuda:0
    buf108.group.iteration = (256, 98)
    buf108.sizes = ([2, 128], [98])
    buf106_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf105_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf104_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf108_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf108_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf104', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf105', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf106', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf108', get_index_3, getitem_1)
            return store_reduction
    buf108 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf107_buf108_buf109.snodes[2] =
    buf109: SchedulerNode(ComputedBuffer)
    buf109.writes = [MemoryDep('buf109', c0, {c0: 256}, None)]
    buf109.unmet_dependencies = 
        [   MemoryDep('buf104', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf105', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf106', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf109.met_dependencies = []
    buf109.users = [NodeUser(node=SchedulerNode(name='buf110'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf111'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf112'), can_inplace=False, is_weak=False)]
    buf109.group.device = cuda:0
    buf109.group.iteration = (256, 98)
    buf109.sizes = ([2, 128], [98])
    buf106_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf105_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf104_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf109_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf109_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf104', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf105', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf106', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf109', get_index_3, getitem_2)
            return store_reduction
    buf109 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf107_buf108_buf109 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf110_buf111_buf113_buf291_buf292_buf294_buf295: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf110_buf111_buf113_buf291_buf292_buf294_buf295.writes = 
    [   MemoryDep('buf110', c0, {c0: 128}, None),
        MemoryDep('buf111', c0, {c0: 128}, None),
        MemoryDep('buf113', c0, {c0: 128}, None),
        MemoryDep('buf291', c0, {c0: 128}, None),
        MemoryDep('buf292', c0, {c0: 128}, None),
        MemoryDep('buf294', c0, {c0: 128}, None),
        MemoryDep('buf295', c0, {c0: 128}, None)]
buf110_buf111_buf113_buf291_buf292_buf294_buf295.unmet_dependencies = 
    [   MemoryDep('buf107', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf108', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf109', c0 + 128*c1, {c0: 128, c1: 2}, None)]
buf110_buf111_buf113_buf291_buf292_buf294_buf295.met_dependencies = 
    [   MemoryDep('primals_84', c0, {c0: 128}, None),
        MemoryDep('primals_85', c0, {c0: 128}, None),
        StarDep(name='primals_84', mode=None),
        StarDep(name='primals_85', mode=None)]
buf110_buf111_buf113_buf291_buf292_buf294_buf295.users = []
    buf110_buf111_buf113_buf291_buf292_buf294_buf295.snodes[0] =
    buf110: SchedulerNode(ComputedBuffer)
    buf110.writes = [MemoryDep('buf110', c0, {c0: 128}, None)]
    buf110.unmet_dependencies = 
        [   MemoryDep('buf107', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf108', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf109', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf110.met_dependencies = []
    buf110.users = [NodeUser(node=SchedulerNode(name='buf114'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf291'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf110.group.device = cuda:0
    buf110.group.iteration = (128, 2)
    buf110.sizes = ([128], [2])
    buf107_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf108_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf109_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf110_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf110_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf107', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf108', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf109', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf110', get_index_3, getitem)
            return store_reduction
    buf110 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf110_buf111_buf113_buf291_buf292_buf294_buf295.snodes[1] =
    buf111: SchedulerNode(ComputedBuffer)
    buf111.writes = [MemoryDep('buf111', c0, {c0: 128}, None)]
    buf111.unmet_dependencies = 
        [   MemoryDep('buf107', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf108', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf109', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf111.met_dependencies = []
    buf111.users = [NodeUser(node=SchedulerNode(name='buf113'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf114'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf294'), can_inplace=True, is_weak=False)]
    buf111.group.device = cuda:0
    buf111.group.iteration = (128, 2)
    buf111.sizes = ([128], [2])
    buf107_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf108_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf109_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf111_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf111_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf107', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf108', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf109', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf111', get_index_3, getitem_1)
            return store_reduction
    buf111 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf110_buf111_buf113_buf291_buf292_buf294_buf295.snodes[2] =
    buf113: SchedulerNode(ComputedBuffer)
    buf113.writes = [MemoryDep('buf113', c0, {c0: 128}, None)]
    buf113.unmet_dependencies = [MemoryDep('buf111', c0, {c0: 128}, None)]
    buf113.met_dependencies = []
    buf113.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf113.group.device = cuda:0
    buf113.group.iteration = (128, 1)
    buf113.sizes = ([128], [])
    buf111_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf113_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf113_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf111', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf113', get_index_1, rsqrt, None)
            return store
    buf113 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf110_buf111_buf113_buf291_buf292_buf294_buf295.snodes[3] =
    buf291: SchedulerNode(ComputedBuffer)
    buf291.writes = [MemoryDep('buf291', c0, {c0: 128}, None)]
    buf291.unmet_dependencies = [MemoryDep('buf110', c0, {c0: 128}, None)]
    buf291.met_dependencies = [MemoryDep('primals_84', c0, {c0: 128}, None)]
    buf291.users = [NodeUser(node=SchedulerNode(name='buf292'), can_inplace=True, is_weak=False)]
    buf291.group.device = cuda:0
    buf291.group.iteration = (128, 1)
    buf291.sizes = ([128], [])
    primals_84_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf110_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf291_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf291_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf110', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_84', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf291', get_index_2, add, None)
            return store
    buf291 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf110_buf111_buf113_buf291_buf292_buf294_buf295.snodes[4] =
    buf292: SchedulerNode(ComputedBuffer)
    buf292.writes = [MemoryDep('buf292', c0, {c0: 128}, None)]
    buf292.unmet_dependencies = [MemoryDep('buf291', c0, {c0: 128}, None)]
    buf292.met_dependencies = [StarDep(name='primals_84', mode=None)]
    buf292.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf292.group.device = cuda:0
    buf292.group.iteration = (128, 1)
    buf292.sizes = ([128], [])
    primals_84_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf291_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf292_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf292.mutations = ['primals_84']
    class buf292_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf291', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf292', get_index_1, load, None)
            return store
    buf292 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf110_buf111_buf113_buf291_buf292_buf294_buf295.snodes[5] =
    buf294: SchedulerNode(ComputedBuffer)
    buf294.writes = [MemoryDep('buf294', c0, {c0: 128}, None)]
    buf294.unmet_dependencies = [MemoryDep('buf111', c0, {c0: 128}, None)]
    buf294.met_dependencies = [MemoryDep('primals_85', c0, {c0: 128}, None)]
    buf294.users = [NodeUser(node=SchedulerNode(name='buf295'), can_inplace=True, is_weak=False)]
    buf294.group.device = cuda:0
    buf294.group.iteration = (128, 1)
    buf294.sizes = ([128], [])
    primals_85_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf111_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf294_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf294_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf111', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0000398612827361, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_85', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf294', get_index_2, add, None)
            return store
    buf294 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0000398612827361
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf110_buf111_buf113_buf291_buf292_buf294_buf295.snodes[6] =
    buf295: SchedulerNode(ComputedBuffer)
    buf295.writes = [MemoryDep('buf295', c0, {c0: 128}, None)]
    buf295.unmet_dependencies = [MemoryDep('buf294', c0, {c0: 128}, None)]
    buf295.met_dependencies = [StarDep(name='primals_85', mode=None)]
    buf295.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf295.group.device = cuda:0
    buf295.group.iteration = (128, 1)
    buf295.sizes = ([128], [])
    buf294_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    primals_85_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf295_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf295.mutations = ['primals_85']
    class buf295_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf294', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf295', get_index_1, load, None)
            return store
    buf295 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf110_buf111_buf113_buf291_buf292_buf294_buf295 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 25088.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0000398612827361
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf114_buf115: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf114_buf115.writes = 
    [   MemoryDep('buf114', c0, {c0: 3211264}, None),
        MemoryDep('buf115', c0, {c0: 3211264}, None)]
buf114_buf115.unmet_dependencies = 
    [   MemoryDep('buf100', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf103', c0, {c0: 3211264}, None),
        MemoryDep('buf110', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf111', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf92', c0, {c0: 3211264}, None),
        MemoryDep('buf99', c1, {c0: 25088, c1: 128}, None)]
buf114_buf115.met_dependencies = 
    [   MemoryDep('primals_20', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('primals_21', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('primals_23', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('primals_24', c1, {c0: 25088, c1: 128}, None)]
buf114_buf115.users = []
    buf114_buf115.snodes[0] =
    buf114: SchedulerNode(ComputedBuffer)
    buf114.writes = [MemoryDep('buf114', c0, {c0: 3211264}, None)]
    buf114.unmet_dependencies = 
        [   MemoryDep('buf100', c1, {c0: 25088, c1: 128}, None),
            MemoryDep('buf103', c0, {c0: 3211264}, None),
            MemoryDep('buf110', c1, {c0: 25088, c1: 128}, None),
            MemoryDep('buf111', c1, {c0: 25088, c1: 128}, None),
            MemoryDep('buf92', c0, {c0: 3211264}, None),
            MemoryDep('buf99', c1, {c0: 25088, c1: 128}, None)]
    buf114.met_dependencies = 
        [   MemoryDep('primals_20', c1, {c0: 25088, c1: 128}, None),
            MemoryDep('primals_21', c1, {c0: 25088, c1: 128}, None),
            MemoryDep('primals_23', c1, {c0: 25088, c1: 128}, None),
            MemoryDep('primals_24', c1, {c0: 25088, c1: 128}, None)]
    buf114.users = [NodeUser(node=SchedulerNode(name='buf115'), can_inplace=True, is_weak=False)]
    buf114.group.device = cuda:0
    buf114.group.iteration = (3211264, 1)
    buf114.sizes = ([25088, 128], [])
    primals_21_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf110_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf92_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    primals_24_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf103_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf99_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf100_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    primals_23_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf111_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    primals_20_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf114_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    class buf114_loop_body:
        var_ranges = {z0: 25088, z1: 128}
        index0 = 128*z0 + z1
        index1 = z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf92', get_index)
            get_index_1 = self.get_index('index1')
            load_1 = ops.load('buf99', get_index_1)
            sub = ops.sub(load, load_1)
            get_index_2 = self.get_index('index1')
            load_2 = ops.load('buf100', get_index_2)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load_2, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            mul = ops.mul(sub, rsqrt)
            get_index_3 = self.get_index('index1')
            load_3 = ops.load('primals_20', get_index_3)
            mul_1 = ops.mul(mul, load_3)
            get_index_4 = self.get_index('index1')
            load_4 = ops.load('primals_21', get_index_4)
            add_1 = ops.add(mul_1, load_4)
            get_index_5 = self.get_index('index0')
            load_5 = ops.load('buf103', get_index_5)
            get_index_6 = self.get_index('index1')
            load_6 = ops.load('buf110', get_index_6)
            sub_1 = ops.sub(load_5, load_6)
            get_index_7 = self.get_index('index1')
            load_7 = ops.load('buf111', get_index_7)
            constant_2 = ops.constant(25088.0, torch.float32)
            truediv_1 = ops.truediv(load_7, constant_2)
            constant_3 = ops.constant(1e-05, torch.float32)
            add_2 = ops.add(truediv_1, constant_3)
            rsqrt_1 = ops.rsqrt(add_2)
            mul_2 = ops.mul(sub_1, rsqrt_1)
            get_index_8 = self.get_index('index1')
            load_8 = ops.load('primals_23', get_index_8)
            mul_3 = ops.mul(mul_2, load_8)
            get_index_9 = self.get_index('index1')
            load_9 = ops.load('primals_24', get_index_9)
            add_3 = ops.add(mul_3, load_9)
            add_4 = ops.add(add_1, add_3)
            get_index_10 = self.get_index('index0')
            store = ops.store('buf114', get_index_10, add_4, None)
            return store
    buf114 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[4194304], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 10, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 3211264
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 128
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
            tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
            tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
            tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
            tmp2 = tmp0 - tmp1
            tmp4 = 25088.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp16 = tmp14 - tmp15
            tmp18 = tmp17 / tmp4
            tmp19 = tmp18 + tmp6
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = tmp16 * tmp20
            tmp23 = tmp21 * tmp22
            tmp25 = tmp23 + tmp24
            tmp26 = tmp13 + tmp25
            tl.store(out_ptr0 + (x2), tmp26, None)
    buf114_buf115.snodes[1] =
    buf115: SchedulerNode(ComputedBuffer)
    buf115.writes = [MemoryDep('buf115', c0, {c0: 3211264}, None)]
    buf115.unmet_dependencies = [MemoryDep('buf114', c0, {c0: 3211264}, None)]
    buf115.met_dependencies = []
    buf115.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf116'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf139'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf115.group.device = cuda:0
    buf115.group.iteration = (3211264, 1)
    buf115.sizes = ([3211264], [])
    buf114_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf115_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    class buf115_loop_body:
        var_ranges = {z0: 3211264}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf114', get_index)
            relu = ops.relu(load)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf115', get_index_1, relu, None)
            return store
    buf115 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[4194304], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 3211264
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_out_ptr0 + (x0), None)
            tmp1 = tl.full([1], 0, tl.int32)
            tmp2 = triton_helpers.maximum(tmp1, tmp0)
            tl.store(in_out_ptr0 + (x0), tmp2, None)
    buf114_buf115 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[4194304], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 10, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
            xnumel = 3211264
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 128
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
            tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
            tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
            tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
            tmp2 = tmp0 - tmp1
            tmp4 = 25088.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp16 = tmp14 - tmp15
            tmp18 = tmp17 / tmp4
            tmp19 = tmp18 + tmp6
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = tmp16 * tmp20
            tmp23 = tmp21 * tmp22
            tmp25 = tmp23 + tmp24
            tmp26 = tmp13 + tmp25
            tmp27 = tl.full([1], 0, tl.int32)
            tmp28 = triton_helpers.maximum(tmp27, tmp26)
            tl.store(in_out_ptr0 + (x2), tmp28, None)


buf116: ExternKernelSchedulerNode(ExternKernelAlloc)
buf116.writes = [StarDep(name='buf116', mode=None)]
buf116.unmet_dependencies = [StarDep(name='buf115', mode=None), StarDep(name='buf7', mode=None)]
buf116.met_dependencies = []
buf116.users = [NodeUser(node=SchedulerNode(name='buf117'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf118'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf119'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf127'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf116.node.kernel = extern_kernels.convolution


buf117_buf118_buf119: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf117_buf118_buf119.writes = 
    [   MemoryDep('buf117', c0, {c0: 25088}, None),
        MemoryDep('buf118', c0, {c0: 25088}, None),
        MemoryDep('buf119', c0, {c0: 25088}, None)]
buf117_buf118_buf119.unmet_dependencies = [MemoryDep('buf116', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf117_buf118_buf119.met_dependencies = []
buf117_buf118_buf119.users = []
    buf117_buf118_buf119.snodes[0] =
    buf117: SchedulerNode(ComputedBuffer)
    buf117.writes = [MemoryDep('buf117', c0, {c0: 25088}, None)]
    buf117.unmet_dependencies = [MemoryDep('buf116', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf117.met_dependencies = []
    buf117.users = [NodeUser(node=SchedulerNode(name='buf120'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf121'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf122'), can_inplace=False, is_weak=False)]
    buf117.group.device = cuda:0
    buf117.group.iteration = (25088, 128)
    buf117.sizes = ([196, 128], [128])
    buf116_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf117_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf117_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf116', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf117', get_index_1, getitem)
            return store_reduction
    buf117 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf117_buf118_buf119.snodes[1] =
    buf118: SchedulerNode(ComputedBuffer)
    buf118.writes = [MemoryDep('buf118', c0, {c0: 25088}, None)]
    buf118.unmet_dependencies = [MemoryDep('buf116', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf118.met_dependencies = []
    buf118.users = [NodeUser(node=SchedulerNode(name='buf120'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf121'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf122'), can_inplace=False, is_weak=False)]
    buf118.group.device = cuda:0
    buf118.group.iteration = (25088, 128)
    buf118.sizes = ([196, 128], [128])
    buf116_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf118_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf118_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf116', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf118', get_index_1, getitem_1)
            return store_reduction
    buf118 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf117_buf118_buf119.snodes[2] =
    buf119: SchedulerNode(ComputedBuffer)
    buf119.writes = [MemoryDep('buf119', c0, {c0: 25088}, None)]
    buf119.unmet_dependencies = [MemoryDep('buf116', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf119.met_dependencies = []
    buf119.users = [NodeUser(node=SchedulerNode(name='buf120'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf121'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf122'), can_inplace=False, is_weak=False)]
    buf119.group.device = cuda:0
    buf119.group.iteration = (25088, 128)
    buf119.sizes = ([196, 128], [128])
    buf116_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf119_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf119_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf116', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf119', get_index_1, getitem_2)
            return store_reduction
    buf119 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf117_buf118_buf119 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf120_buf121_buf122: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf120_buf121_buf122.writes = 
    [   MemoryDep('buf120', c0, {c0: 256}, None),
        MemoryDep('buf121', c0, {c0: 256}, None),
        MemoryDep('buf122', c0, {c0: 256}, None)]
buf120_buf121_buf122.unmet_dependencies = 
    [   MemoryDep('buf117', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf118', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf119', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
buf120_buf121_buf122.met_dependencies = []
buf120_buf121_buf122.users = []
    buf120_buf121_buf122.snodes[0] =
    buf120: SchedulerNode(ComputedBuffer)
    buf120.writes = [MemoryDep('buf120', c0, {c0: 256}, None)]
    buf120.unmet_dependencies = 
        [   MemoryDep('buf117', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf118', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf119', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf120.met_dependencies = []
    buf120.users = [NodeUser(node=SchedulerNode(name='buf123'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf124'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf125'), can_inplace=False, is_weak=False)]
    buf120.group.device = cuda:0
    buf120.group.iteration = (256, 98)
    buf120.sizes = ([2, 128], [98])
    buf118_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf119_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf117_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf120_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf120_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf117', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf118', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf119', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf120', get_index_3, getitem)
            return store_reduction
    buf120 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf120_buf121_buf122.snodes[1] =
    buf121: SchedulerNode(ComputedBuffer)
    buf121.writes = [MemoryDep('buf121', c0, {c0: 256}, None)]
    buf121.unmet_dependencies = 
        [   MemoryDep('buf117', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf118', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf119', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf121.met_dependencies = []
    buf121.users = [NodeUser(node=SchedulerNode(name='buf123'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf124'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf125'), can_inplace=False, is_weak=False)]
    buf121.group.device = cuda:0
    buf121.group.iteration = (256, 98)
    buf121.sizes = ([2, 128], [98])
    buf118_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf119_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf117_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf121_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf121_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf117', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf118', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf119', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf121', get_index_3, getitem_1)
            return store_reduction
    buf121 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf120_buf121_buf122.snodes[2] =
    buf122: SchedulerNode(ComputedBuffer)
    buf122.writes = [MemoryDep('buf122', c0, {c0: 256}, None)]
    buf122.unmet_dependencies = 
        [   MemoryDep('buf117', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf118', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf119', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf122.met_dependencies = []
    buf122.users = [NodeUser(node=SchedulerNode(name='buf123'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf124'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf125'), can_inplace=False, is_weak=False)]
    buf122.group.device = cuda:0
    buf122.group.iteration = (256, 98)
    buf122.sizes = ([2, 128], [98])
    buf118_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf119_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf117_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf122_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf122_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf117', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf118', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf119', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf122', get_index_3, getitem_2)
            return store_reduction
    buf122 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf120_buf121_buf122 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf123_buf124_buf126_buf299_buf300_buf302_buf303: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf123_buf124_buf126_buf299_buf300_buf302_buf303.writes = 
    [   MemoryDep('buf123', c0, {c0: 128}, None),
        MemoryDep('buf124', c0, {c0: 128}, None),
        MemoryDep('buf126', c0, {c0: 128}, None),
        MemoryDep('buf299', c0, {c0: 128}, None),
        MemoryDep('buf300', c0, {c0: 128}, None),
        MemoryDep('buf302', c0, {c0: 128}, None),
        MemoryDep('buf303', c0, {c0: 128}, None)]
buf123_buf124_buf126_buf299_buf300_buf302_buf303.unmet_dependencies = 
    [   MemoryDep('buf120', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf121', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf122', c0 + 128*c1, {c0: 128, c1: 2}, None)]
buf123_buf124_buf126_buf299_buf300_buf302_buf303.met_dependencies = 
    [   MemoryDep('primals_87', c0, {c0: 128}, None),
        MemoryDep('primals_88', c0, {c0: 128}, None),
        StarDep(name='primals_87', mode=None),
        StarDep(name='primals_88', mode=None)]
buf123_buf124_buf126_buf299_buf300_buf302_buf303.users = []
    buf123_buf124_buf126_buf299_buf300_buf302_buf303.snodes[0] =
    buf123: SchedulerNode(ComputedBuffer)
    buf123.writes = [MemoryDep('buf123', c0, {c0: 128}, None)]
    buf123.unmet_dependencies = 
        [   MemoryDep('buf120', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf121', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf122', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf123.met_dependencies = []
    buf123.users = [NodeUser(node=SchedulerNode(name='buf127'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf299'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf123.group.device = cuda:0
    buf123.group.iteration = (128, 2)
    buf123.sizes = ([128], [2])
    buf120_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf122_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf121_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf123_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf123_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf120', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf121', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf122', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf123', get_index_3, getitem)
            return store_reduction
    buf123 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf123_buf124_buf126_buf299_buf300_buf302_buf303.snodes[1] =
    buf124: SchedulerNode(ComputedBuffer)
    buf124.writes = [MemoryDep('buf124', c0, {c0: 128}, None)]
    buf124.unmet_dependencies = 
        [   MemoryDep('buf120', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf121', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf122', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf124.met_dependencies = []
    buf124.users = [NodeUser(node=SchedulerNode(name='buf126'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf127'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf302'), can_inplace=True, is_weak=False)]
    buf124.group.device = cuda:0
    buf124.group.iteration = (128, 2)
    buf124.sizes = ([128], [2])
    buf120_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf122_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf121_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf124_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf124_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf120', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf121', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf122', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf124', get_index_3, getitem_1)
            return store_reduction
    buf124 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf123_buf124_buf126_buf299_buf300_buf302_buf303.snodes[2] =
    buf126: SchedulerNode(ComputedBuffer)
    buf126.writes = [MemoryDep('buf126', c0, {c0: 128}, None)]
    buf126.unmet_dependencies = [MemoryDep('buf124', c0, {c0: 128}, None)]
    buf126.met_dependencies = []
    buf126.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf126.group.device = cuda:0
    buf126.group.iteration = (128, 1)
    buf126.sizes = ([128], [])
    buf124_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf126_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf126_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf124', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf126', get_index_1, rsqrt, None)
            return store
    buf126 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf123_buf124_buf126_buf299_buf300_buf302_buf303.snodes[3] =
    buf299: SchedulerNode(ComputedBuffer)
    buf299.writes = [MemoryDep('buf299', c0, {c0: 128}, None)]
    buf299.unmet_dependencies = [MemoryDep('buf123', c0, {c0: 128}, None)]
    buf299.met_dependencies = [MemoryDep('primals_87', c0, {c0: 128}, None)]
    buf299.users = [NodeUser(node=SchedulerNode(name='buf300'), can_inplace=True, is_weak=False)]
    buf299.group.device = cuda:0
    buf299.group.iteration = (128, 1)
    buf299.sizes = ([128], [])
    buf123_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    primals_87_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf299_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf299_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf123', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_87', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf299', get_index_2, add, None)
            return store
    buf299 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf123_buf124_buf126_buf299_buf300_buf302_buf303.snodes[4] =
    buf300: SchedulerNode(ComputedBuffer)
    buf300.writes = [MemoryDep('buf300', c0, {c0: 128}, None)]
    buf300.unmet_dependencies = [MemoryDep('buf299', c0, {c0: 128}, None)]
    buf300.met_dependencies = [StarDep(name='primals_87', mode=None)]
    buf300.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf300.group.device = cuda:0
    buf300.group.iteration = (128, 1)
    buf300.sizes = ([128], [])
    buf299_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    primals_87_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf300_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf300.mutations = ['primals_87']
    class buf300_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf299', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf300', get_index_1, load, None)
            return store
    buf300 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf123_buf124_buf126_buf299_buf300_buf302_buf303.snodes[5] =
    buf302: SchedulerNode(ComputedBuffer)
    buf302.writes = [MemoryDep('buf302', c0, {c0: 128}, None)]
    buf302.unmet_dependencies = [MemoryDep('buf124', c0, {c0: 128}, None)]
    buf302.met_dependencies = [MemoryDep('primals_88', c0, {c0: 128}, None)]
    buf302.users = [NodeUser(node=SchedulerNode(name='buf303'), can_inplace=True, is_weak=False)]
    buf302.group.device = cuda:0
    buf302.group.iteration = (128, 1)
    buf302.sizes = ([128], [])
    buf124_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    primals_88_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf302_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf302_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf124', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0000398612827361, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_88', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf302', get_index_2, add, None)
            return store
    buf302 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0000398612827361
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf123_buf124_buf126_buf299_buf300_buf302_buf303.snodes[6] =
    buf303: SchedulerNode(ComputedBuffer)
    buf303.writes = [MemoryDep('buf303', c0, {c0: 128}, None)]
    buf303.unmet_dependencies = [MemoryDep('buf302', c0, {c0: 128}, None)]
    buf303.met_dependencies = [StarDep(name='primals_88', mode=None)]
    buf303.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf303.group.device = cuda:0
    buf303.group.iteration = (128, 1)
    buf303.sizes = ([128], [])
    primals_88_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf302_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf303_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf303.mutations = ['primals_88']
    class buf303_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf302', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf303', get_index_1, load, None)
            return store
    buf303 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf123_buf124_buf126_buf299_buf300_buf302_buf303 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 25088.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0000398612827361
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf127: SchedulerNode(ComputedBuffer)
buf127.writes = [MemoryDep('buf127', c0, {c0: 3211264}, None)]
buf127.unmet_dependencies = 
    [   MemoryDep('buf116', c0, {c0: 3211264}, None),
        MemoryDep('buf123', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf124', c1, {c0: 25088, c1: 128}, None)]
buf127.met_dependencies = 
    [   MemoryDep('primals_26', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('primals_27', c1, {c0: 25088, c1: 128}, None)]
buf127.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf128'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf127.group.device = cuda:0
buf127.group.iteration = (3211264, 1)
buf127.sizes = ([25088, 128], [])
primals_27_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
primals_26_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf123_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
buf116_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf124_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
buf127_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf127_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf116', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf123', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf124', get_index_2)
        constant = ops.constant(25088.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_26', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_27', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf127', get_index_5, relu, None)
        return store
buf127 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 25088.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf128: ExternKernelSchedulerNode(ExternKernelAlloc)
buf128.writes = [StarDep(name='buf128', mode=None)]
buf128.unmet_dependencies = [StarDep(name='buf127', mode=None), StarDep(name='buf8', mode=None)]
buf128.met_dependencies = []
buf128.users = [NodeUser(node=SchedulerNode(name='buf129'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf130'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf131'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf139'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf128.node.kernel = extern_kernels.convolution


buf129_buf130_buf131: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf129_buf130_buf131.writes = 
    [   MemoryDep('buf129', c0, {c0: 25088}, None),
        MemoryDep('buf130', c0, {c0: 25088}, None),
        MemoryDep('buf131', c0, {c0: 25088}, None)]
buf129_buf130_buf131.unmet_dependencies = [MemoryDep('buf128', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
buf129_buf130_buf131.met_dependencies = []
buf129_buf130_buf131.users = []
    buf129_buf130_buf131.snodes[0] =
    buf129: SchedulerNode(ComputedBuffer)
    buf129.writes = [MemoryDep('buf129', c0, {c0: 25088}, None)]
    buf129.unmet_dependencies = [MemoryDep('buf128', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf129.met_dependencies = []
    buf129.users = [NodeUser(node=SchedulerNode(name='buf132'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf133'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf134'), can_inplace=False, is_weak=False)]
    buf129.group.device = cuda:0
    buf129.group.iteration = (25088, 128)
    buf129.sizes = ([196, 128], [128])
    buf128_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf129_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf129_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf128', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf129', get_index_1, getitem)
            return store_reduction
    buf129 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf129_buf130_buf131.snodes[1] =
    buf130: SchedulerNode(ComputedBuffer)
    buf130.writes = [MemoryDep('buf130', c0, {c0: 25088}, None)]
    buf130.unmet_dependencies = [MemoryDep('buf128', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf130.met_dependencies = []
    buf130.users = [NodeUser(node=SchedulerNode(name='buf132'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf133'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf134'), can_inplace=False, is_weak=False)]
    buf130.group.device = cuda:0
    buf130.group.iteration = (25088, 128)
    buf130.sizes = ([196, 128], [128])
    buf128_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf130_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf130_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf128', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf130', get_index_1, getitem_1)
            return store_reduction
    buf130 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf129_buf130_buf131.snodes[2] =
    buf131: SchedulerNode(ComputedBuffer)
    buf131.writes = [MemoryDep('buf131', c0, {c0: 25088}, None)]
    buf131.unmet_dependencies = [MemoryDep('buf128', 16384*c0 + c1 + 128*c2, {c0: 196, c1: 128, c2: 128}, None)]
    buf131.met_dependencies = []
    buf131.users = [NodeUser(node=SchedulerNode(name='buf132'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf133'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf134'), can_inplace=False, is_weak=False)]
    buf131.group.device = cuda:0
    buf131.group.iteration = (25088, 128)
    buf131.sizes = ([196, 128], [128])
    buf128_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
    buf131_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    class buf131_loop_body:
        var_ranges = {z0: 196, z1: 128, z2: 128}
        index0 = 16384*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf128', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf131', get_index_1, getitem_2)
            return store_reduction
    buf131 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf129_buf130_buf131 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[32768, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 25088
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf132_buf133_buf134: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf132_buf133_buf134.writes = 
    [   MemoryDep('buf132', c0, {c0: 256}, None),
        MemoryDep('buf133', c0, {c0: 256}, None),
        MemoryDep('buf134', c0, {c0: 256}, None)]
buf132_buf133_buf134.unmet_dependencies = 
    [   MemoryDep('buf129', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf130', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
        MemoryDep('buf131', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
buf132_buf133_buf134.met_dependencies = []
buf132_buf133_buf134.users = []
    buf132_buf133_buf134.snodes[0] =
    buf132: SchedulerNode(ComputedBuffer)
    buf132.writes = [MemoryDep('buf132', c0, {c0: 256}, None)]
    buf132.unmet_dependencies = 
        [   MemoryDep('buf129', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf130', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf131', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf132.met_dependencies = []
    buf132.users = [NodeUser(node=SchedulerNode(name='buf135'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf136'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf137'), can_inplace=False, is_weak=False)]
    buf132.group.device = cuda:0
    buf132.group.iteration = (256, 98)
    buf132.sizes = ([2, 128], [98])
    buf131_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf130_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf129_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf132_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf132_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf129', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf130', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf131', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf132', get_index_3, getitem)
            return store_reduction
    buf132 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
    buf132_buf133_buf134.snodes[1] =
    buf133: SchedulerNode(ComputedBuffer)
    buf133.writes = [MemoryDep('buf133', c0, {c0: 256}, None)]
    buf133.unmet_dependencies = 
        [   MemoryDep('buf129', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf130', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf131', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf133.met_dependencies = []
    buf133.users = [NodeUser(node=SchedulerNode(name='buf135'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf136'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf137'), can_inplace=False, is_weak=False)]
    buf133.group.device = cuda:0
    buf133.group.iteration = (256, 98)
    buf133.sizes = ([2, 128], [98])
    buf131_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf130_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf129_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf133_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf133_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf129', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf130', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf131', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf133', get_index_3, getitem_1)
            return store_reduction
    buf133 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp7, xmask)
    buf132_buf133_buf134.snodes[2] =
    buf134: SchedulerNode(ComputedBuffer)
    buf134.writes = [MemoryDep('buf134', c0, {c0: 256}, None)]
    buf134.unmet_dependencies = 
        [   MemoryDep('buf129', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf130', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None),
            MemoryDep('buf131', 12544*c0 + c1 + 128*c2, {c0: 2, c1: 128, c2: 98}, None)]
    buf134.met_dependencies = []
    buf134.users = [NodeUser(node=SchedulerNode(name='buf135'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf136'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf137'), can_inplace=False, is_weak=False)]
    buf134.group.device = cuda:0
    buf134.group.iteration = (256, 98)
    buf134.sizes = ([2, 128], [98])
    buf131_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf130_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf129_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 196], stride=[25088, 1, 25088, 25088, 128])
    buf134_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    class buf134_loop_body:
        var_ranges = {z0: 2, z1: 128, z2: 98}
        index0 = 12544*z0 + z1 + 128*z2
        index1 = 128*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf129', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf130', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf131', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf134', get_index_3, getitem_2)
            return store_reduction
    buf134 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp8, xmask)
    buf132_buf133_buf134 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[256, 128],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 98
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 128
            x1 = (xindex // 128)
            tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.load(in_ptr1 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp2 = tl.load(in_ptr2 + (x0 + (128*r2) + (12544*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
                tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
                tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
                    tmp6_mean, tmp6_m2, tmp6_weight,
                    tmp3, tmp4, tmp5
                )
                tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
                tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
                tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
            tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
                tmp6_mean, tmp6_m2, tmp6_weight, 1
            )
            tmp6 = tmp6_tmp[:, None]
            tmp7 = tmp7_tmp[:, None]
            tmp8 = tmp8_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp6, xmask)
            tl.store(out_ptr1 + (x3), tmp7, xmask)
            tl.store(out_ptr2 + (x3), tmp8, xmask)


buf135_buf136_buf138_buf307_buf308_buf310_buf311: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf135_buf136_buf138_buf307_buf308_buf310_buf311.writes = 
    [   MemoryDep('buf135', c0, {c0: 128}, None),
        MemoryDep('buf136', c0, {c0: 128}, None),
        MemoryDep('buf138', c0, {c0: 128}, None),
        MemoryDep('buf307', c0, {c0: 128}, None),
        MemoryDep('buf308', c0, {c0: 128}, None),
        MemoryDep('buf310', c0, {c0: 128}, None),
        MemoryDep('buf311', c0, {c0: 128}, None)]
buf135_buf136_buf138_buf307_buf308_buf310_buf311.unmet_dependencies = 
    [   MemoryDep('buf132', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf133', c0 + 128*c1, {c0: 128, c1: 2}, None),
        MemoryDep('buf134', c0 + 128*c1, {c0: 128, c1: 2}, None)]
buf135_buf136_buf138_buf307_buf308_buf310_buf311.met_dependencies = 
    [   MemoryDep('primals_90', c0, {c0: 128}, None),
        MemoryDep('primals_91', c0, {c0: 128}, None),
        StarDep(name='primals_90', mode=None),
        StarDep(name='primals_91', mode=None)]
buf135_buf136_buf138_buf307_buf308_buf310_buf311.users = []
    buf135_buf136_buf138_buf307_buf308_buf310_buf311.snodes[0] =
    buf135: SchedulerNode(ComputedBuffer)
    buf135.writes = [MemoryDep('buf135', c0, {c0: 128}, None)]
    buf135.unmet_dependencies = 
        [   MemoryDep('buf132', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf133', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf134', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf135.met_dependencies = []
    buf135.users = [NodeUser(node=SchedulerNode(name='buf139'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf307'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf135.group.device = cuda:0
    buf135.group.iteration = (128, 2)
    buf135.sizes = ([128], [2])
    buf134_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf132_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf133_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf135_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf135_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf132', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf133', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf134', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf135', get_index_3, getitem)
            return store_reduction
    buf135 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf135_buf136_buf138_buf307_buf308_buf310_buf311.snodes[1] =
    buf136: SchedulerNode(ComputedBuffer)
    buf136.writes = [MemoryDep('buf136', c0, {c0: 128}, None)]
    buf136.unmet_dependencies = 
        [   MemoryDep('buf132', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf133', c0 + 128*c1, {c0: 128, c1: 2}, None),
            MemoryDep('buf134', c0 + 128*c1, {c0: 128, c1: 2}, None)]
    buf136.met_dependencies = []
    buf136.users = [NodeUser(node=SchedulerNode(name='buf138'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf139'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf310'), can_inplace=True, is_weak=False)]
    buf136.group.device = cuda:0
    buf136.group.iteration = (128, 2)
    buf136.sizes = ([128], [2])
    buf134_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf132_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf133_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1, 2], stride=[256, 1, 256, 256, 128])
    buf136_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf136_loop_body:
        var_ranges = {z0: 128, z1: 2}
        index0 = z0 + 128*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf132', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf133', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf134', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf136', get_index_3, getitem_1)
            return store_reduction
    buf136 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf135_buf136_buf138_buf307_buf308_buf310_buf311.snodes[2] =
    buf138: SchedulerNode(ComputedBuffer)
    buf138.writes = [MemoryDep('buf138', c0, {c0: 128}, None)]
    buf138.unmet_dependencies = [MemoryDep('buf136', c0, {c0: 128}, None)]
    buf138.met_dependencies = []
    buf138.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf138.group.device = cuda:0
    buf138.group.iteration = (128, 1)
    buf138.sizes = ([128], [])
    buf136_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf138_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    class buf138_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf136', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf138', get_index_1, rsqrt, None)
            return store
    buf138 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf135_buf136_buf138_buf307_buf308_buf310_buf311.snodes[3] =
    buf307: SchedulerNode(ComputedBuffer)
    buf307.writes = [MemoryDep('buf307', c0, {c0: 128}, None)]
    buf307.unmet_dependencies = [MemoryDep('buf135', c0, {c0: 128}, None)]
    buf307.met_dependencies = [MemoryDep('primals_90', c0, {c0: 128}, None)]
    buf307.users = [NodeUser(node=SchedulerNode(name='buf308'), can_inplace=True, is_weak=False)]
    buf307.group.device = cuda:0
    buf307.group.iteration = (128, 1)
    buf307.sizes = ([128], [])
    primals_90_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf135_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    buf307_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf307_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf135', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_90', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf307', get_index_2, add, None)
            return store
    buf307 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf135_buf136_buf138_buf307_buf308_buf310_buf311.snodes[4] =
    buf308: SchedulerNode(ComputedBuffer)
    buf308.writes = [MemoryDep('buf308', c0, {c0: 128}, None)]
    buf308.unmet_dependencies = [MemoryDep('buf307', c0, {c0: 128}, None)]
    buf308.met_dependencies = [StarDep(name='primals_90', mode=None)]
    buf308.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf308.group.device = cuda:0
    buf308.group.iteration = (128, 1)
    buf308.sizes = ([128], [])
    primals_90_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf307_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf308_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf308.mutations = ['primals_90']
    class buf308_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf307', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf308', get_index_1, load, None)
            return store
    buf308 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf135_buf136_buf138_buf307_buf308_buf310_buf311.snodes[5] =
    buf310: SchedulerNode(ComputedBuffer)
    buf310.writes = [MemoryDep('buf310', c0, {c0: 128}, None)]
    buf310.unmet_dependencies = [MemoryDep('buf136', c0, {c0: 128}, None)]
    buf310.met_dependencies = [MemoryDep('primals_91', c0, {c0: 128}, None)]
    buf310.users = [NodeUser(node=SchedulerNode(name='buf311'), can_inplace=True, is_weak=False)]
    buf310.group.device = cuda:0
    buf310.group.iteration = (128, 1)
    buf310.sizes = ([128], [])
    buf136_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
    primals_91_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf310_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    class buf310_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf136', get_index)
            constant = ops.constant(25088.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0000398612827361, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_91', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf310', get_index_2, add, None)
            return store
    buf310 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 25088.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0000398612827361
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf135_buf136_buf138_buf307_buf308_buf310_buf311.snodes[6] =
    buf311: SchedulerNode(ComputedBuffer)
    buf311.writes = [MemoryDep('buf311', c0, {c0: 128}, None)]
    buf311.unmet_dependencies = [MemoryDep('buf310', c0, {c0: 128}, None)]
    buf311.met_dependencies = [StarDep(name='primals_91', mode=None)]
    buf311.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf311.group.device = cuda:0
    buf311.group.iteration = (128, 1)
    buf311.sizes = ([128], [])
    primals_91_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf310_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
    buf311_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[128], stride=[1])
    buf311.mutations = ['primals_91']
    class buf311_loop_body:
        var_ranges = {z0: 128}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf310', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf311', get_index_1, load, None)
            return store
    buf311 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[128], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf135_buf136_buf138_buf307_buf308_buf310_buf311 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[128, 2],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 128
            rnumel = 2
            RBLOCK: tl.constexpr = 2
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 25088.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0000398612827361
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf139: SchedulerNode(ComputedBuffer)
buf139.writes = [MemoryDep('buf139', c0, {c0: 3211264}, None)]
buf139.unmet_dependencies = 
    [   MemoryDep('buf115', c0, {c0: 3211264}, None),
        MemoryDep('buf128', c0, {c0: 3211264}, None),
        MemoryDep('buf135', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('buf136', c1, {c0: 25088, c1: 128}, None)]
buf139.met_dependencies = 
    [   MemoryDep('primals_29', c1, {c0: 25088, c1: 128}, None),
        MemoryDep('primals_30', c1, {c0: 25088, c1: 128}, None)]
buf139.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf140'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf157'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf139.group.device = cuda:0
buf139.group.iteration = (3211264, 1)
buf139.sizes = ([25088, 128], [])
buf115_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
buf136_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
buf128_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
primals_29_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
primals_30_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf135_layout = FixedLayout('cuda', torch.float32, size=[1, 128, 1, 1], stride=[128, 1, 128, 128])
buf139_layout = FixedLayout('cuda', torch.float32, size=[32, 128, 28, 28], stride=[100352, 1, 3584, 128])
class buf139_loop_body:
    var_ranges = {z0: 25088, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf128', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf135', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf136', get_index_2)
        constant = ops.constant(25088.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_29', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_30', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        get_index_5 = self.get_index('index0')
        load_5 = ops.load('buf115', get_index_5)
        add_2 = ops.add(add_1, load_5)
        relu = ops.relu(add_2)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf139', get_index_6, relu, None)
        return store
buf139 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 3211264
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 128
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp14 = tl.load(in_ptr5 + (x2), None)
        tmp2 = tmp0 - tmp1
        tmp4 = 25088.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp15 = tmp13 + tmp14
        tmp16 = tl.full([1], 0, tl.int32)
        tmp17 = triton_helpers.maximum(tmp16, tmp15)
        tl.store(out_ptr0 + (x2), tmp17, None)


buf140: ExternKernelSchedulerNode(ExternKernelAlloc)
buf140.writes = [StarDep(name='buf140', mode=None)]
buf140.unmet_dependencies = [StarDep(name='buf139', mode=None), StarDep(name='buf9', mode=None)]
buf140.met_dependencies = []
buf140.users = [NodeUser(node=SchedulerNode(name='buf141'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf142'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf143'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf148'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf140.node.kernel = extern_kernels.convolution


buf141_buf142_buf143: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf141_buf142_buf143.writes = 
    [   MemoryDep('buf141', c0, {c0: 12544}, None),
        MemoryDep('buf142', c0, {c0: 12544}, None),
        MemoryDep('buf143', c0, {c0: 12544}, None)]
buf141_buf142_buf143.unmet_dependencies = [MemoryDep('buf140', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf141_buf142_buf143.met_dependencies = []
buf141_buf142_buf143.users = []
    buf141_buf142_buf143.snodes[0] =
    buf141: SchedulerNode(ComputedBuffer)
    buf141.writes = [MemoryDep('buf141', c0, {c0: 12544}, None)]
    buf141.unmet_dependencies = [MemoryDep('buf140', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf141.met_dependencies = []
    buf141.users = [NodeUser(node=SchedulerNode(name='buf144'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf145'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf146'), can_inplace=False, is_weak=False)]
    buf141.group.device = cuda:0
    buf141.group.iteration = (12544, 128)
    buf141.sizes = ([49, 256], [128])
    buf140_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf141_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf141_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf140', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf141', get_index_1, getitem)
            return store_reduction
    buf141 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf141_buf142_buf143.snodes[1] =
    buf142: SchedulerNode(ComputedBuffer)
    buf142.writes = [MemoryDep('buf142', c0, {c0: 12544}, None)]
    buf142.unmet_dependencies = [MemoryDep('buf140', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf142.met_dependencies = []
    buf142.users = [NodeUser(node=SchedulerNode(name='buf144'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf145'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf146'), can_inplace=False, is_weak=False)]
    buf142.group.device = cuda:0
    buf142.group.iteration = (12544, 128)
    buf142.sizes = ([49, 256], [128])
    buf140_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf142_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf142_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf140', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf142', get_index_1, getitem_1)
            return store_reduction
    buf142 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf141_buf142_buf143.snodes[2] =
    buf143: SchedulerNode(ComputedBuffer)
    buf143.writes = [MemoryDep('buf143', c0, {c0: 12544}, None)]
    buf143.unmet_dependencies = [MemoryDep('buf140', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf143.met_dependencies = []
    buf143.users = [NodeUser(node=SchedulerNode(name='buf144'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf145'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf146'), can_inplace=False, is_weak=False)]
    buf143.group.device = cuda:0
    buf143.group.iteration = (12544, 128)
    buf143.sizes = ([49, 256], [128])
    buf140_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf143_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf143_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf140', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf143', get_index_1, getitem_2)
            return store_reduction
    buf143 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf141_buf142_buf143 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf144_buf145_buf147_buf315_buf316_buf318_buf319: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf144_buf145_buf147_buf315_buf316_buf318_buf319.writes = 
    [   MemoryDep('buf144', c0, {c0: 256}, None),
        MemoryDep('buf145', c0, {c0: 256}, None),
        MemoryDep('buf147', c0, {c0: 256}, None),
        MemoryDep('buf315', c0, {c0: 256}, None),
        MemoryDep('buf316', c0, {c0: 256}, None),
        MemoryDep('buf318', c0, {c0: 256}, None),
        MemoryDep('buf319', c0, {c0: 256}, None)]
buf144_buf145_buf147_buf315_buf316_buf318_buf319.unmet_dependencies = 
    [   MemoryDep('buf141', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf142', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf143', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf144_buf145_buf147_buf315_buf316_buf318_buf319.met_dependencies = 
    [   MemoryDep('primals_93', c0, {c0: 256}, None),
        MemoryDep('primals_94', c0, {c0: 256}, None),
        StarDep(name='primals_93', mode=None),
        StarDep(name='primals_94', mode=None)]
buf144_buf145_buf147_buf315_buf316_buf318_buf319.users = []
    buf144_buf145_buf147_buf315_buf316_buf318_buf319.snodes[0] =
    buf144: SchedulerNode(ComputedBuffer)
    buf144.writes = [MemoryDep('buf144', c0, {c0: 256}, None)]
    buf144.unmet_dependencies = 
        [   MemoryDep('buf141', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf142', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf143', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf144.met_dependencies = []
    buf144.users = [NodeUser(node=SchedulerNode(name='buf148'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf315'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf144.group.device = cuda:0
    buf144.group.iteration = (256, 49)
    buf144.sizes = ([256], [49])
    buf141_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf143_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf142_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf144_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf144_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf141', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf142', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf143', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf144', get_index_3, getitem)
            return store_reduction
    buf144 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf144_buf145_buf147_buf315_buf316_buf318_buf319.snodes[1] =
    buf145: SchedulerNode(ComputedBuffer)
    buf145.writes = [MemoryDep('buf145', c0, {c0: 256}, None)]
    buf145.unmet_dependencies = 
        [   MemoryDep('buf141', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf142', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf143', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf145.met_dependencies = []
    buf145.users = [NodeUser(node=SchedulerNode(name='buf147'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf148'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf318'), can_inplace=True, is_weak=False)]
    buf145.group.device = cuda:0
    buf145.group.iteration = (256, 49)
    buf145.sizes = ([256], [49])
    buf141_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf143_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf142_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf145_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf145_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf141', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf142', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf143', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf145', get_index_3, getitem_1)
            return store_reduction
    buf145 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf144_buf145_buf147_buf315_buf316_buf318_buf319.snodes[2] =
    buf147: SchedulerNode(ComputedBuffer)
    buf147.writes = [MemoryDep('buf147', c0, {c0: 256}, None)]
    buf147.unmet_dependencies = [MemoryDep('buf145', c0, {c0: 256}, None)]
    buf147.met_dependencies = []
    buf147.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf147.group.device = cuda:0
    buf147.group.iteration = (256, 1)
    buf147.sizes = ([256], [])
    buf145_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf147_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf147_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf145', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf147', get_index_1, rsqrt, None)
            return store
    buf147 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf144_buf145_buf147_buf315_buf316_buf318_buf319.snodes[3] =
    buf315: SchedulerNode(ComputedBuffer)
    buf315.writes = [MemoryDep('buf315', c0, {c0: 256}, None)]
    buf315.unmet_dependencies = [MemoryDep('buf144', c0, {c0: 256}, None)]
    buf315.met_dependencies = [MemoryDep('primals_93', c0, {c0: 256}, None)]
    buf315.users = [NodeUser(node=SchedulerNode(name='buf316'), can_inplace=True, is_weak=False)]
    buf315.group.device = cuda:0
    buf315.group.iteration = (256, 1)
    buf315.sizes = ([256], [])
    primals_93_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf144_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf315_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf315_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf144', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_93', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf315', get_index_2, add, None)
            return store
    buf315 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf144_buf145_buf147_buf315_buf316_buf318_buf319.snodes[4] =
    buf316: SchedulerNode(ComputedBuffer)
    buf316.writes = [MemoryDep('buf316', c0, {c0: 256}, None)]
    buf316.unmet_dependencies = [MemoryDep('buf315', c0, {c0: 256}, None)]
    buf316.met_dependencies = [StarDep(name='primals_93', mode=None)]
    buf316.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf316.group.device = cuda:0
    buf316.group.iteration = (256, 1)
    buf316.sizes = ([256], [])
    buf315_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    primals_93_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf316_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf316.mutations = ['primals_93']
    class buf316_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf315', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf316', get_index_1, load, None)
            return store
    buf316 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf144_buf145_buf147_buf315_buf316_buf318_buf319.snodes[5] =
    buf318: SchedulerNode(ComputedBuffer)
    buf318.writes = [MemoryDep('buf318', c0, {c0: 256}, None)]
    buf318.unmet_dependencies = [MemoryDep('buf145', c0, {c0: 256}, None)]
    buf318.met_dependencies = [MemoryDep('primals_94', c0, {c0: 256}, None)]
    buf318.users = [NodeUser(node=SchedulerNode(name='buf319'), can_inplace=True, is_weak=False)]
    buf318.group.device = cuda:0
    buf318.group.iteration = (256, 1)
    buf318.sizes = ([256], [])
    primals_94_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf145_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf318_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf318_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf145', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0001594642002871, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_94', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf318', get_index_2, add, None)
            return store
    buf318 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0001594642002871
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf144_buf145_buf147_buf315_buf316_buf318_buf319.snodes[6] =
    buf319: SchedulerNode(ComputedBuffer)
    buf319.writes = [MemoryDep('buf319', c0, {c0: 256}, None)]
    buf319.unmet_dependencies = [MemoryDep('buf318', c0, {c0: 256}, None)]
    buf319.met_dependencies = [StarDep(name='primals_94', mode=None)]
    buf319.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf319.group.device = cuda:0
    buf319.group.iteration = (256, 1)
    buf319.sizes = ([256], [])
    primals_94_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf318_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf319_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf319.mutations = ['primals_94']
    class buf319_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf318', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf319', get_index_1, load, None)
            return store
    buf319 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf144_buf145_buf147_buf315_buf316_buf318_buf319 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 6272.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0001594642002871
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf148: SchedulerNode(ComputedBuffer)
buf148.writes = [MemoryDep('buf148', c0, {c0: 1605632}, None)]
buf148.unmet_dependencies = 
    [   MemoryDep('buf140', c0, {c0: 1605632}, None),
        MemoryDep('buf144', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf145', c1, {c0: 6272, c1: 256}, None)]
buf148.met_dependencies = 
    [   MemoryDep('primals_32', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('primals_33', c1, {c0: 6272, c1: 256}, None)]
buf148.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf149'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf148.group.device = cuda:0
buf148.group.iteration = (1605632, 1)
buf148.sizes = ([6272, 256], [])
buf145_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
buf140_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
primals_32_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf144_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
primals_33_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf148_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf148_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf140', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf144', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf145', get_index_2)
        constant = ops.constant(6272.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_32', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_33', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf148', get_index_5, relu, None)
        return store
buf148 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 6272.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf149: ExternKernelSchedulerNode(ExternKernelAlloc)
buf149.writes = [StarDep(name='buf149', mode=None)]
buf149.unmet_dependencies = [StarDep(name='buf10', mode=None), StarDep(name='buf148', mode=None)]
buf149.met_dependencies = []
buf149.users = [NodeUser(node=SchedulerNode(name='buf150'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf151'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf152'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf165'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf149.node.kernel = extern_kernels.convolution


buf150_buf151_buf152: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf150_buf151_buf152.writes = 
    [   MemoryDep('buf150', c0, {c0: 12544}, None),
        MemoryDep('buf151', c0, {c0: 12544}, None),
        MemoryDep('buf152', c0, {c0: 12544}, None)]
buf150_buf151_buf152.unmet_dependencies = [MemoryDep('buf149', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf150_buf151_buf152.met_dependencies = []
buf150_buf151_buf152.users = []
    buf150_buf151_buf152.snodes[0] =
    buf150: SchedulerNode(ComputedBuffer)
    buf150.writes = [MemoryDep('buf150', c0, {c0: 12544}, None)]
    buf150.unmet_dependencies = [MemoryDep('buf149', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf150.met_dependencies = []
    buf150.users = [NodeUser(node=SchedulerNode(name='buf153'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf154'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf155'), can_inplace=False, is_weak=False)]
    buf150.group.device = cuda:0
    buf150.group.iteration = (12544, 128)
    buf150.sizes = ([49, 256], [128])
    buf149_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf150_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf150_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf149', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf150', get_index_1, getitem)
            return store_reduction
    buf150 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf150_buf151_buf152.snodes[1] =
    buf151: SchedulerNode(ComputedBuffer)
    buf151.writes = [MemoryDep('buf151', c0, {c0: 12544}, None)]
    buf151.unmet_dependencies = [MemoryDep('buf149', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf151.met_dependencies = []
    buf151.users = [NodeUser(node=SchedulerNode(name='buf153'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf154'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf155'), can_inplace=False, is_weak=False)]
    buf151.group.device = cuda:0
    buf151.group.iteration = (12544, 128)
    buf151.sizes = ([49, 256], [128])
    buf149_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf151_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf151_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf149', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf151', get_index_1, getitem_1)
            return store_reduction
    buf151 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf150_buf151_buf152.snodes[2] =
    buf152: SchedulerNode(ComputedBuffer)
    buf152.writes = [MemoryDep('buf152', c0, {c0: 12544}, None)]
    buf152.unmet_dependencies = [MemoryDep('buf149', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf152.met_dependencies = []
    buf152.users = [NodeUser(node=SchedulerNode(name='buf153'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf154'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf155'), can_inplace=False, is_weak=False)]
    buf152.group.device = cuda:0
    buf152.group.iteration = (12544, 128)
    buf152.sizes = ([49, 256], [128])
    buf149_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf152_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf152_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf149', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf152', get_index_1, getitem_2)
            return store_reduction
    buf152 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf150_buf151_buf152 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf153_buf154_buf156_buf323_buf324_buf326_buf327: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf153_buf154_buf156_buf323_buf324_buf326_buf327.writes = 
    [   MemoryDep('buf153', c0, {c0: 256}, None),
        MemoryDep('buf154', c0, {c0: 256}, None),
        MemoryDep('buf156', c0, {c0: 256}, None),
        MemoryDep('buf323', c0, {c0: 256}, None),
        MemoryDep('buf324', c0, {c0: 256}, None),
        MemoryDep('buf326', c0, {c0: 256}, None),
        MemoryDep('buf327', c0, {c0: 256}, None)]
buf153_buf154_buf156_buf323_buf324_buf326_buf327.unmet_dependencies = 
    [   MemoryDep('buf150', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf151', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf152', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf153_buf154_buf156_buf323_buf324_buf326_buf327.met_dependencies = 
    [   MemoryDep('primals_96', c0, {c0: 256}, None),
        MemoryDep('primals_97', c0, {c0: 256}, None),
        StarDep(name='primals_96', mode=None),
        StarDep(name='primals_97', mode=None)]
buf153_buf154_buf156_buf323_buf324_buf326_buf327.users = []
    buf153_buf154_buf156_buf323_buf324_buf326_buf327.snodes[0] =
    buf153: SchedulerNode(ComputedBuffer)
    buf153.writes = [MemoryDep('buf153', c0, {c0: 256}, None)]
    buf153.unmet_dependencies = 
        [   MemoryDep('buf150', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf151', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf152', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf153.met_dependencies = []
    buf153.users = [NodeUser(node=SchedulerNode(name='buf165'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf323'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf153.group.device = cuda:0
    buf153.group.iteration = (256, 49)
    buf153.sizes = ([256], [49])
    buf152_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf151_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf150_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf153_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf153_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf150', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf151', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf152', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf153', get_index_3, getitem)
            return store_reduction
    buf153 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf153_buf154_buf156_buf323_buf324_buf326_buf327.snodes[1] =
    buf154: SchedulerNode(ComputedBuffer)
    buf154.writes = [MemoryDep('buf154', c0, {c0: 256}, None)]
    buf154.unmet_dependencies = 
        [   MemoryDep('buf150', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf151', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf152', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf154.met_dependencies = []
    buf154.users = [NodeUser(node=SchedulerNode(name='buf156'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf165'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf326'), can_inplace=True, is_weak=False)]
    buf154.group.device = cuda:0
    buf154.group.iteration = (256, 49)
    buf154.sizes = ([256], [49])
    buf152_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf151_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf150_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf154_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf154_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf150', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf151', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf152', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf154', get_index_3, getitem_1)
            return store_reduction
    buf154 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf153_buf154_buf156_buf323_buf324_buf326_buf327.snodes[2] =
    buf156: SchedulerNode(ComputedBuffer)
    buf156.writes = [MemoryDep('buf156', c0, {c0: 256}, None)]
    buf156.unmet_dependencies = [MemoryDep('buf154', c0, {c0: 256}, None)]
    buf156.met_dependencies = []
    buf156.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf156.group.device = cuda:0
    buf156.group.iteration = (256, 1)
    buf156.sizes = ([256], [])
    buf154_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf156_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf156_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf154', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf156', get_index_1, rsqrt, None)
            return store
    buf156 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf153_buf154_buf156_buf323_buf324_buf326_buf327.snodes[3] =
    buf323: SchedulerNode(ComputedBuffer)
    buf323.writes = [MemoryDep('buf323', c0, {c0: 256}, None)]
    buf323.unmet_dependencies = [MemoryDep('buf153', c0, {c0: 256}, None)]
    buf323.met_dependencies = [MemoryDep('primals_96', c0, {c0: 256}, None)]
    buf323.users = [NodeUser(node=SchedulerNode(name='buf324'), can_inplace=True, is_weak=False)]
    buf323.group.device = cuda:0
    buf323.group.iteration = (256, 1)
    buf323.sizes = ([256], [])
    buf153_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    primals_96_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf323_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf323_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf153', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_96', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf323', get_index_2, add, None)
            return store
    buf323 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf153_buf154_buf156_buf323_buf324_buf326_buf327.snodes[4] =
    buf324: SchedulerNode(ComputedBuffer)
    buf324.writes = [MemoryDep('buf324', c0, {c0: 256}, None)]
    buf324.unmet_dependencies = [MemoryDep('buf323', c0, {c0: 256}, None)]
    buf324.met_dependencies = [StarDep(name='primals_96', mode=None)]
    buf324.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf324.group.device = cuda:0
    buf324.group.iteration = (256, 1)
    buf324.sizes = ([256], [])
    buf323_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    primals_96_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf324_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf324.mutations = ['primals_96']
    class buf324_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf323', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf324', get_index_1, load, None)
            return store
    buf324 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf153_buf154_buf156_buf323_buf324_buf326_buf327.snodes[5] =
    buf326: SchedulerNode(ComputedBuffer)
    buf326.writes = [MemoryDep('buf326', c0, {c0: 256}, None)]
    buf326.unmet_dependencies = [MemoryDep('buf154', c0, {c0: 256}, None)]
    buf326.met_dependencies = [MemoryDep('primals_97', c0, {c0: 256}, None)]
    buf326.users = [NodeUser(node=SchedulerNode(name='buf327'), can_inplace=True, is_weak=False)]
    buf326.group.device = cuda:0
    buf326.group.iteration = (256, 1)
    buf326.sizes = ([256], [])
    buf154_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    primals_97_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf326_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf326_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf154', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0001594642002871, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_97', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf326', get_index_2, add, None)
            return store
    buf326 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0001594642002871
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf153_buf154_buf156_buf323_buf324_buf326_buf327.snodes[6] =
    buf327: SchedulerNode(ComputedBuffer)
    buf327.writes = [MemoryDep('buf327', c0, {c0: 256}, None)]
    buf327.unmet_dependencies = [MemoryDep('buf326', c0, {c0: 256}, None)]
    buf327.met_dependencies = [StarDep(name='primals_97', mode=None)]
    buf327.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf327.group.device = cuda:0
    buf327.group.iteration = (256, 1)
    buf327.sizes = ([256], [])
    primals_97_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf326_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf327_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf327.mutations = ['primals_97']
    class buf327_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf326', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf327', get_index_1, load, None)
            return store
    buf327 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf153_buf154_buf156_buf323_buf324_buf326_buf327 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 6272.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0001594642002871
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf157: ExternKernelSchedulerNode(ExternKernelAlloc)
buf157.writes = [StarDep(name='buf157', mode=None)]
buf157.unmet_dependencies = [StarDep(name='buf139', mode=None)]
buf157.met_dependencies = [StarDep(name='primals_37', mode=None)]
buf157.users = [NodeUser(node=SchedulerNode(name='buf158'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf159'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf160'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf165'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf157.node.kernel = extern_kernels.convolution


buf158_buf159_buf160: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf158_buf159_buf160.writes = 
    [   MemoryDep('buf158', c0, {c0: 12544}, None),
        MemoryDep('buf159', c0, {c0: 12544}, None),
        MemoryDep('buf160', c0, {c0: 12544}, None)]
buf158_buf159_buf160.unmet_dependencies = [MemoryDep('buf157', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf158_buf159_buf160.met_dependencies = []
buf158_buf159_buf160.users = []
    buf158_buf159_buf160.snodes[0] =
    buf158: SchedulerNode(ComputedBuffer)
    buf158.writes = [MemoryDep('buf158', c0, {c0: 12544}, None)]
    buf158.unmet_dependencies = [MemoryDep('buf157', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf158.met_dependencies = []
    buf158.users = [NodeUser(node=SchedulerNode(name='buf161'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf162'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf163'), can_inplace=False, is_weak=False)]
    buf158.group.device = cuda:0
    buf158.group.iteration = (12544, 128)
    buf158.sizes = ([49, 256], [128])
    buf157_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf158_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf158_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf157', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf158', get_index_1, getitem)
            return store_reduction
    buf158 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf158_buf159_buf160.snodes[1] =
    buf159: SchedulerNode(ComputedBuffer)
    buf159.writes = [MemoryDep('buf159', c0, {c0: 12544}, None)]
    buf159.unmet_dependencies = [MemoryDep('buf157', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf159.met_dependencies = []
    buf159.users = [NodeUser(node=SchedulerNode(name='buf161'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf162'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf163'), can_inplace=False, is_weak=False)]
    buf159.group.device = cuda:0
    buf159.group.iteration = (12544, 128)
    buf159.sizes = ([49, 256], [128])
    buf157_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf159_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf159_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf157', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf159', get_index_1, getitem_1)
            return store_reduction
    buf159 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf158_buf159_buf160.snodes[2] =
    buf160: SchedulerNode(ComputedBuffer)
    buf160.writes = [MemoryDep('buf160', c0, {c0: 12544}, None)]
    buf160.unmet_dependencies = [MemoryDep('buf157', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf160.met_dependencies = []
    buf160.users = [NodeUser(node=SchedulerNode(name='buf161'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf162'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf163'), can_inplace=False, is_weak=False)]
    buf160.group.device = cuda:0
    buf160.group.iteration = (12544, 128)
    buf160.sizes = ([49, 256], [128])
    buf157_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf160_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf160_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf157', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf160', get_index_1, getitem_2)
            return store_reduction
    buf160 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf158_buf159_buf160 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf161_buf162_buf164_buf331_buf332_buf334_buf335: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf161_buf162_buf164_buf331_buf332_buf334_buf335.writes = 
    [   MemoryDep('buf161', c0, {c0: 256}, None),
        MemoryDep('buf162', c0, {c0: 256}, None),
        MemoryDep('buf164', c0, {c0: 256}, None),
        MemoryDep('buf331', c0, {c0: 256}, None),
        MemoryDep('buf332', c0, {c0: 256}, None),
        MemoryDep('buf334', c0, {c0: 256}, None),
        MemoryDep('buf335', c0, {c0: 256}, None)]
buf161_buf162_buf164_buf331_buf332_buf334_buf335.unmet_dependencies = 
    [   MemoryDep('buf158', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf159', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf160', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf161_buf162_buf164_buf331_buf332_buf334_buf335.met_dependencies = 
    [   MemoryDep('primals_100', c0, {c0: 256}, None),
        MemoryDep('primals_99', c0, {c0: 256}, None),
        StarDep(name='primals_100', mode=None),
        StarDep(name='primals_99', mode=None)]
buf161_buf162_buf164_buf331_buf332_buf334_buf335.users = []
    buf161_buf162_buf164_buf331_buf332_buf334_buf335.snodes[0] =
    buf161: SchedulerNode(ComputedBuffer)
    buf161.writes = [MemoryDep('buf161', c0, {c0: 256}, None)]
    buf161.unmet_dependencies = 
        [   MemoryDep('buf158', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf159', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf160', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf161.met_dependencies = []
    buf161.users = [NodeUser(node=SchedulerNode(name='buf165'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf331'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf161.group.device = cuda:0
    buf161.group.iteration = (256, 49)
    buf161.sizes = ([256], [49])
    buf159_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf160_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf158_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf161_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf161_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf158', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf159', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf160', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf161', get_index_3, getitem)
            return store_reduction
    buf161 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf161_buf162_buf164_buf331_buf332_buf334_buf335.snodes[1] =
    buf162: SchedulerNode(ComputedBuffer)
    buf162.writes = [MemoryDep('buf162', c0, {c0: 256}, None)]
    buf162.unmet_dependencies = 
        [   MemoryDep('buf158', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf159', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf160', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf162.met_dependencies = []
    buf162.users = [NodeUser(node=SchedulerNode(name='buf164'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf165'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf334'), can_inplace=True, is_weak=False)]
    buf162.group.device = cuda:0
    buf162.group.iteration = (256, 49)
    buf162.sizes = ([256], [49])
    buf159_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf160_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf158_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf162_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf162_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf158', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf159', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf160', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf162', get_index_3, getitem_1)
            return store_reduction
    buf162 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf161_buf162_buf164_buf331_buf332_buf334_buf335.snodes[2] =
    buf164: SchedulerNode(ComputedBuffer)
    buf164.writes = [MemoryDep('buf164', c0, {c0: 256}, None)]
    buf164.unmet_dependencies = [MemoryDep('buf162', c0, {c0: 256}, None)]
    buf164.met_dependencies = []
    buf164.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf164.group.device = cuda:0
    buf164.group.iteration = (256, 1)
    buf164.sizes = ([256], [])
    buf162_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf164_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf164_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf162', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf164', get_index_1, rsqrt, None)
            return store
    buf164 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf161_buf162_buf164_buf331_buf332_buf334_buf335.snodes[3] =
    buf331: SchedulerNode(ComputedBuffer)
    buf331.writes = [MemoryDep('buf331', c0, {c0: 256}, None)]
    buf331.unmet_dependencies = [MemoryDep('buf161', c0, {c0: 256}, None)]
    buf331.met_dependencies = [MemoryDep('primals_99', c0, {c0: 256}, None)]
    buf331.users = [NodeUser(node=SchedulerNode(name='buf332'), can_inplace=True, is_weak=False)]
    buf331.group.device = cuda:0
    buf331.group.iteration = (256, 1)
    buf331.sizes = ([256], [])
    buf161_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    primals_99_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf331_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf331_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf161', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_99', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf331', get_index_2, add, None)
            return store
    buf331 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf161_buf162_buf164_buf331_buf332_buf334_buf335.snodes[4] =
    buf332: SchedulerNode(ComputedBuffer)
    buf332.writes = [MemoryDep('buf332', c0, {c0: 256}, None)]
    buf332.unmet_dependencies = [MemoryDep('buf331', c0, {c0: 256}, None)]
    buf332.met_dependencies = [StarDep(name='primals_99', mode=None)]
    buf332.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf332.group.device = cuda:0
    buf332.group.iteration = (256, 1)
    buf332.sizes = ([256], [])
    buf331_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    primals_99_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf332_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf332.mutations = ['primals_99']
    class buf332_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf331', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf332', get_index_1, load, None)
            return store
    buf332 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf161_buf162_buf164_buf331_buf332_buf334_buf335.snodes[5] =
    buf334: SchedulerNode(ComputedBuffer)
    buf334.writes = [MemoryDep('buf334', c0, {c0: 256}, None)]
    buf334.unmet_dependencies = [MemoryDep('buf162', c0, {c0: 256}, None)]
    buf334.met_dependencies = [MemoryDep('primals_100', c0, {c0: 256}, None)]
    buf334.users = [NodeUser(node=SchedulerNode(name='buf335'), can_inplace=True, is_weak=False)]
    buf334.group.device = cuda:0
    buf334.group.iteration = (256, 1)
    buf334.sizes = ([256], [])
    primals_100_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf162_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf334_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf334_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf162', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0001594642002871, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_100', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf334', get_index_2, add, None)
            return store
    buf334 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0001594642002871
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf161_buf162_buf164_buf331_buf332_buf334_buf335.snodes[6] =
    buf335: SchedulerNode(ComputedBuffer)
    buf335.writes = [MemoryDep('buf335', c0, {c0: 256}, None)]
    buf335.unmet_dependencies = [MemoryDep('buf334', c0, {c0: 256}, None)]
    buf335.met_dependencies = [StarDep(name='primals_100', mode=None)]
    buf335.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf335.group.device = cuda:0
    buf335.group.iteration = (256, 1)
    buf335.sizes = ([256], [])
    primals_100_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf334_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf335_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf335.mutations = ['primals_100']
    class buf335_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf334', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf335', get_index_1, load, None)
            return store
    buf335 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf161_buf162_buf164_buf331_buf332_buf334_buf335 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 6272.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0001594642002871
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf165_buf166: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf165_buf166.writes = 
    [   MemoryDep('buf165', c0, {c0: 1605632}, None),
        MemoryDep('buf166', c0, {c0: 1605632}, None)]
buf165_buf166.unmet_dependencies = 
    [   MemoryDep('buf149', c0, {c0: 1605632}, None),
        MemoryDep('buf153', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf154', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf157', c0, {c0: 1605632}, None),
        MemoryDep('buf161', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf162', c1, {c0: 6272, c1: 256}, None)]
buf165_buf166.met_dependencies = 
    [   MemoryDep('primals_35', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('primals_36', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('primals_38', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('primals_39', c1, {c0: 6272, c1: 256}, None)]
buf165_buf166.users = []
    buf165_buf166.snodes[0] =
    buf165: SchedulerNode(ComputedBuffer)
    buf165.writes = [MemoryDep('buf165', c0, {c0: 1605632}, None)]
    buf165.unmet_dependencies = 
        [   MemoryDep('buf149', c0, {c0: 1605632}, None),
            MemoryDep('buf153', c1, {c0: 6272, c1: 256}, None),
            MemoryDep('buf154', c1, {c0: 6272, c1: 256}, None),
            MemoryDep('buf157', c0, {c0: 1605632}, None),
            MemoryDep('buf161', c1, {c0: 6272, c1: 256}, None),
            MemoryDep('buf162', c1, {c0: 6272, c1: 256}, None)]
    buf165.met_dependencies = 
        [   MemoryDep('primals_35', c1, {c0: 6272, c1: 256}, None),
            MemoryDep('primals_36', c1, {c0: 6272, c1: 256}, None),
            MemoryDep('primals_38', c1, {c0: 6272, c1: 256}, None),
            MemoryDep('primals_39', c1, {c0: 6272, c1: 256}, None)]
    buf165.users = [NodeUser(node=SchedulerNode(name='buf166'), can_inplace=True, is_weak=False)]
    buf165.group.device = cuda:0
    buf165.group.iteration = (1605632, 1)
    buf165.sizes = ([6272, 256], [])
    buf154_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    primals_39_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    primals_36_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf157_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf162_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf153_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf161_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    primals_38_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf149_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    primals_35_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf165_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    class buf165_loop_body:
        var_ranges = {z0: 6272, z1: 256}
        index0 = 256*z0 + z1
        index1 = z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf149', get_index)
            get_index_1 = self.get_index('index1')
            load_1 = ops.load('buf153', get_index_1)
            sub = ops.sub(load, load_1)
            get_index_2 = self.get_index('index1')
            load_2 = ops.load('buf154', get_index_2)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load_2, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            mul = ops.mul(sub, rsqrt)
            get_index_3 = self.get_index('index1')
            load_3 = ops.load('primals_35', get_index_3)
            mul_1 = ops.mul(mul, load_3)
            get_index_4 = self.get_index('index1')
            load_4 = ops.load('primals_36', get_index_4)
            add_1 = ops.add(mul_1, load_4)
            get_index_5 = self.get_index('index0')
            load_5 = ops.load('buf157', get_index_5)
            get_index_6 = self.get_index('index1')
            load_6 = ops.load('buf161', get_index_6)
            sub_1 = ops.sub(load_5, load_6)
            get_index_7 = self.get_index('index1')
            load_7 = ops.load('buf162', get_index_7)
            constant_2 = ops.constant(6272.0, torch.float32)
            truediv_1 = ops.truediv(load_7, constant_2)
            constant_3 = ops.constant(1e-05, torch.float32)
            add_2 = ops.add(truediv_1, constant_3)
            rsqrt_1 = ops.rsqrt(add_2)
            mul_2 = ops.mul(sub_1, rsqrt_1)
            get_index_8 = self.get_index('index1')
            load_8 = ops.load('primals_38', get_index_8)
            mul_3 = ops.mul(mul_2, load_8)
            get_index_9 = self.get_index('index1')
            load_9 = ops.load('primals_39', get_index_9)
            add_3 = ops.add(mul_3, load_9)
            add_4 = ops.add(add_1, add_3)
            get_index_10 = self.get_index('index0')
            store = ops.store('buf165', get_index_10, add_4, None)
            return store
    buf165 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[2097152], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 10, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1605632
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 256
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
            tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
            tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
            tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
            tmp2 = tmp0 - tmp1
            tmp4 = 6272.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp16 = tmp14 - tmp15
            tmp18 = tmp17 / tmp4
            tmp19 = tmp18 + tmp6
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = tmp16 * tmp20
            tmp23 = tmp21 * tmp22
            tmp25 = tmp23 + tmp24
            tmp26 = tmp13 + tmp25
            tl.store(out_ptr0 + (x2), tmp26, None)
    buf165_buf166.snodes[1] =
    buf166: SchedulerNode(ComputedBuffer)
    buf166.writes = [MemoryDep('buf166', c0, {c0: 1605632}, None)]
    buf166.unmet_dependencies = [MemoryDep('buf165', c0, {c0: 1605632}, None)]
    buf166.met_dependencies = []
    buf166.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf167'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf184'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf166.group.device = cuda:0
    buf166.group.iteration = (1605632, 1)
    buf166.sizes = ([1605632], [])
    buf165_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf166_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    class buf166_loop_body:
        var_ranges = {z0: 1605632}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf165', get_index)
            relu = ops.relu(load)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf166', get_index_1, relu, None)
            return store
    buf166 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[2097152], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1605632
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_out_ptr0 + (x0), None)
            tmp1 = tl.full([1], 0, tl.int32)
            tmp2 = triton_helpers.maximum(tmp1, tmp0)
            tl.store(in_out_ptr0 + (x0), tmp2, None)
    buf165_buf166 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[2097152], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 10, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1605632
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 256
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
            tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
            tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
            tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
            tmp2 = tmp0 - tmp1
            tmp4 = 6272.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp16 = tmp14 - tmp15
            tmp18 = tmp17 / tmp4
            tmp19 = tmp18 + tmp6
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = tmp16 * tmp20
            tmp23 = tmp21 * tmp22
            tmp25 = tmp23 + tmp24
            tmp26 = tmp13 + tmp25
            tmp27 = tl.full([1], 0, tl.int32)
            tmp28 = triton_helpers.maximum(tmp27, tmp26)
            tl.store(in_out_ptr0 + (x2), tmp28, None)


buf167: ExternKernelSchedulerNode(ExternKernelAlloc)
buf167.writes = [StarDep(name='buf167', mode=None)]
buf167.unmet_dependencies = [StarDep(name='buf11', mode=None), StarDep(name='buf166', mode=None)]
buf167.met_dependencies = []
buf167.users = [NodeUser(node=SchedulerNode(name='buf168'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf169'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf170'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf175'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf167.node.kernel = extern_kernels.convolution


buf168_buf169_buf170: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf168_buf169_buf170.writes = 
    [   MemoryDep('buf168', c0, {c0: 12544}, None),
        MemoryDep('buf169', c0, {c0: 12544}, None),
        MemoryDep('buf170', c0, {c0: 12544}, None)]
buf168_buf169_buf170.unmet_dependencies = [MemoryDep('buf167', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf168_buf169_buf170.met_dependencies = []
buf168_buf169_buf170.users = []
    buf168_buf169_buf170.snodes[0] =
    buf168: SchedulerNode(ComputedBuffer)
    buf168.writes = [MemoryDep('buf168', c0, {c0: 12544}, None)]
    buf168.unmet_dependencies = [MemoryDep('buf167', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf168.met_dependencies = []
    buf168.users = [NodeUser(node=SchedulerNode(name='buf171'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf172'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf173'), can_inplace=False, is_weak=False)]
    buf168.group.device = cuda:0
    buf168.group.iteration = (12544, 128)
    buf168.sizes = ([49, 256], [128])
    buf167_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf168_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf168_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf167', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf168', get_index_1, getitem)
            return store_reduction
    buf168 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf168_buf169_buf170.snodes[1] =
    buf169: SchedulerNode(ComputedBuffer)
    buf169.writes = [MemoryDep('buf169', c0, {c0: 12544}, None)]
    buf169.unmet_dependencies = [MemoryDep('buf167', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf169.met_dependencies = []
    buf169.users = [NodeUser(node=SchedulerNode(name='buf171'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf172'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf173'), can_inplace=False, is_weak=False)]
    buf169.group.device = cuda:0
    buf169.group.iteration = (12544, 128)
    buf169.sizes = ([49, 256], [128])
    buf167_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf169_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf169_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf167', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf169', get_index_1, getitem_1)
            return store_reduction
    buf169 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf168_buf169_buf170.snodes[2] =
    buf170: SchedulerNode(ComputedBuffer)
    buf170.writes = [MemoryDep('buf170', c0, {c0: 12544}, None)]
    buf170.unmet_dependencies = [MemoryDep('buf167', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf170.met_dependencies = []
    buf170.users = [NodeUser(node=SchedulerNode(name='buf171'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf172'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf173'), can_inplace=False, is_weak=False)]
    buf170.group.device = cuda:0
    buf170.group.iteration = (12544, 128)
    buf170.sizes = ([49, 256], [128])
    buf167_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf170_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf170_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf167', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf170', get_index_1, getitem_2)
            return store_reduction
    buf170 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf168_buf169_buf170 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf171_buf172_buf174_buf339_buf340_buf342_buf343: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf171_buf172_buf174_buf339_buf340_buf342_buf343.writes = 
    [   MemoryDep('buf171', c0, {c0: 256}, None),
        MemoryDep('buf172', c0, {c0: 256}, None),
        MemoryDep('buf174', c0, {c0: 256}, None),
        MemoryDep('buf339', c0, {c0: 256}, None),
        MemoryDep('buf340', c0, {c0: 256}, None),
        MemoryDep('buf342', c0, {c0: 256}, None),
        MemoryDep('buf343', c0, {c0: 256}, None)]
buf171_buf172_buf174_buf339_buf340_buf342_buf343.unmet_dependencies = 
    [   MemoryDep('buf168', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf169', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf170', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf171_buf172_buf174_buf339_buf340_buf342_buf343.met_dependencies = 
    [   MemoryDep('primals_102', c0, {c0: 256}, None),
        MemoryDep('primals_103', c0, {c0: 256}, None),
        StarDep(name='primals_102', mode=None),
        StarDep(name='primals_103', mode=None)]
buf171_buf172_buf174_buf339_buf340_buf342_buf343.users = []
    buf171_buf172_buf174_buf339_buf340_buf342_buf343.snodes[0] =
    buf171: SchedulerNode(ComputedBuffer)
    buf171.writes = [MemoryDep('buf171', c0, {c0: 256}, None)]
    buf171.unmet_dependencies = 
        [   MemoryDep('buf168', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf169', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf170', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf171.met_dependencies = []
    buf171.users = [NodeUser(node=SchedulerNode(name='buf175'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf339'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf171.group.device = cuda:0
    buf171.group.iteration = (256, 49)
    buf171.sizes = ([256], [49])
    buf169_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf170_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf168_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf171_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf171_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf168', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf169', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf170', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf171', get_index_3, getitem)
            return store_reduction
    buf171 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf171_buf172_buf174_buf339_buf340_buf342_buf343.snodes[1] =
    buf172: SchedulerNode(ComputedBuffer)
    buf172.writes = [MemoryDep('buf172', c0, {c0: 256}, None)]
    buf172.unmet_dependencies = 
        [   MemoryDep('buf168', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf169', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf170', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf172.met_dependencies = []
    buf172.users = [NodeUser(node=SchedulerNode(name='buf174'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf175'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf342'), can_inplace=True, is_weak=False)]
    buf172.group.device = cuda:0
    buf172.group.iteration = (256, 49)
    buf172.sizes = ([256], [49])
    buf169_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf170_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf168_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf172_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf172_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf168', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf169', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf170', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf172', get_index_3, getitem_1)
            return store_reduction
    buf172 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf171_buf172_buf174_buf339_buf340_buf342_buf343.snodes[2] =
    buf174: SchedulerNode(ComputedBuffer)
    buf174.writes = [MemoryDep('buf174', c0, {c0: 256}, None)]
    buf174.unmet_dependencies = [MemoryDep('buf172', c0, {c0: 256}, None)]
    buf174.met_dependencies = []
    buf174.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf174.group.device = cuda:0
    buf174.group.iteration = (256, 1)
    buf174.sizes = ([256], [])
    buf172_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf174_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf174_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf172', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf174', get_index_1, rsqrt, None)
            return store
    buf174 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf171_buf172_buf174_buf339_buf340_buf342_buf343.snodes[3] =
    buf339: SchedulerNode(ComputedBuffer)
    buf339.writes = [MemoryDep('buf339', c0, {c0: 256}, None)]
    buf339.unmet_dependencies = [MemoryDep('buf171', c0, {c0: 256}, None)]
    buf339.met_dependencies = [MemoryDep('primals_102', c0, {c0: 256}, None)]
    buf339.users = [NodeUser(node=SchedulerNode(name='buf340'), can_inplace=True, is_weak=False)]
    buf339.group.device = cuda:0
    buf339.group.iteration = (256, 1)
    buf339.sizes = ([256], [])
    buf171_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    primals_102_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf339_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf339_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf171', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_102', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf339', get_index_2, add, None)
            return store
    buf339 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf171_buf172_buf174_buf339_buf340_buf342_buf343.snodes[4] =
    buf340: SchedulerNode(ComputedBuffer)
    buf340.writes = [MemoryDep('buf340', c0, {c0: 256}, None)]
    buf340.unmet_dependencies = [MemoryDep('buf339', c0, {c0: 256}, None)]
    buf340.met_dependencies = [StarDep(name='primals_102', mode=None)]
    buf340.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf340.group.device = cuda:0
    buf340.group.iteration = (256, 1)
    buf340.sizes = ([256], [])
    primals_102_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf339_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf340_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf340.mutations = ['primals_102']
    class buf340_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf339', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf340', get_index_1, load, None)
            return store
    buf340 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf171_buf172_buf174_buf339_buf340_buf342_buf343.snodes[5] =
    buf342: SchedulerNode(ComputedBuffer)
    buf342.writes = [MemoryDep('buf342', c0, {c0: 256}, None)]
    buf342.unmet_dependencies = [MemoryDep('buf172', c0, {c0: 256}, None)]
    buf342.met_dependencies = [MemoryDep('primals_103', c0, {c0: 256}, None)]
    buf342.users = [NodeUser(node=SchedulerNode(name='buf343'), can_inplace=True, is_weak=False)]
    buf342.group.device = cuda:0
    buf342.group.iteration = (256, 1)
    buf342.sizes = ([256], [])
    primals_103_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf172_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf342_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf342_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf172', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0001594642002871, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_103', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf342', get_index_2, add, None)
            return store
    buf342 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0001594642002871
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf171_buf172_buf174_buf339_buf340_buf342_buf343.snodes[6] =
    buf343: SchedulerNode(ComputedBuffer)
    buf343.writes = [MemoryDep('buf343', c0, {c0: 256}, None)]
    buf343.unmet_dependencies = [MemoryDep('buf342', c0, {c0: 256}, None)]
    buf343.met_dependencies = [StarDep(name='primals_103', mode=None)]
    buf343.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf343.group.device = cuda:0
    buf343.group.iteration = (256, 1)
    buf343.sizes = ([256], [])
    buf342_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    primals_103_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf343_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf343.mutations = ['primals_103']
    class buf343_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf342', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf343', get_index_1, load, None)
            return store
    buf343 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf171_buf172_buf174_buf339_buf340_buf342_buf343 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 6272.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0001594642002871
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf175: SchedulerNode(ComputedBuffer)
buf175.writes = [MemoryDep('buf175', c0, {c0: 1605632}, None)]
buf175.unmet_dependencies = 
    [   MemoryDep('buf167', c0, {c0: 1605632}, None),
        MemoryDep('buf171', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf172', c1, {c0: 6272, c1: 256}, None)]
buf175.met_dependencies = 
    [   MemoryDep('primals_41', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('primals_42', c1, {c0: 6272, c1: 256}, None)]
buf175.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf176'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf175.group.device = cuda:0
buf175.group.iteration = (1605632, 1)
buf175.sizes = ([6272, 256], [])
buf172_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
buf171_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
buf167_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
primals_41_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
primals_42_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf175_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf175_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf167', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf171', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf172', get_index_2)
        constant = ops.constant(6272.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_41', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_42', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf175', get_index_5, relu, None)
        return store
buf175 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 6272.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf176: ExternKernelSchedulerNode(ExternKernelAlloc)
buf176.writes = [StarDep(name='buf176', mode=None)]
buf176.unmet_dependencies = [StarDep(name='buf12', mode=None), StarDep(name='buf175', mode=None)]
buf176.met_dependencies = []
buf176.users = [NodeUser(node=SchedulerNode(name='buf177'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf178'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf179'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf184'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf176.node.kernel = extern_kernels.convolution


buf177_buf178_buf179: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf177_buf178_buf179.writes = 
    [   MemoryDep('buf177', c0, {c0: 12544}, None),
        MemoryDep('buf178', c0, {c0: 12544}, None),
        MemoryDep('buf179', c0, {c0: 12544}, None)]
buf177_buf178_buf179.unmet_dependencies = [MemoryDep('buf176', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
buf177_buf178_buf179.met_dependencies = []
buf177_buf178_buf179.users = []
    buf177_buf178_buf179.snodes[0] =
    buf177: SchedulerNode(ComputedBuffer)
    buf177.writes = [MemoryDep('buf177', c0, {c0: 12544}, None)]
    buf177.unmet_dependencies = [MemoryDep('buf176', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf177.met_dependencies = []
    buf177.users = [NodeUser(node=SchedulerNode(name='buf180'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf181'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf182'), can_inplace=False, is_weak=False)]
    buf177.group.device = cuda:0
    buf177.group.iteration = (12544, 128)
    buf177.sizes = ([49, 256], [128])
    buf176_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf177_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf177_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf176', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf177', get_index_1, getitem)
            return store_reduction
    buf177 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
    buf177_buf178_buf179.snodes[1] =
    buf178: SchedulerNode(ComputedBuffer)
    buf178.writes = [MemoryDep('buf178', c0, {c0: 12544}, None)]
    buf178.unmet_dependencies = [MemoryDep('buf176', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf178.met_dependencies = []
    buf178.users = [NodeUser(node=SchedulerNode(name='buf180'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf181'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf182'), can_inplace=False, is_weak=False)]
    buf178.group.device = cuda:0
    buf178.group.iteration = (12544, 128)
    buf178.sizes = ([49, 256], [128])
    buf176_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf178_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf178_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf176', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf178', get_index_1, getitem_1)
            return store_reduction
    buf178 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp3, xmask)
    buf177_buf178_buf179.snodes[2] =
    buf179: SchedulerNode(ComputedBuffer)
    buf179.writes = [MemoryDep('buf179', c0, {c0: 12544}, None)]
    buf179.unmet_dependencies = [MemoryDep('buf176', 32768*c0 + c1 + 256*c2, {c0: 49, c1: 256, c2: 128}, None)]
    buf179.met_dependencies = []
    buf179.users = [NodeUser(node=SchedulerNode(name='buf180'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf181'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf182'), can_inplace=False, is_weak=False)]
    buf179.group.device = cuda:0
    buf179.group.iteration = (12544, 128)
    buf179.sizes = ([49, 256], [128])
    buf176_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
    buf179_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    class buf179_loop_body:
        var_ranges = {z0: 49, z1: 256, z2: 128}
        index0 = 32768*z0 + z1 + 256*z2
        index1 = 256*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf176', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf179', get_index_1, getitem_2)
            return store_reduction
    buf179 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp4, xmask)
    buf177_buf178_buf179 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[16384, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 12544
            rnumel = 128
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x0 = xindex % 256
            x1 = (xindex // 256)
            tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, eviction_policy='evict_last', other=0.0)
                tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
                tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
                    tmp1, tmp2_mean, tmp2_m2, tmp2_weight, roffset == 0
                )
                tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
                tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
                tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
            tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
                tmp2_mean, tmp2_m2, tmp2_weight, 1
            )
            tmp2 = tmp2_tmp[:, None]
            tmp3 = tmp3_tmp[:, None]
            tmp4 = tmp4_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp2, xmask)
            tl.store(out_ptr1 + (x3), tmp3, xmask)
            tl.store(out_ptr2 + (x3), tmp4, xmask)


buf180_buf181_buf183_buf347_buf348_buf350_buf351: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf180_buf181_buf183_buf347_buf348_buf350_buf351.writes = 
    [   MemoryDep('buf180', c0, {c0: 256}, None),
        MemoryDep('buf181', c0, {c0: 256}, None),
        MemoryDep('buf183', c0, {c0: 256}, None),
        MemoryDep('buf347', c0, {c0: 256}, None),
        MemoryDep('buf348', c0, {c0: 256}, None),
        MemoryDep('buf350', c0, {c0: 256}, None),
        MemoryDep('buf351', c0, {c0: 256}, None)]
buf180_buf181_buf183_buf347_buf348_buf350_buf351.unmet_dependencies = 
    [   MemoryDep('buf177', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf178', c0 + 256*c1, {c0: 256, c1: 49}, None),
        MemoryDep('buf179', c0 + 256*c1, {c0: 256, c1: 49}, None)]
buf180_buf181_buf183_buf347_buf348_buf350_buf351.met_dependencies = 
    [   MemoryDep('primals_105', c0, {c0: 256}, None),
        MemoryDep('primals_106', c0, {c0: 256}, None),
        StarDep(name='primals_105', mode=None),
        StarDep(name='primals_106', mode=None)]
buf180_buf181_buf183_buf347_buf348_buf350_buf351.users = []
    buf180_buf181_buf183_buf347_buf348_buf350_buf351.snodes[0] =
    buf180: SchedulerNode(ComputedBuffer)
    buf180.writes = [MemoryDep('buf180', c0, {c0: 256}, None)]
    buf180.unmet_dependencies = 
        [   MemoryDep('buf177', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf178', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf179', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf180.met_dependencies = []
    buf180.users = [NodeUser(node=SchedulerNode(name='buf184'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf347'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf180.group.device = cuda:0
    buf180.group.iteration = (256, 49)
    buf180.sizes = ([256], [49])
    buf178_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf177_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf179_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf180_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf180_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf177', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf178', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf179', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf180', get_index_3, getitem)
            return store_reduction
    buf180 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf180_buf181_buf183_buf347_buf348_buf350_buf351.snodes[1] =
    buf181: SchedulerNode(ComputedBuffer)
    buf181.writes = [MemoryDep('buf181', c0, {c0: 256}, None)]
    buf181.unmet_dependencies = 
        [   MemoryDep('buf177', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf178', c0 + 256*c1, {c0: 256, c1: 49}, None),
            MemoryDep('buf179', c0 + 256*c1, {c0: 256, c1: 49}, None)]
    buf181.met_dependencies = []
    buf181.users = [NodeUser(node=SchedulerNode(name='buf183'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf184'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf350'), can_inplace=True, is_weak=False)]
    buf181.group.device = cuda:0
    buf181.group.iteration = (256, 49)
    buf181.sizes = ([256], [49])
    buf178_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf177_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf179_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1, 49], stride=[12544, 1, 12544, 12544, 256])
    buf181_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf181_loop_body:
        var_ranges = {z0: 256, z1: 49}
        index0 = z0 + 256*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf177', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf178', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf179', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf181', get_index_3, getitem_1)
            return store_reduction
    buf181 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf180_buf181_buf183_buf347_buf348_buf350_buf351.snodes[2] =
    buf183: SchedulerNode(ComputedBuffer)
    buf183.writes = [MemoryDep('buf183', c0, {c0: 256}, None)]
    buf183.unmet_dependencies = [MemoryDep('buf181', c0, {c0: 256}, None)]
    buf183.met_dependencies = []
    buf183.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf183.group.device = cuda:0
    buf183.group.iteration = (256, 1)
    buf183.sizes = ([256], [])
    buf181_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf183_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    class buf183_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf181', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf183', get_index_1, rsqrt, None)
            return store
    buf183 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf180_buf181_buf183_buf347_buf348_buf350_buf351.snodes[3] =
    buf347: SchedulerNode(ComputedBuffer)
    buf347.writes = [MemoryDep('buf347', c0, {c0: 256}, None)]
    buf347.unmet_dependencies = [MemoryDep('buf180', c0, {c0: 256}, None)]
    buf347.met_dependencies = [MemoryDep('primals_105', c0, {c0: 256}, None)]
    buf347.users = [NodeUser(node=SchedulerNode(name='buf348'), can_inplace=True, is_weak=False)]
    buf347.group.device = cuda:0
    buf347.group.iteration = (256, 1)
    buf347.sizes = ([256], [])
    buf180_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    primals_105_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf347_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf347_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf180', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_105', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf347', get_index_2, add, None)
            return store
    buf347 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf180_buf181_buf183_buf347_buf348_buf350_buf351.snodes[4] =
    buf348: SchedulerNode(ComputedBuffer)
    buf348.writes = [MemoryDep('buf348', c0, {c0: 256}, None)]
    buf348.unmet_dependencies = [MemoryDep('buf347', c0, {c0: 256}, None)]
    buf348.met_dependencies = [StarDep(name='primals_105', mode=None)]
    buf348.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf348.group.device = cuda:0
    buf348.group.iteration = (256, 1)
    buf348.sizes = ([256], [])
    buf347_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    primals_105_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf348_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf348.mutations = ['primals_105']
    class buf348_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf347', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf348', get_index_1, load, None)
            return store
    buf348 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf180_buf181_buf183_buf347_buf348_buf350_buf351.snodes[5] =
    buf350: SchedulerNode(ComputedBuffer)
    buf350.writes = [MemoryDep('buf350', c0, {c0: 256}, None)]
    buf350.unmet_dependencies = [MemoryDep('buf181', c0, {c0: 256}, None)]
    buf350.met_dependencies = [MemoryDep('primals_106', c0, {c0: 256}, None)]
    buf350.users = [NodeUser(node=SchedulerNode(name='buf351'), can_inplace=True, is_weak=False)]
    buf350.group.device = cuda:0
    buf350.group.iteration = (256, 1)
    buf350.sizes = ([256], [])
    primals_106_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf181_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
    buf350_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    class buf350_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf181', get_index)
            constant = ops.constant(6272.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0001594642002871, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_106', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf350', get_index_2, add, None)
            return store
    buf350 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 6272.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0001594642002871
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf180_buf181_buf183_buf347_buf348_buf350_buf351.snodes[6] =
    buf351: SchedulerNode(ComputedBuffer)
    buf351.writes = [MemoryDep('buf351', c0, {c0: 256}, None)]
    buf351.unmet_dependencies = [MemoryDep('buf350', c0, {c0: 256}, None)]
    buf351.met_dependencies = [StarDep(name='primals_106', mode=None)]
    buf351.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf351.group.device = cuda:0
    buf351.group.iteration = (256, 1)
    buf351.sizes = ([256], [])
    buf350_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    primals_106_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
    buf351_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[256], stride=[1])
    buf351.mutations = ['primals_106']
    class buf351_loop_body:
        var_ranges = {z0: 256}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf350', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf351', get_index_1, load, None)
            return store
    buf351 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[256], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf180_buf181_buf183_buf347_buf348_buf350_buf351 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[256, 64],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 256
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 6272.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0001594642002871
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf184: SchedulerNode(ComputedBuffer)
buf184.writes = [MemoryDep('buf184', c0, {c0: 1605632}, None)]
buf184.unmet_dependencies = 
    [   MemoryDep('buf166', c0, {c0: 1605632}, None),
        MemoryDep('buf176', c0, {c0: 1605632}, None),
        MemoryDep('buf180', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('buf181', c1, {c0: 6272, c1: 256}, None)]
buf184.met_dependencies = 
    [   MemoryDep('primals_44', c1, {c0: 6272, c1: 256}, None),
        MemoryDep('primals_45', c1, {c0: 6272, c1: 256}, None)]
buf184.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf185'), can_inplace=False, is_weak=False), NodeUser(node=ExternKernelSchedulerNode(name='buf202'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf184.group.device = cuda:0
buf184.group.iteration = (1605632, 1)
buf184.sizes = ([6272, 256], [])
primals_45_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf180_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
primals_44_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf181_layout = FixedLayout('cuda', torch.float32, size=[1, 256, 1, 1], stride=[256, 1, 256, 256])
buf176_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf166_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
buf184_layout = FixedLayout('cuda', torch.float32, size=[32, 256, 14, 14], stride=[50176, 1, 3584, 256])
class buf184_loop_body:
    var_ranges = {z0: 6272, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf176', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf180', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf181', get_index_2)
        constant = ops.constant(6272.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_44', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_45', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        get_index_5 = self.get_index('index0')
        load_5 = ops.load('buf166', get_index_5)
        add_2 = ops.add(add_1, load_5)
        relu = ops.relu(add_2)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf184', get_index_6, relu, None)
        return store
buf184 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[2097152], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1605632
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 256
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp14 = tl.load(in_ptr5 + (x2), None)
        tmp2 = tmp0 - tmp1
        tmp4 = 6272.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp15 = tmp13 + tmp14
        tmp16 = tl.full([1], 0, tl.int32)
        tmp17 = triton_helpers.maximum(tmp16, tmp15)
        tl.store(out_ptr0 + (x2), tmp17, None)


buf185: ExternKernelSchedulerNode(ExternKernelAlloc)
buf185.writes = [StarDep(name='buf185', mode=None)]
buf185.unmet_dependencies = [StarDep(name='buf13', mode=None), StarDep(name='buf184', mode=None)]
buf185.met_dependencies = []
buf185.users = [NodeUser(node=SchedulerNode(name='buf186'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf187'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf188'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf193'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf185.node.kernel = extern_kernels.convolution


buf186_buf187_buf188: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf186_buf187_buf188.writes = 
    [   MemoryDep('buf186', c0, {c0: 6656}, None),
        MemoryDep('buf187', c0, {c0: 6656}, None),
        MemoryDep('buf188', c0, {c0: 6656}, None)]
buf186_buf187_buf188.unmet_dependencies = [   MemoryDep('buf185', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf186_buf187_buf188.met_dependencies = []
buf186_buf187_buf188.users = []
    buf186_buf187_buf188.snodes[0] =
    buf186: SchedulerNode(ComputedBuffer)
    buf186.writes = [MemoryDep('buf186', c0, {c0: 6656}, None)]
    buf186.unmet_dependencies = [   MemoryDep('buf185', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf186.met_dependencies = []
    buf186.users = [NodeUser(node=SchedulerNode(name='buf189'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf190'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf191'), can_inplace=False, is_weak=False)]
    buf186.group.device = cuda:0
    buf186.group.iteration = (6656, 121)
    buf186.sizes = ([13, 512], [121])
    buf185_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf186_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf186_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf186', get_index_3, getitem)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf185', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf186 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
    buf186_buf187_buf188.snodes[1] =
    buf187: SchedulerNode(ComputedBuffer)
    buf187.writes = [MemoryDep('buf187', c0, {c0: 6656}, None)]
    buf187.unmet_dependencies = [   MemoryDep('buf185', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf187.met_dependencies = []
    buf187.users = [NodeUser(node=SchedulerNode(name='buf189'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf190'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf191'), can_inplace=False, is_weak=False)]
    buf187.group.device = cuda:0
    buf187.group.iteration = (6656, 121)
    buf187.sizes = ([13, 512], [121])
    buf185_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf187_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf187_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf187', get_index_3, getitem_1)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf185', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf187 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp16, xmask)
    buf186_buf187_buf188.snodes[2] =
    buf188: SchedulerNode(ComputedBuffer)
    buf188.writes = [MemoryDep('buf188', c0, {c0: 6656}, None)]
    buf188.unmet_dependencies = [   MemoryDep('buf185', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf188.met_dependencies = []
    buf188.users = [NodeUser(node=SchedulerNode(name='buf189'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf190'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf191'), can_inplace=False, is_weak=False)]
    buf188.group.device = cuda:0
    buf188.group.iteration = (6656, 121)
    buf188.sizes = ([13, 512], [121])
    buf185_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf188_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf188_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf188', get_index_3, getitem_2)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf185', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf188 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp17, xmask)
    buf186_buf187_buf188 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
            tl.store(out_ptr1 + (x3), tmp16, xmask)
            tl.store(out_ptr2 + (x3), tmp17, xmask)


buf189_buf190_buf192_buf355_buf356_buf358_buf359: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf189_buf190_buf192_buf355_buf356_buf358_buf359.writes = 
    [   MemoryDep('buf189', c0, {c0: 512}, None),
        MemoryDep('buf190', c0, {c0: 512}, None),
        MemoryDep('buf192', c0, {c0: 512}, None),
        MemoryDep('buf355', c0, {c0: 512}, None),
        MemoryDep('buf356', c0, {c0: 512}, None),
        MemoryDep('buf358', c0, {c0: 512}, None),
        MemoryDep('buf359', c0, {c0: 512}, None)]
buf189_buf190_buf192_buf355_buf356_buf358_buf359.unmet_dependencies = 
    [   MemoryDep('buf186', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf187', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf188', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf189_buf190_buf192_buf355_buf356_buf358_buf359.met_dependencies = 
    [   MemoryDep('primals_108', c0, {c0: 512}, None),
        MemoryDep('primals_109', c0, {c0: 512}, None),
        StarDep(name='primals_108', mode=None),
        StarDep(name='primals_109', mode=None)]
buf189_buf190_buf192_buf355_buf356_buf358_buf359.users = []
    buf189_buf190_buf192_buf355_buf356_buf358_buf359.snodes[0] =
    buf189: SchedulerNode(ComputedBuffer)
    buf189.writes = [MemoryDep('buf189', c0, {c0: 512}, None)]
    buf189.unmet_dependencies = 
        [   MemoryDep('buf186', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf187', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf188', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf189.met_dependencies = []
    buf189.users = [NodeUser(node=SchedulerNode(name='buf193'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf355'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf189.group.device = cuda:0
    buf189.group.iteration = (512, 13)
    buf189.sizes = ([512], [13])
    buf188_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf187_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf186_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf189_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf189_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf186', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf187', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf188', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf189', get_index_3, getitem)
            return store_reduction
    buf189 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf189_buf190_buf192_buf355_buf356_buf358_buf359.snodes[1] =
    buf190: SchedulerNode(ComputedBuffer)
    buf190.writes = [MemoryDep('buf190', c0, {c0: 512}, None)]
    buf190.unmet_dependencies = 
        [   MemoryDep('buf186', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf187', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf188', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf190.met_dependencies = []
    buf190.users = [NodeUser(node=SchedulerNode(name='buf192'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf193'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf358'), can_inplace=True, is_weak=False)]
    buf190.group.device = cuda:0
    buf190.group.iteration = (512, 13)
    buf190.sizes = ([512], [13])
    buf188_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf187_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf186_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf190_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf190_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf186', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf187', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf188', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf190', get_index_3, getitem_1)
            return store_reduction
    buf190 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf189_buf190_buf192_buf355_buf356_buf358_buf359.snodes[2] =
    buf192: SchedulerNode(ComputedBuffer)
    buf192.writes = [MemoryDep('buf192', c0, {c0: 512}, None)]
    buf192.unmet_dependencies = [MemoryDep('buf190', c0, {c0: 512}, None)]
    buf192.met_dependencies = []
    buf192.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf192.group.device = cuda:0
    buf192.group.iteration = (512, 1)
    buf192.sizes = ([512], [])
    buf190_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf192_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf192_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf190', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf192', get_index_1, rsqrt, None)
            return store
    buf192 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf189_buf190_buf192_buf355_buf356_buf358_buf359.snodes[3] =
    buf355: SchedulerNode(ComputedBuffer)
    buf355.writes = [MemoryDep('buf355', c0, {c0: 512}, None)]
    buf355.unmet_dependencies = [MemoryDep('buf189', c0, {c0: 512}, None)]
    buf355.met_dependencies = [MemoryDep('primals_108', c0, {c0: 512}, None)]
    buf355.users = [NodeUser(node=SchedulerNode(name='buf356'), can_inplace=True, is_weak=False)]
    buf355.group.device = cuda:0
    buf355.group.iteration = (512, 1)
    buf355.sizes = ([512], [])
    buf189_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_108_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf355_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf355_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf189', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_108', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf355', get_index_2, add, None)
            return store
    buf355 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf189_buf190_buf192_buf355_buf356_buf358_buf359.snodes[4] =
    buf356: SchedulerNode(ComputedBuffer)
    buf356.writes = [MemoryDep('buf356', c0, {c0: 512}, None)]
    buf356.unmet_dependencies = [MemoryDep('buf355', c0, {c0: 512}, None)]
    buf356.met_dependencies = [StarDep(name='primals_108', mode=None)]
    buf356.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf356.group.device = cuda:0
    buf356.group.iteration = (512, 1)
    buf356.sizes = ([512], [])
    primals_108_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf355_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf356_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf356.mutations = ['primals_108']
    class buf356_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf355', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf356', get_index_1, load, None)
            return store
    buf356 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf189_buf190_buf192_buf355_buf356_buf358_buf359.snodes[5] =
    buf358: SchedulerNode(ComputedBuffer)
    buf358.writes = [MemoryDep('buf358', c0, {c0: 512}, None)]
    buf358.unmet_dependencies = [MemoryDep('buf190', c0, {c0: 512}, None)]
    buf358.met_dependencies = [MemoryDep('primals_109', c0, {c0: 512}, None)]
    buf358.users = [NodeUser(node=SchedulerNode(name='buf359'), can_inplace=True, is_weak=False)]
    buf358.group.device = cuda:0
    buf358.group.iteration = (512, 1)
    buf358.sizes = ([512], [])
    buf190_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_109_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf358_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf358_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf190', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0006381620931717, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_109', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf358', get_index_2, add, None)
            return store
    buf358 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0006381620931717
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf189_buf190_buf192_buf355_buf356_buf358_buf359.snodes[6] =
    buf359: SchedulerNode(ComputedBuffer)
    buf359.writes = [MemoryDep('buf359', c0, {c0: 512}, None)]
    buf359.unmet_dependencies = [MemoryDep('buf358', c0, {c0: 512}, None)]
    buf359.met_dependencies = [StarDep(name='primals_109', mode=None)]
    buf359.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf359.group.device = cuda:0
    buf359.group.iteration = (512, 1)
    buf359.sizes = ([512], [])
    buf358_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    primals_109_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf359_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf359.mutations = ['primals_109']
    class buf359_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf358', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf359', get_index_1, load, None)
            return store
    buf359 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf189_buf190_buf192_buf355_buf356_buf358_buf359 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 1568.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0006381620931717
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf193: SchedulerNode(ComputedBuffer)
buf193.writes = [MemoryDep('buf193', c0, {c0: 802816}, None)]
buf193.unmet_dependencies = 
    [   MemoryDep('buf185', c0, {c0: 802816}, None),
        MemoryDep('buf189', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf190', c1, {c0: 1568, c1: 512}, None)]
buf193.met_dependencies = 
    [   MemoryDep('primals_47', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('primals_48', c1, {c0: 1568, c1: 512}, None)]
buf193.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf194'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf193.group.device = cuda:0
buf193.group.iteration = (802816, 1)
buf193.sizes = ([1568, 512], [])
buf189_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
primals_47_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
primals_48_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf190_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
buf185_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
buf193_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf193_loop_body:
    var_ranges = {z0: 1568, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf185', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf189', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf190', get_index_2)
        constant = ops.constant(1568.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_47', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_48', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf193', get_index_5, relu, None)
        return store
buf193 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 512
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 1568.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf194: ExternKernelSchedulerNode(ExternKernelAlloc)
buf194.writes = [StarDep(name='buf194', mode=None)]
buf194.unmet_dependencies = [StarDep(name='buf14', mode=None), StarDep(name='buf193', mode=None)]
buf194.met_dependencies = []
buf194.users = [NodeUser(node=SchedulerNode(name='buf195'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf196'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf197'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf210'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf194.node.kernel = extern_kernels.convolution


buf195_buf196_buf197: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf195_buf196_buf197.writes = 
    [   MemoryDep('buf195', c0, {c0: 6656}, None),
        MemoryDep('buf196', c0, {c0: 6656}, None),
        MemoryDep('buf197', c0, {c0: 6656}, None)]
buf195_buf196_buf197.unmet_dependencies = [   MemoryDep('buf194', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf195_buf196_buf197.met_dependencies = []
buf195_buf196_buf197.users = []
    buf195_buf196_buf197.snodes[0] =
    buf195: SchedulerNode(ComputedBuffer)
    buf195.writes = [MemoryDep('buf195', c0, {c0: 6656}, None)]
    buf195.unmet_dependencies = [   MemoryDep('buf194', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf195.met_dependencies = []
    buf195.users = [NodeUser(node=SchedulerNode(name='buf198'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf199'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf200'), can_inplace=False, is_weak=False)]
    buf195.group.device = cuda:0
    buf195.group.iteration = (6656, 121)
    buf195.sizes = ([13, 512], [121])
    buf194_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf195_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf195_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf195', get_index_3, getitem)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf194', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf195 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
    buf195_buf196_buf197.snodes[1] =
    buf196: SchedulerNode(ComputedBuffer)
    buf196.writes = [MemoryDep('buf196', c0, {c0: 6656}, None)]
    buf196.unmet_dependencies = [   MemoryDep('buf194', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf196.met_dependencies = []
    buf196.users = [NodeUser(node=SchedulerNode(name='buf198'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf199'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf200'), can_inplace=False, is_weak=False)]
    buf196.group.device = cuda:0
    buf196.group.iteration = (6656, 121)
    buf196.sizes = ([13, 512], [121])
    buf194_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf196_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf196_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf196', get_index_3, getitem_1)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf194', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf196 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp16, xmask)
    buf195_buf196_buf197.snodes[2] =
    buf197: SchedulerNode(ComputedBuffer)
    buf197.writes = [MemoryDep('buf197', c0, {c0: 6656}, None)]
    buf197.unmet_dependencies = [   MemoryDep('buf194', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf197.met_dependencies = []
    buf197.users = [NodeUser(node=SchedulerNode(name='buf198'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf199'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf200'), can_inplace=False, is_weak=False)]
    buf197.group.device = cuda:0
    buf197.group.iteration = (6656, 121)
    buf197.sizes = ([13, 512], [121])
    buf194_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf197_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf197_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf197', get_index_3, getitem_2)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf194', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf197 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp17, xmask)
    buf195_buf196_buf197 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
            tl.store(out_ptr1 + (x3), tmp16, xmask)
            tl.store(out_ptr2 + (x3), tmp17, xmask)


buf198_buf199_buf201_buf363_buf364_buf366_buf367: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf198_buf199_buf201_buf363_buf364_buf366_buf367.writes = 
    [   MemoryDep('buf198', c0, {c0: 512}, None),
        MemoryDep('buf199', c0, {c0: 512}, None),
        MemoryDep('buf201', c0, {c0: 512}, None),
        MemoryDep('buf363', c0, {c0: 512}, None),
        MemoryDep('buf364', c0, {c0: 512}, None),
        MemoryDep('buf366', c0, {c0: 512}, None),
        MemoryDep('buf367', c0, {c0: 512}, None)]
buf198_buf199_buf201_buf363_buf364_buf366_buf367.unmet_dependencies = 
    [   MemoryDep('buf195', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf196', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf197', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf198_buf199_buf201_buf363_buf364_buf366_buf367.met_dependencies = 
    [   MemoryDep('primals_111', c0, {c0: 512}, None),
        MemoryDep('primals_112', c0, {c0: 512}, None),
        StarDep(name='primals_111', mode=None),
        StarDep(name='primals_112', mode=None)]
buf198_buf199_buf201_buf363_buf364_buf366_buf367.users = []
    buf198_buf199_buf201_buf363_buf364_buf366_buf367.snodes[0] =
    buf198: SchedulerNode(ComputedBuffer)
    buf198.writes = [MemoryDep('buf198', c0, {c0: 512}, None)]
    buf198.unmet_dependencies = 
        [   MemoryDep('buf195', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf196', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf197', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf198.met_dependencies = []
    buf198.users = [NodeUser(node=SchedulerNode(name='buf210'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf363'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf198.group.device = cuda:0
    buf198.group.iteration = (512, 13)
    buf198.sizes = ([512], [13])
    buf196_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf195_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf197_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf198_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf198_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf195', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf196', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf197', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf198', get_index_3, getitem)
            return store_reduction
    buf198 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf198_buf199_buf201_buf363_buf364_buf366_buf367.snodes[1] =
    buf199: SchedulerNode(ComputedBuffer)
    buf199.writes = [MemoryDep('buf199', c0, {c0: 512}, None)]
    buf199.unmet_dependencies = 
        [   MemoryDep('buf195', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf196', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf197', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf199.met_dependencies = []
    buf199.users = [NodeUser(node=SchedulerNode(name='buf201'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf210'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf366'), can_inplace=True, is_weak=False)]
    buf199.group.device = cuda:0
    buf199.group.iteration = (512, 13)
    buf199.sizes = ([512], [13])
    buf196_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf195_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf197_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf199_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf199_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf195', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf196', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf197', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf199', get_index_3, getitem_1)
            return store_reduction
    buf199 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf198_buf199_buf201_buf363_buf364_buf366_buf367.snodes[2] =
    buf201: SchedulerNode(ComputedBuffer)
    buf201.writes = [MemoryDep('buf201', c0, {c0: 512}, None)]
    buf201.unmet_dependencies = [MemoryDep('buf199', c0, {c0: 512}, None)]
    buf201.met_dependencies = []
    buf201.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf201.group.device = cuda:0
    buf201.group.iteration = (512, 1)
    buf201.sizes = ([512], [])
    buf199_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf201_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf201_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf199', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf201', get_index_1, rsqrt, None)
            return store
    buf201 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf198_buf199_buf201_buf363_buf364_buf366_buf367.snodes[3] =
    buf363: SchedulerNode(ComputedBuffer)
    buf363.writes = [MemoryDep('buf363', c0, {c0: 512}, None)]
    buf363.unmet_dependencies = [MemoryDep('buf198', c0, {c0: 512}, None)]
    buf363.met_dependencies = [MemoryDep('primals_111', c0, {c0: 512}, None)]
    buf363.users = [NodeUser(node=SchedulerNode(name='buf364'), can_inplace=True, is_weak=False)]
    buf363.group.device = cuda:0
    buf363.group.iteration = (512, 1)
    buf363.sizes = ([512], [])
    buf198_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_111_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf363_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf363_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf198', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_111', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf363', get_index_2, add, None)
            return store
    buf363 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf198_buf199_buf201_buf363_buf364_buf366_buf367.snodes[4] =
    buf364: SchedulerNode(ComputedBuffer)
    buf364.writes = [MemoryDep('buf364', c0, {c0: 512}, None)]
    buf364.unmet_dependencies = [MemoryDep('buf363', c0, {c0: 512}, None)]
    buf364.met_dependencies = [StarDep(name='primals_111', mode=None)]
    buf364.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf364.group.device = cuda:0
    buf364.group.iteration = (512, 1)
    buf364.sizes = ([512], [])
    primals_111_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf363_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf364_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf364.mutations = ['primals_111']
    class buf364_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf363', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf364', get_index_1, load, None)
            return store
    buf364 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf198_buf199_buf201_buf363_buf364_buf366_buf367.snodes[5] =
    buf366: SchedulerNode(ComputedBuffer)
    buf366.writes = [MemoryDep('buf366', c0, {c0: 512}, None)]
    buf366.unmet_dependencies = [MemoryDep('buf199', c0, {c0: 512}, None)]
    buf366.met_dependencies = [MemoryDep('primals_112', c0, {c0: 512}, None)]
    buf366.users = [NodeUser(node=SchedulerNode(name='buf367'), can_inplace=True, is_weak=False)]
    buf366.group.device = cuda:0
    buf366.group.iteration = (512, 1)
    buf366.sizes = ([512], [])
    buf199_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_112_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf366_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf366_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf199', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0006381620931717, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_112', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf366', get_index_2, add, None)
            return store
    buf366 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0006381620931717
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf198_buf199_buf201_buf363_buf364_buf366_buf367.snodes[6] =
    buf367: SchedulerNode(ComputedBuffer)
    buf367.writes = [MemoryDep('buf367', c0, {c0: 512}, None)]
    buf367.unmet_dependencies = [MemoryDep('buf366', c0, {c0: 512}, None)]
    buf367.met_dependencies = [StarDep(name='primals_112', mode=None)]
    buf367.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf367.group.device = cuda:0
    buf367.group.iteration = (512, 1)
    buf367.sizes = ([512], [])
    buf366_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    primals_112_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf367_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf367.mutations = ['primals_112']
    class buf367_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf366', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf367', get_index_1, load, None)
            return store
    buf367 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf198_buf199_buf201_buf363_buf364_buf366_buf367 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 1568.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0006381620931717
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf202: ExternKernelSchedulerNode(ExternKernelAlloc)
buf202.writes = [StarDep(name='buf202', mode=None)]
buf202.unmet_dependencies = [StarDep(name='buf184', mode=None)]
buf202.met_dependencies = [StarDep(name='primals_52', mode=None)]
buf202.users = [NodeUser(node=SchedulerNode(name='buf203'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf204'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf205'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf210'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf202.node.kernel = extern_kernels.convolution


buf203_buf204_buf205: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf203_buf204_buf205.writes = 
    [   MemoryDep('buf203', c0, {c0: 6656}, None),
        MemoryDep('buf204', c0, {c0: 6656}, None),
        MemoryDep('buf205', c0, {c0: 6656}, None)]
buf203_buf204_buf205.unmet_dependencies = [   MemoryDep('buf202', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf203_buf204_buf205.met_dependencies = []
buf203_buf204_buf205.users = []
    buf203_buf204_buf205.snodes[0] =
    buf203: SchedulerNode(ComputedBuffer)
    buf203.writes = [MemoryDep('buf203', c0, {c0: 6656}, None)]
    buf203.unmet_dependencies = [   MemoryDep('buf202', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf203.met_dependencies = []
    buf203.users = [NodeUser(node=SchedulerNode(name='buf206'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf207'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf208'), can_inplace=False, is_weak=False)]
    buf203.group.device = cuda:0
    buf203.group.iteration = (6656, 121)
    buf203.sizes = ([13, 512], [121])
    buf202_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf203_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf203_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf203', get_index_3, getitem)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf202', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf203 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
    buf203_buf204_buf205.snodes[1] =
    buf204: SchedulerNode(ComputedBuffer)
    buf204.writes = [MemoryDep('buf204', c0, {c0: 6656}, None)]
    buf204.unmet_dependencies = [   MemoryDep('buf202', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf204.met_dependencies = []
    buf204.users = [NodeUser(node=SchedulerNode(name='buf206'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf207'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf208'), can_inplace=False, is_weak=False)]
    buf204.group.device = cuda:0
    buf204.group.iteration = (6656, 121)
    buf204.sizes = ([13, 512], [121])
    buf202_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf204_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf204_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf204', get_index_3, getitem_1)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf202', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf204 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp16, xmask)
    buf203_buf204_buf205.snodes[2] =
    buf205: SchedulerNode(ComputedBuffer)
    buf205.writes = [MemoryDep('buf205', c0, {c0: 6656}, None)]
    buf205.unmet_dependencies = [   MemoryDep('buf202', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf205.met_dependencies = []
    buf205.users = [NodeUser(node=SchedulerNode(name='buf206'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf207'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf208'), can_inplace=False, is_weak=False)]
    buf205.group.device = cuda:0
    buf205.group.iteration = (6656, 121)
    buf205.sizes = ([13, 512], [121])
    buf202_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf205_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf205_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf205', get_index_3, getitem_2)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf202', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf205 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp17, xmask)
    buf203_buf204_buf205 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
            tl.store(out_ptr1 + (x3), tmp16, xmask)
            tl.store(out_ptr2 + (x3), tmp17, xmask)


buf206_buf207_buf209_buf371_buf372_buf374_buf375: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf206_buf207_buf209_buf371_buf372_buf374_buf375.writes = 
    [   MemoryDep('buf206', c0, {c0: 512}, None),
        MemoryDep('buf207', c0, {c0: 512}, None),
        MemoryDep('buf209', c0, {c0: 512}, None),
        MemoryDep('buf371', c0, {c0: 512}, None),
        MemoryDep('buf372', c0, {c0: 512}, None),
        MemoryDep('buf374', c0, {c0: 512}, None),
        MemoryDep('buf375', c0, {c0: 512}, None)]
buf206_buf207_buf209_buf371_buf372_buf374_buf375.unmet_dependencies = 
    [   MemoryDep('buf203', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf204', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf205', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf206_buf207_buf209_buf371_buf372_buf374_buf375.met_dependencies = 
    [   MemoryDep('primals_114', c0, {c0: 512}, None),
        MemoryDep('primals_115', c0, {c0: 512}, None),
        StarDep(name='primals_114', mode=None),
        StarDep(name='primals_115', mode=None)]
buf206_buf207_buf209_buf371_buf372_buf374_buf375.users = []
    buf206_buf207_buf209_buf371_buf372_buf374_buf375.snodes[0] =
    buf206: SchedulerNode(ComputedBuffer)
    buf206.writes = [MemoryDep('buf206', c0, {c0: 512}, None)]
    buf206.unmet_dependencies = 
        [   MemoryDep('buf203', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf204', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf205', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf206.met_dependencies = []
    buf206.users = [NodeUser(node=SchedulerNode(name='buf210'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf371'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf206.group.device = cuda:0
    buf206.group.iteration = (512, 13)
    buf206.sizes = ([512], [13])
    buf204_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf205_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf203_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf206_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf206_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf203', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf204', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf205', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf206', get_index_3, getitem)
            return store_reduction
    buf206 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf206_buf207_buf209_buf371_buf372_buf374_buf375.snodes[1] =
    buf207: SchedulerNode(ComputedBuffer)
    buf207.writes = [MemoryDep('buf207', c0, {c0: 512}, None)]
    buf207.unmet_dependencies = 
        [   MemoryDep('buf203', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf204', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf205', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf207.met_dependencies = []
    buf207.users = [NodeUser(node=SchedulerNode(name='buf209'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf210'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf374'), can_inplace=True, is_weak=False)]
    buf207.group.device = cuda:0
    buf207.group.iteration = (512, 13)
    buf207.sizes = ([512], [13])
    buf204_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf205_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf203_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf207_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf207_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf203', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf204', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf205', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf207', get_index_3, getitem_1)
            return store_reduction
    buf207 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf206_buf207_buf209_buf371_buf372_buf374_buf375.snodes[2] =
    buf209: SchedulerNode(ComputedBuffer)
    buf209.writes = [MemoryDep('buf209', c0, {c0: 512}, None)]
    buf209.unmet_dependencies = [MemoryDep('buf207', c0, {c0: 512}, None)]
    buf209.met_dependencies = []
    buf209.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf209.group.device = cuda:0
    buf209.group.iteration = (512, 1)
    buf209.sizes = ([512], [])
    buf207_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf209_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf209_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf207', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf209', get_index_1, rsqrt, None)
            return store
    buf209 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf206_buf207_buf209_buf371_buf372_buf374_buf375.snodes[3] =
    buf371: SchedulerNode(ComputedBuffer)
    buf371.writes = [MemoryDep('buf371', c0, {c0: 512}, None)]
    buf371.unmet_dependencies = [MemoryDep('buf206', c0, {c0: 512}, None)]
    buf371.met_dependencies = [MemoryDep('primals_114', c0, {c0: 512}, None)]
    buf371.users = [NodeUser(node=SchedulerNode(name='buf372'), can_inplace=True, is_weak=False)]
    buf371.group.device = cuda:0
    buf371.group.iteration = (512, 1)
    buf371.sizes = ([512], [])
    buf206_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_114_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf371_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf371_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf206', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_114', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf371', get_index_2, add, None)
            return store
    buf371 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf206_buf207_buf209_buf371_buf372_buf374_buf375.snodes[4] =
    buf372: SchedulerNode(ComputedBuffer)
    buf372.writes = [MemoryDep('buf372', c0, {c0: 512}, None)]
    buf372.unmet_dependencies = [MemoryDep('buf371', c0, {c0: 512}, None)]
    buf372.met_dependencies = [StarDep(name='primals_114', mode=None)]
    buf372.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf372.group.device = cuda:0
    buf372.group.iteration = (512, 1)
    buf372.sizes = ([512], [])
    buf371_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    primals_114_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf372_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf372.mutations = ['primals_114']
    class buf372_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf371', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf372', get_index_1, load, None)
            return store
    buf372 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf206_buf207_buf209_buf371_buf372_buf374_buf375.snodes[5] =
    buf374: SchedulerNode(ComputedBuffer)
    buf374.writes = [MemoryDep('buf374', c0, {c0: 512}, None)]
    buf374.unmet_dependencies = [MemoryDep('buf207', c0, {c0: 512}, None)]
    buf374.met_dependencies = [MemoryDep('primals_115', c0, {c0: 512}, None)]
    buf374.users = [NodeUser(node=SchedulerNode(name='buf375'), can_inplace=True, is_weak=False)]
    buf374.group.device = cuda:0
    buf374.group.iteration = (512, 1)
    buf374.sizes = ([512], [])
    buf207_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_115_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf374_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf374_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf207', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0006381620931717, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_115', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf374', get_index_2, add, None)
            return store
    buf374 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0006381620931717
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf206_buf207_buf209_buf371_buf372_buf374_buf375.snodes[6] =
    buf375: SchedulerNode(ComputedBuffer)
    buf375.writes = [MemoryDep('buf375', c0, {c0: 512}, None)]
    buf375.unmet_dependencies = [MemoryDep('buf374', c0, {c0: 512}, None)]
    buf375.met_dependencies = [StarDep(name='primals_115', mode=None)]
    buf375.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf375.group.device = cuda:0
    buf375.group.iteration = (512, 1)
    buf375.sizes = ([512], [])
    primals_115_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf374_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf375_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf375.mutations = ['primals_115']
    class buf375_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf374', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf375', get_index_1, load, None)
            return store
    buf375 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf206_buf207_buf209_buf371_buf372_buf374_buf375 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 1568.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0006381620931717
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf210_buf211: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf210_buf211.writes = 
    [   MemoryDep('buf210', c0, {c0: 802816}, None),
        MemoryDep('buf211', c0, {c0: 802816}, None)]
buf210_buf211.unmet_dependencies = 
    [   MemoryDep('buf194', c0, {c0: 802816}, None),
        MemoryDep('buf198', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf199', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf202', c0, {c0: 802816}, None),
        MemoryDep('buf206', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf207', c1, {c0: 1568, c1: 512}, None)]
buf210_buf211.met_dependencies = 
    [   MemoryDep('primals_50', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('primals_51', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('primals_53', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('primals_54', c1, {c0: 1568, c1: 512}, None)]
buf210_buf211.users = []
    buf210_buf211.snodes[0] =
    buf210: SchedulerNode(ComputedBuffer)
    buf210.writes = [MemoryDep('buf210', c0, {c0: 802816}, None)]
    buf210.unmet_dependencies = 
        [   MemoryDep('buf194', c0, {c0: 802816}, None),
            MemoryDep('buf198', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('buf199', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('buf202', c0, {c0: 802816}, None),
            MemoryDep('buf206', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('buf207', c1, {c0: 1568, c1: 512}, None)]
    buf210.met_dependencies = 
        [   MemoryDep('primals_50', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('primals_51', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('primals_53', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('primals_54', c1, {c0: 1568, c1: 512}, None)]
    buf210.users = [NodeUser(node=SchedulerNode(name='buf211'), can_inplace=True, is_weak=False)]
    buf210.group.device = cuda:0
    buf210.group.iteration = (802816, 1)
    buf210.sizes = ([1568, 512], [])
    buf199_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_53_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    primals_50_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf202_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf194_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    primals_54_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf207_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_51_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf198_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf206_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf210_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    class buf210_loop_body:
        var_ranges = {z0: 1568, z1: 512}
        index0 = 512*z0 + z1
        index1 = z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf194', get_index)
            get_index_1 = self.get_index('index1')
            load_1 = ops.load('buf198', get_index_1)
            sub = ops.sub(load, load_1)
            get_index_2 = self.get_index('index1')
            load_2 = ops.load('buf199', get_index_2)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load_2, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            mul = ops.mul(sub, rsqrt)
            get_index_3 = self.get_index('index1')
            load_3 = ops.load('primals_50', get_index_3)
            mul_1 = ops.mul(mul, load_3)
            get_index_4 = self.get_index('index1')
            load_4 = ops.load('primals_51', get_index_4)
            add_1 = ops.add(mul_1, load_4)
            get_index_5 = self.get_index('index0')
            load_5 = ops.load('buf202', get_index_5)
            get_index_6 = self.get_index('index1')
            load_6 = ops.load('buf206', get_index_6)
            sub_1 = ops.sub(load_5, load_6)
            get_index_7 = self.get_index('index1')
            load_7 = ops.load('buf207', get_index_7)
            constant_2 = ops.constant(1568.0, torch.float32)
            truediv_1 = ops.truediv(load_7, constant_2)
            constant_3 = ops.constant(1e-05, torch.float32)
            add_2 = ops.add(truediv_1, constant_3)
            rsqrt_1 = ops.rsqrt(add_2)
            mul_2 = ops.mul(sub_1, rsqrt_1)
            get_index_8 = self.get_index('index1')
            load_8 = ops.load('primals_53', get_index_8)
            mul_3 = ops.mul(mul_2, load_8)
            get_index_9 = self.get_index('index1')
            load_9 = ops.load('primals_54', get_index_9)
            add_3 = ops.add(mul_3, load_9)
            add_4 = ops.add(add_1, add_3)
            get_index_10 = self.get_index('index0')
            store = ops.store('buf210', get_index_10, add_4, None)
            return store
    buf210 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1048576], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 10, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 802816
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 512
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
            tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
            tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
            tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
            tmp2 = tmp0 - tmp1
            tmp4 = 1568.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp16 = tmp14 - tmp15
            tmp18 = tmp17 / tmp4
            tmp19 = tmp18 + tmp6
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = tmp16 * tmp20
            tmp23 = tmp21 * tmp22
            tmp25 = tmp23 + tmp24
            tmp26 = tmp13 + tmp25
            tl.store(out_ptr0 + (x2), tmp26, None)
    buf210_buf211.snodes[1] =
    buf211: SchedulerNode(ComputedBuffer)
    buf211.writes = [MemoryDep('buf211', c0, {c0: 802816}, None)]
    buf211.unmet_dependencies = [MemoryDep('buf210', c0, {c0: 802816}, None)]
    buf211.met_dependencies = []
    buf211.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf212'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf229'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf211.group.device = cuda:0
    buf211.group.iteration = (802816, 1)
    buf211.sizes = ([802816], [])
    buf210_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf211_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    class buf211_loop_body:
        var_ranges = {z0: 802816}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf210', get_index)
            relu = ops.relu(load)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf211', get_index_1, relu, None)
            return store
    buf211 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1048576], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 802816
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_out_ptr0 + (x0), None)
            tmp1 = tl.full([1], 0, tl.int32)
            tmp2 = triton_helpers.maximum(tmp1, tmp0)
            tl.store(in_out_ptr0 + (x0), tmp2, None)
    buf210_buf211 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1048576], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 10, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
            xnumel = 802816
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 512
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
            tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
            tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
            tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
            tmp2 = tmp0 - tmp1
            tmp4 = 1568.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp16 = tmp14 - tmp15
            tmp18 = tmp17 / tmp4
            tmp19 = tmp18 + tmp6
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = tmp16 * tmp20
            tmp23 = tmp21 * tmp22
            tmp25 = tmp23 + tmp24
            tmp26 = tmp13 + tmp25
            tmp27 = tl.full([1], 0, tl.int32)
            tmp28 = triton_helpers.maximum(tmp27, tmp26)
            tl.store(in_out_ptr0 + (x2), tmp28, None)


buf212: ExternKernelSchedulerNode(ExternKernelAlloc)
buf212.writes = [StarDep(name='buf212', mode=None)]
buf212.unmet_dependencies = [StarDep(name='buf15', mode=None), StarDep(name='buf211', mode=None)]
buf212.met_dependencies = []
buf212.users = [NodeUser(node=SchedulerNode(name='buf213'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf214'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf215'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf220'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf212.node.kernel = extern_kernels.convolution


buf213_buf214_buf215: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf213_buf214_buf215.writes = 
    [   MemoryDep('buf213', c0, {c0: 6656}, None),
        MemoryDep('buf214', c0, {c0: 6656}, None),
        MemoryDep('buf215', c0, {c0: 6656}, None)]
buf213_buf214_buf215.unmet_dependencies = [   MemoryDep('buf212', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf213_buf214_buf215.met_dependencies = []
buf213_buf214_buf215.users = []
    buf213_buf214_buf215.snodes[0] =
    buf213: SchedulerNode(ComputedBuffer)
    buf213.writes = [MemoryDep('buf213', c0, {c0: 6656}, None)]
    buf213.unmet_dependencies = [   MemoryDep('buf212', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf213.met_dependencies = []
    buf213.users = [NodeUser(node=SchedulerNode(name='buf216'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf217'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf218'), can_inplace=False, is_weak=False)]
    buf213.group.device = cuda:0
    buf213.group.iteration = (6656, 121)
    buf213.sizes = ([13, 512], [121])
    buf212_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf213_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf213_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf213', get_index_3, getitem)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf212', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf213 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
    buf213_buf214_buf215.snodes[1] =
    buf214: SchedulerNode(ComputedBuffer)
    buf214.writes = [MemoryDep('buf214', c0, {c0: 6656}, None)]
    buf214.unmet_dependencies = [   MemoryDep('buf212', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf214.met_dependencies = []
    buf214.users = [NodeUser(node=SchedulerNode(name='buf216'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf217'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf218'), can_inplace=False, is_weak=False)]
    buf214.group.device = cuda:0
    buf214.group.iteration = (6656, 121)
    buf214.sizes = ([13, 512], [121])
    buf212_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf214_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf214_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf214', get_index_3, getitem_1)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf212', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf214 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp16, xmask)
    buf213_buf214_buf215.snodes[2] =
    buf215: SchedulerNode(ComputedBuffer)
    buf215.writes = [MemoryDep('buf215', c0, {c0: 6656}, None)]
    buf215.unmet_dependencies = [   MemoryDep('buf212', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf215.met_dependencies = []
    buf215.users = [NodeUser(node=SchedulerNode(name='buf216'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf217'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf218'), can_inplace=False, is_weak=False)]
    buf215.group.device = cuda:0
    buf215.group.iteration = (6656, 121)
    buf215.sizes = ([13, 512], [121])
    buf212_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf215_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf215_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf215', get_index_3, getitem_2)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf212', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf215 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp17, xmask)
    buf213_buf214_buf215 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
            tl.store(out_ptr1 + (x3), tmp16, xmask)
            tl.store(out_ptr2 + (x3), tmp17, xmask)


buf216_buf217_buf219_buf379_buf380_buf382_buf383: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf216_buf217_buf219_buf379_buf380_buf382_buf383.writes = 
    [   MemoryDep('buf216', c0, {c0: 512}, None),
        MemoryDep('buf217', c0, {c0: 512}, None),
        MemoryDep('buf219', c0, {c0: 512}, None),
        MemoryDep('buf379', c0, {c0: 512}, None),
        MemoryDep('buf380', c0, {c0: 512}, None),
        MemoryDep('buf382', c0, {c0: 512}, None),
        MemoryDep('buf383', c0, {c0: 512}, None)]
buf216_buf217_buf219_buf379_buf380_buf382_buf383.unmet_dependencies = 
    [   MemoryDep('buf213', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf214', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf215', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf216_buf217_buf219_buf379_buf380_buf382_buf383.met_dependencies = 
    [   MemoryDep('primals_117', c0, {c0: 512}, None),
        MemoryDep('primals_118', c0, {c0: 512}, None),
        StarDep(name='primals_117', mode=None),
        StarDep(name='primals_118', mode=None)]
buf216_buf217_buf219_buf379_buf380_buf382_buf383.users = []
    buf216_buf217_buf219_buf379_buf380_buf382_buf383.snodes[0] =
    buf216: SchedulerNode(ComputedBuffer)
    buf216.writes = [MemoryDep('buf216', c0, {c0: 512}, None)]
    buf216.unmet_dependencies = 
        [   MemoryDep('buf213', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf214', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf215', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf216.met_dependencies = []
    buf216.users = [NodeUser(node=SchedulerNode(name='buf220'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf379'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf216.group.device = cuda:0
    buf216.group.iteration = (512, 13)
    buf216.sizes = ([512], [13])
    buf215_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf214_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf213_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf216_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf216_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf213', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf214', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf215', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf216', get_index_3, getitem)
            return store_reduction
    buf216 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf216_buf217_buf219_buf379_buf380_buf382_buf383.snodes[1] =
    buf217: SchedulerNode(ComputedBuffer)
    buf217.writes = [MemoryDep('buf217', c0, {c0: 512}, None)]
    buf217.unmet_dependencies = 
        [   MemoryDep('buf213', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf214', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf215', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf217.met_dependencies = []
    buf217.users = [NodeUser(node=SchedulerNode(name='buf219'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf220'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf382'), can_inplace=True, is_weak=False)]
    buf217.group.device = cuda:0
    buf217.group.iteration = (512, 13)
    buf217.sizes = ([512], [13])
    buf215_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf214_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf213_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf217_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf217_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf213', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf214', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf215', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf217', get_index_3, getitem_1)
            return store_reduction
    buf217 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf216_buf217_buf219_buf379_buf380_buf382_buf383.snodes[2] =
    buf219: SchedulerNode(ComputedBuffer)
    buf219.writes = [MemoryDep('buf219', c0, {c0: 512}, None)]
    buf219.unmet_dependencies = [MemoryDep('buf217', c0, {c0: 512}, None)]
    buf219.met_dependencies = []
    buf219.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf219.group.device = cuda:0
    buf219.group.iteration = (512, 1)
    buf219.sizes = ([512], [])
    buf217_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf219_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf219_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf217', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf219', get_index_1, rsqrt, None)
            return store
    buf219 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf216_buf217_buf219_buf379_buf380_buf382_buf383.snodes[3] =
    buf379: SchedulerNode(ComputedBuffer)
    buf379.writes = [MemoryDep('buf379', c0, {c0: 512}, None)]
    buf379.unmet_dependencies = [MemoryDep('buf216', c0, {c0: 512}, None)]
    buf379.met_dependencies = [MemoryDep('primals_117', c0, {c0: 512}, None)]
    buf379.users = [NodeUser(node=SchedulerNode(name='buf380'), can_inplace=True, is_weak=False)]
    buf379.group.device = cuda:0
    buf379.group.iteration = (512, 1)
    buf379.sizes = ([512], [])
    primals_117_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf216_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf379_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf379_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf216', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_117', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf379', get_index_2, add, None)
            return store
    buf379 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf216_buf217_buf219_buf379_buf380_buf382_buf383.snodes[4] =
    buf380: SchedulerNode(ComputedBuffer)
    buf380.writes = [MemoryDep('buf380', c0, {c0: 512}, None)]
    buf380.unmet_dependencies = [MemoryDep('buf379', c0, {c0: 512}, None)]
    buf380.met_dependencies = [StarDep(name='primals_117', mode=None)]
    buf380.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf380.group.device = cuda:0
    buf380.group.iteration = (512, 1)
    buf380.sizes = ([512], [])
    primals_117_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf379_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf380_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf380.mutations = ['primals_117']
    class buf380_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf379', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf380', get_index_1, load, None)
            return store
    buf380 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf216_buf217_buf219_buf379_buf380_buf382_buf383.snodes[5] =
    buf382: SchedulerNode(ComputedBuffer)
    buf382.writes = [MemoryDep('buf382', c0, {c0: 512}, None)]
    buf382.unmet_dependencies = [MemoryDep('buf217', c0, {c0: 512}, None)]
    buf382.met_dependencies = [MemoryDep('primals_118', c0, {c0: 512}, None)]
    buf382.users = [NodeUser(node=SchedulerNode(name='buf383'), can_inplace=True, is_weak=False)]
    buf382.group.device = cuda:0
    buf382.group.iteration = (512, 1)
    buf382.sizes = ([512], [])
    buf217_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_118_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf382_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf382_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf217', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0006381620931717, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_118', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf382', get_index_2, add, None)
            return store
    buf382 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0006381620931717
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf216_buf217_buf219_buf379_buf380_buf382_buf383.snodes[6] =
    buf383: SchedulerNode(ComputedBuffer)
    buf383.writes = [MemoryDep('buf383', c0, {c0: 512}, None)]
    buf383.unmet_dependencies = [MemoryDep('buf382', c0, {c0: 512}, None)]
    buf383.met_dependencies = [StarDep(name='primals_118', mode=None)]
    buf383.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf383.group.device = cuda:0
    buf383.group.iteration = (512, 1)
    buf383.sizes = ([512], [])
    primals_118_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf382_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf383_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf383.mutations = ['primals_118']
    class buf383_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf382', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf383', get_index_1, load, None)
            return store
    buf383 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf216_buf217_buf219_buf379_buf380_buf382_buf383 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 1568.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0006381620931717
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf220: SchedulerNode(ComputedBuffer)
buf220.writes = [MemoryDep('buf220', c0, {c0: 802816}, None)]
buf220.unmet_dependencies = 
    [   MemoryDep('buf212', c0, {c0: 802816}, None),
        MemoryDep('buf216', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf217', c1, {c0: 1568, c1: 512}, None)]
buf220.met_dependencies = 
    [   MemoryDep('primals_56', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('primals_57', c1, {c0: 1568, c1: 512}, None)]
buf220.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf221'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf220.group.device = cuda:0
buf220.group.iteration = (802816, 1)
buf220.sizes = ([1568, 512], [])
primals_57_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf212_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
primals_56_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf216_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
buf217_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
buf220_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
class buf220_loop_body:
    var_ranges = {z0: 1568, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf212', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf216', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf217', get_index_2)
        constant = ops.constant(1568.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('primals_56', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('primals_57', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf220', get_index_5, relu, None)
        return store
buf220 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1048576], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 802816
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x2 = xindex
        x0 = xindex % 512
        tmp0 = tl.load(in_ptr0 + (x2), None)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
        tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
        tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
        tmp2 = tmp0 - tmp1
        tmp4 = 1568.0
        tmp5 = tmp3 / tmp4
        tmp6 = 1e-05
        tmp7 = tmp5 + tmp6
        tmp8 = libdevice.rsqrt(tmp7)
        tmp9 = tmp2 * tmp8
        tmp11 = tmp9 * tmp10
        tmp13 = tmp11 + tmp12
        tmp14 = tl.full([1], 0, tl.int32)
        tmp15 = triton_helpers.maximum(tmp14, tmp13)
        tl.store(out_ptr0 + (x2), tmp15, None)


buf221: ExternKernelSchedulerNode(ExternKernelAlloc)
buf221.writes = [StarDep(name='buf221', mode=None)]
buf221.unmet_dependencies = [StarDep(name='buf16', mode=None), StarDep(name='buf220', mode=None)]
buf221.met_dependencies = []
buf221.users = [NodeUser(node=SchedulerNode(name='buf222'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf223'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf224'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf229'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf221.node.kernel = extern_kernels.convolution


buf222_buf223_buf224: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
buf222_buf223_buf224.writes = 
    [   MemoryDep('buf222', c0, {c0: 6656}, None),
        MemoryDep('buf223', c0, {c0: 6656}, None),
        MemoryDep('buf224', c0, {c0: 6656}, None)]
buf222_buf223_buf224.unmet_dependencies = [   MemoryDep('buf221', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
buf222_buf223_buf224.met_dependencies = []
buf222_buf223_buf224.users = []
    buf222_buf223_buf224.snodes[0] =
    buf222: SchedulerNode(ComputedBuffer)
    buf222.writes = [MemoryDep('buf222', c0, {c0: 6656}, None)]
    buf222.unmet_dependencies = [   MemoryDep('buf221', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf222.met_dependencies = []
    buf222.users = [NodeUser(node=SchedulerNode(name='buf225'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf226'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf227'), can_inplace=False, is_weak=False)]
    buf222.group.device = cuda:0
    buf222.group.iteration = (6656, 121)
    buf222.sizes = ([13, 512], [121])
    buf221_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf222_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf222_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf222', get_index_3, getitem)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf221', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf222 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
    buf222_buf223_buf224.snodes[1] =
    buf223: SchedulerNode(ComputedBuffer)
    buf223.writes = [MemoryDep('buf223', c0, {c0: 6656}, None)]
    buf223.unmet_dependencies = [   MemoryDep('buf221', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf223.met_dependencies = []
    buf223.users = [NodeUser(node=SchedulerNode(name='buf225'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf226'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf227'), can_inplace=False, is_weak=False)]
    buf223.group.device = cuda:0
    buf223.group.iteration = (6656, 121)
    buf223.sizes = ([13, 512], [121])
    buf221_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf223_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf223_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf223', get_index_3, getitem_1)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf221', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf223 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp16, xmask)
    buf222_buf223_buf224.snodes[2] =
    buf224: SchedulerNode(ComputedBuffer)
    buf224.writes = [MemoryDep('buf224', c0, {c0: 6656}, None)]
    buf224.unmet_dependencies = [   MemoryDep('buf221', c1 + 512*ModularIndexing(121*c0 + c2, 1, 1568), {c0: 13, c1: 512, c2: 121}, None)]
    buf224.met_dependencies = []
    buf224.users = [NodeUser(node=SchedulerNode(name='buf225'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf226'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf227'), can_inplace=False, is_weak=False)]
    buf224.group.device = cuda:0
    buf224.group.iteration = (6656, 121)
    buf224.sizes = ([13, 512], [121])
    buf221_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf224_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    class buf224_loop_body:
        var_ranges = {z0: 13, z1: 512, z2: 121}
        index0 = 121*z0 + z2
        index1 = z1 + 512*ModularIndexing(121*z0 + z2, 1, 1568)
        index2 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            index_expr = ops.index_expr(get_index, torch.int32)
            constant = ops.constant(1568, torch.int32)
            lt = ops.lt(index_expr, constant)
            masked_subblock1 = self.masked_subblock1(lt, 0)
            get_index_1 = self.get_index('index0')
            index_expr_1 = ops.index_expr(get_index_1, torch.int32)
            constant_1 = ops.constant(1568, torch.int32)
            lt_1 = ops.lt(index_expr_1, constant_1)
            masked_subblock2 = self.masked_subblock2(lt_1, 0)
            get_index_2 = self.get_index('index0')
            index_expr_2 = ops.index_expr(get_index_2, torch.int32)
            constant_2 = ops.constant(1568, torch.int32)
            lt_2 = ops.lt(index_expr_2, constant_2)
            masked_subblock3 = self.masked_subblock3(lt_2, 0)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (masked_subblock1, masked_subblock2, masked_subblock3))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index2')
            store_reduction = ops.store_reduction('buf224', get_index_3, getitem_2)
            return store_reduction
        def masked_subblock1(self, ops):
            get_index = self.get_index('index1')
            load = ops.load('buf221', get_index)
            return load
        def masked_subblock2(self, ops):
            constant = ops.constant(0.0, torch.float32)
            return constant
        def masked_subblock3(self, ops):
            constant = ops.constant(1.0, torch.float32)
            return constant
    buf224 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp17, xmask)
    buf222_buf223_buf224 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.reduction(
            size_hints=[8192, 128],
            reduction_hint=ReductionHint.OUTER,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
            xnumel = 6656
            rnumel = 121
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rbase = tl.arange(0, RBLOCK)[None, :]
            x1 = (xindex // 512)
            x0 = xindex % 512
            tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
            x3 = xindex
            for roffset in range(0, rnumel, RBLOCK):
                rindex = roffset + rbase
                rmask = rindex < rnumel
                r2 = rindex
                tmp0 = r2 + (121*x1)
                tmp1 = tl.full([1, 1], 1568, tl.int32)
                tmp2 = tmp0 < tmp1
                tmp3 = tl.load(in_ptr0 + (x0 + (512*((r2 + (121*x1)) % 1568))), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
                tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
                tmp5 = tl.where(tmp2, tmp3, tmp4)
                tmp6 = 0.0
                tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
                tmp8 = tl.where(tmp2, tmp6, tmp7)
                tmp9 = 1.0
                tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
                tmp11 = tl.where(tmp2, tmp9, tmp10)
                tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
                tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
                tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
                tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
                    tmp15_mean, tmp15_m2, tmp15_weight,
                    tmp12, tmp13, tmp14
                )
                tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
                tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
                tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
            tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
                tmp15_mean, tmp15_m2, tmp15_weight, 1
            )
            tmp15 = tmp15_tmp[:, None]
            tmp16 = tmp16_tmp[:, None]
            tmp17 = tmp17_tmp[:, None]
            tl.store(out_ptr0 + (x3), tmp15, xmask)
            tl.store(out_ptr1 + (x3), tmp16, xmask)
            tl.store(out_ptr2 + (x3), tmp17, xmask)


buf225_buf226_buf228_buf387_buf388_buf390_buf391: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
buf225_buf226_buf228_buf387_buf388_buf390_buf391.writes = 
    [   MemoryDep('buf225', c0, {c0: 512}, None),
        MemoryDep('buf226', c0, {c0: 512}, None),
        MemoryDep('buf228', c0, {c0: 512}, None),
        MemoryDep('buf387', c0, {c0: 512}, None),
        MemoryDep('buf388', c0, {c0: 512}, None),
        MemoryDep('buf390', c0, {c0: 512}, None),
        MemoryDep('buf391', c0, {c0: 512}, None)]
buf225_buf226_buf228_buf387_buf388_buf390_buf391.unmet_dependencies = 
    [   MemoryDep('buf222', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf223', c0 + 512*c1, {c0: 512, c1: 13}, None),
        MemoryDep('buf224', c0 + 512*c1, {c0: 512, c1: 13}, None)]
buf225_buf226_buf228_buf387_buf388_buf390_buf391.met_dependencies = 
    [   MemoryDep('primals_120', c0, {c0: 512}, None),
        MemoryDep('primals_121', c0, {c0: 512}, None),
        StarDep(name='primals_120', mode=None),
        StarDep(name='primals_121', mode=None)]
buf225_buf226_buf228_buf387_buf388_buf390_buf391.users = []
    buf225_buf226_buf228_buf387_buf388_buf390_buf391.snodes[0] =
    buf225: SchedulerNode(ComputedBuffer)
    buf225.writes = [MemoryDep('buf225', c0, {c0: 512}, None)]
    buf225.unmet_dependencies = 
        [   MemoryDep('buf222', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf223', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf224', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf225.met_dependencies = []
    buf225.users = [NodeUser(node=SchedulerNode(name='buf229'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf387'), can_inplace=True, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf225.group.device = cuda:0
    buf225.group.iteration = (512, 13)
    buf225.sizes = ([512], [13])
    buf223_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf224_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf222_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf225_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf225_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf222', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf223', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf224', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf225', get_index_3, getitem)
            return store_reduction
    buf225 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp13, xmask)
    buf225_buf226_buf228_buf387_buf388_buf390_buf391.snodes[1] =
    buf226: SchedulerNode(ComputedBuffer)
    buf226.writes = [MemoryDep('buf226', c0, {c0: 512}, None)]
    buf226.unmet_dependencies = 
        [   MemoryDep('buf222', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf223', c0 + 512*c1, {c0: 512, c1: 13}, None),
            MemoryDep('buf224', c0 + 512*c1, {c0: 512, c1: 13}, None)]
    buf226.met_dependencies = []
    buf226.users = [NodeUser(node=SchedulerNode(name='buf228'), can_inplace=True, is_weak=False), NodeUser(node=SchedulerNode(name='buf229'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf390'), can_inplace=True, is_weak=False)]
    buf226.group.device = cuda:0
    buf226.group.iteration = (512, 13)
    buf226.sizes = ([512], [13])
    buf223_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf224_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf222_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1, 13], stride=[6656, 1, 6656, 6656, 512])
    buf226_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf226_loop_body:
        var_ranges = {z0: 512, z1: 13}
        index0 = z0 + 512*z1
        index1 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf222', get_index)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('buf223', get_index_1)
            get_index_2 = self.get_index('index0')
            load_2 = ops.load('buf224', get_index_2)
            reduction = ops.reduction(torch.float32, torch.float32, 'welford_combine', (load, load_1, load_2))
            getitem = reduction[0]
            getitem_1 = reduction[1]
            getitem_2 = reduction[2]
            get_index_3 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf226', get_index_3, getitem_1)
            return store_reduction
    buf226 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tl.store(out_ptr0 + (x0), tmp14, xmask)
    buf225_buf226_buf228_buf387_buf388_buf390_buf391.snodes[2] =
    buf228: SchedulerNode(ComputedBuffer)
    buf228.writes = [MemoryDep('buf228', c0, {c0: 512}, None)]
    buf228.unmet_dependencies = [MemoryDep('buf226', c0, {c0: 512}, None)]
    buf228.met_dependencies = []
    buf228.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf228.group.device = cuda:0
    buf228.group.iteration = (512, 1)
    buf228.sizes = ([512], [])
    buf226_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf228_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    class buf228_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf226', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf228', get_index_1, rsqrt, None)
            return store
    buf228 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1e-05
            tmp4 = tmp2 + tmp3
            tmp5 = libdevice.rsqrt(tmp4)
            tl.store(out_ptr0 + (x0), tmp5, xmask)
    buf225_buf226_buf228_buf387_buf388_buf390_buf391.snodes[3] =
    buf387: SchedulerNode(ComputedBuffer)
    buf387.writes = [MemoryDep('buf387', c0, {c0: 512}, None)]
    buf387.unmet_dependencies = [MemoryDep('buf225', c0, {c0: 512}, None)]
    buf387.met_dependencies = [MemoryDep('primals_120', c0, {c0: 512}, None)]
    buf387.users = [NodeUser(node=SchedulerNode(name='buf388'), can_inplace=True, is_weak=False)]
    buf387.group.device = cuda:0
    buf387.group.iteration = (512, 1)
    buf387.sizes = ([512], [])
    primals_120_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf225_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf387_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf387_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf225', get_index)
            constant = ops.constant(0.1, torch.float32)
            mul = ops.mul(load, constant)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_120', get_index_1)
            constant_1 = ops.constant(0.9, torch.float32)
            mul_1 = ops.mul(load_1, constant_1)
            add = ops.add(mul, mul_1)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf387', get_index_2, add, None)
            return store
    buf387 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp3 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 0.1
            tmp2 = tmp0 * tmp1
            tmp4 = 0.9
            tmp5 = tmp3 * tmp4
            tmp6 = tmp2 + tmp5
            tl.store(out_ptr0 + (x0), tmp6, xmask)
    buf225_buf226_buf228_buf387_buf388_buf390_buf391.snodes[4] =
    buf388: SchedulerNode(ComputedBuffer)
    buf388.writes = [MemoryDep('buf388', c0, {c0: 512}, None)]
    buf388.unmet_dependencies = [MemoryDep('buf387', c0, {c0: 512}, None)]
    buf388.met_dependencies = [StarDep(name='primals_120', mode=None)]
    buf388.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf388.group.device = cuda:0
    buf388.group.iteration = (512, 1)
    buf388.sizes = ([512], [])
    primals_120_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf387_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf388_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf388.mutations = ['primals_120']
    class buf388_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf387', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf388', get_index_1, load, None)
            return store
    buf388 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf225_buf226_buf228_buf387_buf388_buf390_buf391.snodes[5] =
    buf390: SchedulerNode(ComputedBuffer)
    buf390.writes = [MemoryDep('buf390', c0, {c0: 512}, None)]
    buf390.unmet_dependencies = [MemoryDep('buf226', c0, {c0: 512}, None)]
    buf390.met_dependencies = [MemoryDep('primals_121', c0, {c0: 512}, None)]
    buf390.users = [NodeUser(node=SchedulerNode(name='buf391'), can_inplace=True, is_weak=False)]
    buf390.group.device = cuda:0
    buf390.group.iteration = (512, 1)
    buf390.sizes = ([512], [])
    buf226_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    primals_121_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf390_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    class buf390_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf226', get_index)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load, constant)
            constant_1 = ops.constant(1.0006381620931717, torch.float32)
            mul = ops.mul(truediv, constant_1)
            constant_2 = ops.constant(0.1, torch.float32)
            mul_1 = ops.mul(mul, constant_2)
            get_index_1 = self.get_index('index0')
            load_1 = ops.load('primals_121', get_index_1)
            constant_3 = ops.constant(0.9, torch.float32)
            mul_2 = ops.mul(load_1, constant_3)
            add = ops.add(mul_1, mul_2)
            get_index_2 = self.get_index('index0')
            store = ops.store('buf390', get_index_2, add, None)
            return store
    buf390 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tmp7 = tl.load(in_ptr1 + (x0), xmask)
            tmp1 = 1568.0
            tmp2 = tmp0 / tmp1
            tmp3 = 1.0006381620931717
            tmp4 = tmp2 * tmp3
            tmp5 = 0.1
            tmp6 = tmp4 * tmp5
            tmp8 = 0.9
            tmp9 = tmp7 * tmp8
            tmp10 = tmp6 + tmp9
            tl.store(out_ptr0 + (x0), tmp10, xmask)
    buf225_buf226_buf228_buf387_buf388_buf390_buf391.snodes[6] =
    buf391: SchedulerNode(ComputedBuffer)
    buf391.writes = [MemoryDep('buf391', c0, {c0: 512}, None)]
    buf391.unmet_dependencies = [MemoryDep('buf390', c0, {c0: 512}, None)]
    buf391.met_dependencies = [StarDep(name='primals_121', mode=None)]
    buf391.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf391.group.device = cuda:0
    buf391.group.iteration = (512, 1)
    buf391.sizes = ([512], [])
    primals_121_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf390_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf391_layout = MutationLayoutSHOULDREMOVE('cuda', torch.float32, size=[512], stride=[1])
    buf391.mutations = ['primals_121']
    class buf391_loop_body:
        var_ranges = {z0: 512}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf390', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf391', get_index_1, load, None)
            return store
    buf391 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[512], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), xmask)
            tl.store(out_ptr0 + (x0), tmp0, xmask)
    buf225_buf226_buf228_buf387_buf388_buf390_buf391 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[512, 16],
            reduction_hint=ReductionHint.OUTER_TINY,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 512
            rnumel = 13
            RBLOCK: tl.constexpr = 16
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r1 = rindex
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0.0)
            tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
            tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
            tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
            tmp7 = tl.where(rmask & xmask, tmp3, 0)
            tmp8 = tl.where(rmask & xmask, tmp4, 0)
            tmp9 = tl.where(rmask & xmask, tmp5, 0)
            tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
            tmp13 = tmp10[:, None]
            tmp14 = tmp11[:, None]
            tmp15 = tmp12[:, None]
            tmp16 = 1568.0
            tmp17 = tmp14 / tmp16
            tmp18 = 1e-05
            tmp19 = tmp17 + tmp18
            tmp20 = libdevice.rsqrt(tmp19)
            tmp21 = 0.1
            tmp22 = tmp13 * tmp21
            tmp24 = 0.9
            tmp25 = tmp23 * tmp24
            tmp26 = tmp22 + tmp25
            tmp27 = 1.0006381620931717
            tmp28 = tmp17 * tmp27
            tmp29 = tmp28 * tmp21
            tmp31 = tmp30 * tmp24
            tmp32 = tmp29 + tmp31
            tl.store(out_ptr2 + (x0), tmp20, xmask)
            tl.store(out_ptr4 + (x0), tmp26, xmask)
            tl.store(out_ptr6 + (x0), tmp32, xmask)
            tl.store(out_ptr0 + (x0), tmp13, xmask)
            tl.store(out_ptr1 + (x0), tmp14, xmask)


buf229_buf233: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf229_buf233.writes = 
    [   MemoryDep('buf229', c0, {c0: 802816}, None),
        MemoryDep('buf233', c0, {c0: 802816}, None)]
buf229_buf233.unmet_dependencies = 
    [   MemoryDep('buf211', c0, {c0: 802816}, None),
        MemoryDep('buf221', c0, {c0: 802816}, None),
        MemoryDep('buf225', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('buf226', c1, {c0: 1568, c1: 512}, None)]
buf229_buf233.met_dependencies = 
    [   MemoryDep('primals_59', c1, {c0: 1568, c1: 512}, None),
        MemoryDep('primals_60', c1, {c0: 1568, c1: 512}, None)]
buf229_buf233.users = []
    buf229_buf233.snodes[0] =
    buf229: SchedulerNode(ComputedBuffer)
    buf229.writes = [MemoryDep('buf229', c0, {c0: 802816}, None)]
    buf229.unmet_dependencies = 
        [   MemoryDep('buf211', c0, {c0: 802816}, None),
            MemoryDep('buf221', c0, {c0: 802816}, None),
            MemoryDep('buf225', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('buf226', c1, {c0: 1568, c1: 512}, None)]
    buf229.met_dependencies = 
        [   MemoryDep('primals_59', c1, {c0: 1568, c1: 512}, None),
            MemoryDep('primals_60', c1, {c0: 1568, c1: 512}, None)]
    buf229.users = [NodeUser(node=SchedulerNode(name='buf230'), can_inplace=False, is_weak=False), NodeUser(node=SchedulerNode(name='buf233'), can_inplace=True, is_weak=False)]
    buf229.group.device = cuda:0
    buf229.group.iteration = (802816, 1)
    buf229.sizes = ([1568, 512], [])
    primals_59_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf211_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf226_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf221_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    primals_60_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
    buf225_layout = FixedLayout('cuda', torch.float32, size=[1, 512, 1, 1], stride=[512, 1, 512, 512])
    buf229_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    class buf229_loop_body:
        var_ranges = {z0: 1568, z1: 512}
        index0 = 512*z0 + z1
        index1 = z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf221', get_index)
            get_index_1 = self.get_index('index1')
            load_1 = ops.load('buf225', get_index_1)
            sub = ops.sub(load, load_1)
            get_index_2 = self.get_index('index1')
            load_2 = ops.load('buf226', get_index_2)
            constant = ops.constant(1568.0, torch.float32)
            truediv = ops.truediv(load_2, constant)
            constant_1 = ops.constant(1e-05, torch.float32)
            add = ops.add(truediv, constant_1)
            rsqrt = ops.rsqrt(add)
            mul = ops.mul(sub, rsqrt)
            get_index_3 = self.get_index('index1')
            load_3 = ops.load('primals_59', get_index_3)
            mul_1 = ops.mul(mul, load_3)
            get_index_4 = self.get_index('index1')
            load_4 = ops.load('primals_60', get_index_4)
            add_1 = ops.add(mul_1, load_4)
            get_index_5 = self.get_index('index0')
            load_5 = ops.load('buf211', get_index_5)
            add_2 = ops.add(add_1, load_5)
            relu = ops.relu(add_2)
            get_index_6 = self.get_index('index0')
            store = ops.store('buf229', get_index_6, relu, None)
            return store
    buf229 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1048576], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 802816
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 512
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp2 = tmp0 - tmp1
            tmp4 = 1568.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp15 = tmp13 + tmp14
            tmp16 = tl.full([1], 0, tl.int32)
            tmp17 = triton_helpers.maximum(tmp16, tmp15)
            tl.store(out_ptr0 + (x2), tmp17, None)
    buf229_buf233.snodes[1] =
    buf233: SchedulerNode(ComputedBuffer)
    buf233.writes = [MemoryDep('buf233', c0, {c0: 802816}, None)]
    buf233.unmet_dependencies = [MemoryDep('buf229', c0, {c0: 802816}, None)]
    buf233.met_dependencies = []
    buf233.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf233.group.device = cuda:0
    buf233.group.iteration = (802816, 1)
    buf233.sizes = ([802816], [])
    buf229_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf233_layout = FixedLayout('cuda', torch.bool, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    class buf233_loop_body:
        var_ranges = {z0: 802816}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf229', get_index)
            constant = ops.constant(0.0, torch.float32)
            le = ops.le(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf233', get_index_1, le, None)
            return store
    buf233 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1048576], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*i1', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 802816
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_ptr0 + (x0), None)
            tmp1 = 0.0
            tmp2 = tmp0 <= tmp1
            tl.store(out_ptr0 + (x0), tmp2, None)
    buf229_buf233 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1048576], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i1', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 802816
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x2 = xindex
            x0 = xindex % 512
            tmp0 = tl.load(in_ptr0 + (x2), None)
            tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
            tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
            tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
            tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
            tmp14 = tl.load(in_ptr5 + (x2), None)
            tmp2 = tmp0 - tmp1
            tmp4 = 1568.0
            tmp5 = tmp3 / tmp4
            tmp6 = 1e-05
            tmp7 = tmp5 + tmp6
            tmp8 = libdevice.rsqrt(tmp7)
            tmp9 = tmp2 * tmp8
            tmp11 = tmp9 * tmp10
            tmp13 = tmp11 + tmp12
            tmp15 = tmp13 + tmp14
            tmp16 = tl.full([1], 0, tl.int32)
            tmp17 = triton_helpers.maximum(tmp16, tmp15)
            tmp18 = 0.0
            tmp19 = tmp17 <= tmp18
            tl.store(out_ptr0 + (x2), tmp17, None)
            tl.store(out_ptr1 + (x2), tmp19, None)


buf230_buf231: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf230_buf231.writes = 
    [   MemoryDep('buf230', c0, {c0: 16384}, None),
        MemoryDep('buf231', c0, {c0: 16384}, None)]
buf230_buf231.unmet_dependencies = [MemoryDep('buf229', 25088*c0 + c1 + 512*c2, {c0: 32, c1: 512, c2: 49}, None)]
buf230_buf231.met_dependencies = []
buf230_buf231.users = []
    buf230_buf231.snodes[0] =
    buf230: SchedulerNode(ComputedBuffer)
    buf230.writes = [MemoryDep('buf230', c0, {c0: 16384}, None)]
    buf230.unmet_dependencies = [MemoryDep('buf229', 25088*c0 + c1 + 512*c2, {c0: 32, c1: 512, c2: 49}, None)]
    buf230.met_dependencies = []
    buf230.users = [NodeUser(node=SchedulerNode(name='buf231'), can_inplace=True, is_weak=False)]
    buf230.group.device = cuda:0
    buf230.group.iteration = (16384, 49)
    buf230.sizes = ([32, 512], [49])
    buf229_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 7, 7], stride=[25088, 1, 3584, 512])
    buf230_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 1, 1], stride=[512, 1, 16384, 16384])
    class buf230_loop_body:
        var_ranges = {z0: 32, z1: 512, z2: 49}
        index0 = 25088*z0 + z1 + 512*z2
        index1 = 512*z0 + z1
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf229', get_index)
            reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
            get_index_1 = self.get_index('index1')
            store_reduction = ops.store_reduction('buf230', get_index_1, reduction)
            return store_reduction
    buf230 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[16384, 64],
            reduction_hint=ReductionHint.DEFAULT,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 16384
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r2 = rindex
            x0 = xindex % 512
            x1 = (xindex // 512)
            x3 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r2) + (25088*x1)), rmask, other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = tl.where(rmask, tmp1, 0)
            tmp4 = tl.sum(tmp3, 1)[:, None]
            tl.store(out_ptr0 + (x3), tmp4, None)
    buf230_buf231.snodes[1] =
    buf231: SchedulerNode(ComputedBuffer)
    buf231.writes = [MemoryDep('buf231', c0, {c0: 16384}, None)]
    buf231.unmet_dependencies = [MemoryDep('buf230', c0, {c0: 16384}, None)]
    buf231.met_dependencies = []
    buf231.users = [NodeUser(node=ExternKernelSchedulerNode(name='buf232'), can_inplace=False, is_weak=False), NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf231.group.device = cuda:0
    buf231.group.iteration = (16384, 1)
    buf231.sizes = ([16384], [])
    buf230_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 1, 1], stride=[512, 1, 16384, 16384])
    buf231_layout = FixedLayout('cuda', torch.float32, size=[32, 512, 1, 1], stride=[512, 1, 16384, 16384])
    class buf231_loop_body:
        var_ranges = {z0: 16384}
        index0 = z0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf230', get_index)
            constant = ops.constant(49.0, torch.float32)
            truediv = ops.truediv(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf231', get_index_1, truediv, None)
            return store
    buf231 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[16384], 
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 16384
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            x0 = xindex
            tmp0 = tl.load(in_out_ptr0 + (x0), None)
            tmp1 = 49.0
            tmp2 = tmp0 / tmp1
            tl.store(in_out_ptr0 + (x0), tmp2, None)
    buf230_buf231 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.persistent_reduction(
            size_hints=[16384, 64],
            reduction_hint=ReductionHint.DEFAULT,
            filename=__file__,
            triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
        )
        @triton.jit
        def triton_(in_out_ptr0, in_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
            xnumel = 16384
            rnumel = 49
            RBLOCK: tl.constexpr = 64
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
            xmask = xindex < xnumel
            rindex = tl.arange(0, RBLOCK)[None, :]
            roffset = 0
            rmask = rindex < rnumel
            r2 = rindex
            x0 = xindex % 512
            x1 = (xindex // 512)
            x3 = xindex
            tmp0 = tl.load(in_ptr0 + (x0 + (512*r2) + (25088*x1)), rmask, other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = tl.where(rmask, tmp1, 0)
            tmp4 = tl.sum(tmp3, 1)[:, None]
            tmp5 = 49.0
            tmp6 = tmp4 / tmp5
            tl.debug_barrier()
            tl.store(in_out_ptr0 + (x3), tmp6, None)


buf232: ExternKernelSchedulerNode(ExternKernelOut)
buf232.writes = [StarDep(name='buf232', mode=None)]
buf232.unmet_dependencies = [StarDep(name='buf231', mode=None)]
buf232.met_dependencies = [StarDep(name='primals_61', mode=None), StarDep(name='primals_62', mode=None)]
buf232.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf232.node.kernel = extern_kernels.addmm


buf240_buf241: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf240_buf241.writes = [MemoryDep('buf240', 0, {}, None), MemoryDep('buf241', 0, {}, None)]
buf240_buf241.unmet_dependencies = []
buf240_buf241.met_dependencies = [MemoryDep('primals_65', 0, {}, None), StarDep(name='primals_65', mode=None)]
buf240_buf241.users = []
    buf240_buf241.snodes[0] =
    buf240: SchedulerNode(ComputedBuffer)
    buf240.writes = [MemoryDep('buf240', 0, {}, None)]
    buf240.unmet_dependencies = []
    buf240.met_dependencies = [MemoryDep('primals_65', 0, {}, None)]
    buf240.users = [NodeUser(node=SchedulerNode(name='buf241'), can_inplace=True, is_weak=False)]
    buf240.group.device = cuda:0
    buf240.group.iteration = (1, 1)
    buf240.sizes = ([], [])
    primals_65_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf240_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf240_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_65', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf240', get_index_1, add, None)
            return store
    buf240 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf240_buf241.snodes[1] =
    buf241: SchedulerNode(ComputedBuffer)
    buf241.writes = [MemoryDep('buf241', 0, {}, None)]
    buf241.unmet_dependencies = [MemoryDep('buf240', 0, {}, None)]
    buf241.met_dependencies = [StarDep(name='primals_65', mode=None)]
    buf241.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf241.group.device = cuda:0
    buf241.group.iteration = (1, 1)
    buf241.sizes = ([], [])
    primals_65_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf240_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf241_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf241.mutations = ['primals_65']
    class buf241_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf240', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf241', get_index_1, load, None)
            return store
    buf241 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf240_buf241 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf248_buf249: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf248_buf249.writes = [MemoryDep('buf248', 0, {}, None), MemoryDep('buf249', 0, {}, None)]
buf248_buf249.unmet_dependencies = []
buf248_buf249.met_dependencies = [MemoryDep('primals_68', 0, {}, None), StarDep(name='primals_68', mode=None)]
buf248_buf249.users = []
    buf248_buf249.snodes[0] =
    buf248: SchedulerNode(ComputedBuffer)
    buf248.writes = [MemoryDep('buf248', 0, {}, None)]
    buf248.unmet_dependencies = []
    buf248.met_dependencies = [MemoryDep('primals_68', 0, {}, None)]
    buf248.users = [NodeUser(node=SchedulerNode(name='buf249'), can_inplace=True, is_weak=False)]
    buf248.group.device = cuda:0
    buf248.group.iteration = (1, 1)
    buf248.sizes = ([], [])
    primals_68_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf248_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf248_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_68', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf248', get_index_1, add, None)
            return store
    buf248 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf248_buf249.snodes[1] =
    buf249: SchedulerNode(ComputedBuffer)
    buf249.writes = [MemoryDep('buf249', 0, {}, None)]
    buf249.unmet_dependencies = [MemoryDep('buf248', 0, {}, None)]
    buf249.met_dependencies = [StarDep(name='primals_68', mode=None)]
    buf249.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf249.group.device = cuda:0
    buf249.group.iteration = (1, 1)
    buf249.sizes = ([], [])
    buf248_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_68_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf249_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf249.mutations = ['primals_68']
    class buf249_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf248', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf249', get_index_1, load, None)
            return store
    buf249 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf248_buf249 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf256_buf257: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf256_buf257.writes = [MemoryDep('buf256', 0, {}, None), MemoryDep('buf257', 0, {}, None)]
buf256_buf257.unmet_dependencies = []
buf256_buf257.met_dependencies = [MemoryDep('primals_71', 0, {}, None), StarDep(name='primals_71', mode=None)]
buf256_buf257.users = []
    buf256_buf257.snodes[0] =
    buf256: SchedulerNode(ComputedBuffer)
    buf256.writes = [MemoryDep('buf256', 0, {}, None)]
    buf256.unmet_dependencies = []
    buf256.met_dependencies = [MemoryDep('primals_71', 0, {}, None)]
    buf256.users = [NodeUser(node=SchedulerNode(name='buf257'), can_inplace=True, is_weak=False)]
    buf256.group.device = cuda:0
    buf256.group.iteration = (1, 1)
    buf256.sizes = ([], [])
    primals_71_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf256_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf256_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_71', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf256', get_index_1, add, None)
            return store
    buf256 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf256_buf257.snodes[1] =
    buf257: SchedulerNode(ComputedBuffer)
    buf257.writes = [MemoryDep('buf257', 0, {}, None)]
    buf257.unmet_dependencies = [MemoryDep('buf256', 0, {}, None)]
    buf257.met_dependencies = [StarDep(name='primals_71', mode=None)]
    buf257.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf257.group.device = cuda:0
    buf257.group.iteration = (1, 1)
    buf257.sizes = ([], [])
    buf256_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_71_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf257_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf257.mutations = ['primals_71']
    class buf257_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf256', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf257', get_index_1, load, None)
            return store
    buf257 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf256_buf257 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf264_buf265: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf264_buf265.writes = [MemoryDep('buf264', 0, {}, None), MemoryDep('buf265', 0, {}, None)]
buf264_buf265.unmet_dependencies = []
buf264_buf265.met_dependencies = [MemoryDep('primals_74', 0, {}, None), StarDep(name='primals_74', mode=None)]
buf264_buf265.users = []
    buf264_buf265.snodes[0] =
    buf264: SchedulerNode(ComputedBuffer)
    buf264.writes = [MemoryDep('buf264', 0, {}, None)]
    buf264.unmet_dependencies = []
    buf264.met_dependencies = [MemoryDep('primals_74', 0, {}, None)]
    buf264.users = [NodeUser(node=SchedulerNode(name='buf265'), can_inplace=True, is_weak=False)]
    buf264.group.device = cuda:0
    buf264.group.iteration = (1, 1)
    buf264.sizes = ([], [])
    primals_74_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf264_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf264_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_74', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf264', get_index_1, add, None)
            return store
    buf264 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf264_buf265.snodes[1] =
    buf265: SchedulerNode(ComputedBuffer)
    buf265.writes = [MemoryDep('buf265', 0, {}, None)]
    buf265.unmet_dependencies = [MemoryDep('buf264', 0, {}, None)]
    buf265.met_dependencies = [StarDep(name='primals_74', mode=None)]
    buf265.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf265.group.device = cuda:0
    buf265.group.iteration = (1, 1)
    buf265.sizes = ([], [])
    buf264_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_74_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf265_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf265.mutations = ['primals_74']
    class buf265_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf264', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf265', get_index_1, load, None)
            return store
    buf265 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf264_buf265 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf272_buf273: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf272_buf273.writes = [MemoryDep('buf272', 0, {}, None), MemoryDep('buf273', 0, {}, None)]
buf272_buf273.unmet_dependencies = []
buf272_buf273.met_dependencies = [MemoryDep('primals_77', 0, {}, None), StarDep(name='primals_77', mode=None)]
buf272_buf273.users = []
    buf272_buf273.snodes[0] =
    buf272: SchedulerNode(ComputedBuffer)
    buf272.writes = [MemoryDep('buf272', 0, {}, None)]
    buf272.unmet_dependencies = []
    buf272.met_dependencies = [MemoryDep('primals_77', 0, {}, None)]
    buf272.users = [NodeUser(node=SchedulerNode(name='buf273'), can_inplace=True, is_weak=False)]
    buf272.group.device = cuda:0
    buf272.group.iteration = (1, 1)
    buf272.sizes = ([], [])
    primals_77_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf272_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf272_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_77', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf272', get_index_1, add, None)
            return store
    buf272 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf272_buf273.snodes[1] =
    buf273: SchedulerNode(ComputedBuffer)
    buf273.writes = [MemoryDep('buf273', 0, {}, None)]
    buf273.unmet_dependencies = [MemoryDep('buf272', 0, {}, None)]
    buf273.met_dependencies = [StarDep(name='primals_77', mode=None)]
    buf273.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf273.group.device = cuda:0
    buf273.group.iteration = (1, 1)
    buf273.sizes = ([], [])
    primals_77_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf272_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf273_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf273.mutations = ['primals_77']
    class buf273_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf272', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf273', get_index_1, load, None)
            return store
    buf273 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf272_buf273 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf280_buf281: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf280_buf281.writes = [MemoryDep('buf280', 0, {}, None), MemoryDep('buf281', 0, {}, None)]
buf280_buf281.unmet_dependencies = []
buf280_buf281.met_dependencies = [MemoryDep('primals_80', 0, {}, None), StarDep(name='primals_80', mode=None)]
buf280_buf281.users = []
    buf280_buf281.snodes[0] =
    buf280: SchedulerNode(ComputedBuffer)
    buf280.writes = [MemoryDep('buf280', 0, {}, None)]
    buf280.unmet_dependencies = []
    buf280.met_dependencies = [MemoryDep('primals_80', 0, {}, None)]
    buf280.users = [NodeUser(node=SchedulerNode(name='buf281'), can_inplace=True, is_weak=False)]
    buf280.group.device = cuda:0
    buf280.group.iteration = (1, 1)
    buf280.sizes = ([], [])
    primals_80_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf280_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf280_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_80', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf280', get_index_1, add, None)
            return store
    buf280 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf280_buf281.snodes[1] =
    buf281: SchedulerNode(ComputedBuffer)
    buf281.writes = [MemoryDep('buf281', 0, {}, None)]
    buf281.unmet_dependencies = [MemoryDep('buf280', 0, {}, None)]
    buf281.met_dependencies = [StarDep(name='primals_80', mode=None)]
    buf281.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf281.group.device = cuda:0
    buf281.group.iteration = (1, 1)
    buf281.sizes = ([], [])
    buf280_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_80_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf281_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf281.mutations = ['primals_80']
    class buf281_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf280', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf281', get_index_1, load, None)
            return store
    buf281 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf280_buf281 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf288_buf289: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf288_buf289.writes = [MemoryDep('buf288', 0, {}, None), MemoryDep('buf289', 0, {}, None)]
buf288_buf289.unmet_dependencies = []
buf288_buf289.met_dependencies = [MemoryDep('primals_83', 0, {}, None), StarDep(name='primals_83', mode=None)]
buf288_buf289.users = []
    buf288_buf289.snodes[0] =
    buf288: SchedulerNode(ComputedBuffer)
    buf288.writes = [MemoryDep('buf288', 0, {}, None)]
    buf288.unmet_dependencies = []
    buf288.met_dependencies = [MemoryDep('primals_83', 0, {}, None)]
    buf288.users = [NodeUser(node=SchedulerNode(name='buf289'), can_inplace=True, is_weak=False)]
    buf288.group.device = cuda:0
    buf288.group.iteration = (1, 1)
    buf288.sizes = ([], [])
    primals_83_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf288_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf288_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_83', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf288', get_index_1, add, None)
            return store
    buf288 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf288_buf289.snodes[1] =
    buf289: SchedulerNode(ComputedBuffer)
    buf289.writes = [MemoryDep('buf289', 0, {}, None)]
    buf289.unmet_dependencies = [MemoryDep('buf288', 0, {}, None)]
    buf289.met_dependencies = [StarDep(name='primals_83', mode=None)]
    buf289.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf289.group.device = cuda:0
    buf289.group.iteration = (1, 1)
    buf289.sizes = ([], [])
    buf288_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_83_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf289_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf289.mutations = ['primals_83']
    class buf289_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf288', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf289', get_index_1, load, None)
            return store
    buf289 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf288_buf289 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf296_buf297: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf296_buf297.writes = [MemoryDep('buf296', 0, {}, None), MemoryDep('buf297', 0, {}, None)]
buf296_buf297.unmet_dependencies = []
buf296_buf297.met_dependencies = [MemoryDep('primals_86', 0, {}, None), StarDep(name='primals_86', mode=None)]
buf296_buf297.users = []
    buf296_buf297.snodes[0] =
    buf296: SchedulerNode(ComputedBuffer)
    buf296.writes = [MemoryDep('buf296', 0, {}, None)]
    buf296.unmet_dependencies = []
    buf296.met_dependencies = [MemoryDep('primals_86', 0, {}, None)]
    buf296.users = [NodeUser(node=SchedulerNode(name='buf297'), can_inplace=True, is_weak=False)]
    buf296.group.device = cuda:0
    buf296.group.iteration = (1, 1)
    buf296.sizes = ([], [])
    primals_86_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf296_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf296_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_86', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf296', get_index_1, add, None)
            return store
    buf296 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf296_buf297.snodes[1] =
    buf297: SchedulerNode(ComputedBuffer)
    buf297.writes = [MemoryDep('buf297', 0, {}, None)]
    buf297.unmet_dependencies = [MemoryDep('buf296', 0, {}, None)]
    buf297.met_dependencies = [StarDep(name='primals_86', mode=None)]
    buf297.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf297.group.device = cuda:0
    buf297.group.iteration = (1, 1)
    buf297.sizes = ([], [])
    primals_86_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf296_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf297_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf297.mutations = ['primals_86']
    class buf297_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf296', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf297', get_index_1, load, None)
            return store
    buf297 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf296_buf297 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf304_buf305: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf304_buf305.writes = [MemoryDep('buf304', 0, {}, None), MemoryDep('buf305', 0, {}, None)]
buf304_buf305.unmet_dependencies = []
buf304_buf305.met_dependencies = [MemoryDep('primals_89', 0, {}, None), StarDep(name='primals_89', mode=None)]
buf304_buf305.users = []
    buf304_buf305.snodes[0] =
    buf304: SchedulerNode(ComputedBuffer)
    buf304.writes = [MemoryDep('buf304', 0, {}, None)]
    buf304.unmet_dependencies = []
    buf304.met_dependencies = [MemoryDep('primals_89', 0, {}, None)]
    buf304.users = [NodeUser(node=SchedulerNode(name='buf305'), can_inplace=True, is_weak=False)]
    buf304.group.device = cuda:0
    buf304.group.iteration = (1, 1)
    buf304.sizes = ([], [])
    primals_89_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf304_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf304_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_89', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf304', get_index_1, add, None)
            return store
    buf304 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf304_buf305.snodes[1] =
    buf305: SchedulerNode(ComputedBuffer)
    buf305.writes = [MemoryDep('buf305', 0, {}, None)]
    buf305.unmet_dependencies = [MemoryDep('buf304', 0, {}, None)]
    buf305.met_dependencies = [StarDep(name='primals_89', mode=None)]
    buf305.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf305.group.device = cuda:0
    buf305.group.iteration = (1, 1)
    buf305.sizes = ([], [])
    primals_89_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf304_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf305_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf305.mutations = ['primals_89']
    class buf305_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf304', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf305', get_index_1, load, None)
            return store
    buf305 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf304_buf305 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf312_buf313: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf312_buf313.writes = [MemoryDep('buf312', 0, {}, None), MemoryDep('buf313', 0, {}, None)]
buf312_buf313.unmet_dependencies = []
buf312_buf313.met_dependencies = [MemoryDep('primals_92', 0, {}, None), StarDep(name='primals_92', mode=None)]
buf312_buf313.users = []
    buf312_buf313.snodes[0] =
    buf312: SchedulerNode(ComputedBuffer)
    buf312.writes = [MemoryDep('buf312', 0, {}, None)]
    buf312.unmet_dependencies = []
    buf312.met_dependencies = [MemoryDep('primals_92', 0, {}, None)]
    buf312.users = [NodeUser(node=SchedulerNode(name='buf313'), can_inplace=True, is_weak=False)]
    buf312.group.device = cuda:0
    buf312.group.iteration = (1, 1)
    buf312.sizes = ([], [])
    primals_92_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf312_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf312_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_92', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf312', get_index_1, add, None)
            return store
    buf312 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf312_buf313.snodes[1] =
    buf313: SchedulerNode(ComputedBuffer)
    buf313.writes = [MemoryDep('buf313', 0, {}, None)]
    buf313.unmet_dependencies = [MemoryDep('buf312', 0, {}, None)]
    buf313.met_dependencies = [StarDep(name='primals_92', mode=None)]
    buf313.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf313.group.device = cuda:0
    buf313.group.iteration = (1, 1)
    buf313.sizes = ([], [])
    buf312_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_92_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf313_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf313.mutations = ['primals_92']
    class buf313_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf312', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf313', get_index_1, load, None)
            return store
    buf313 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf312_buf313 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf320_buf321: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf320_buf321.writes = [MemoryDep('buf320', 0, {}, None), MemoryDep('buf321', 0, {}, None)]
buf320_buf321.unmet_dependencies = []
buf320_buf321.met_dependencies = [MemoryDep('primals_95', 0, {}, None), StarDep(name='primals_95', mode=None)]
buf320_buf321.users = []
    buf320_buf321.snodes[0] =
    buf320: SchedulerNode(ComputedBuffer)
    buf320.writes = [MemoryDep('buf320', 0, {}, None)]
    buf320.unmet_dependencies = []
    buf320.met_dependencies = [MemoryDep('primals_95', 0, {}, None)]
    buf320.users = [NodeUser(node=SchedulerNode(name='buf321'), can_inplace=True, is_weak=False)]
    buf320.group.device = cuda:0
    buf320.group.iteration = (1, 1)
    buf320.sizes = ([], [])
    primals_95_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf320_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf320_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_95', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf320', get_index_1, add, None)
            return store
    buf320 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf320_buf321.snodes[1] =
    buf321: SchedulerNode(ComputedBuffer)
    buf321.writes = [MemoryDep('buf321', 0, {}, None)]
    buf321.unmet_dependencies = [MemoryDep('buf320', 0, {}, None)]
    buf321.met_dependencies = [StarDep(name='primals_95', mode=None)]
    buf321.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf321.group.device = cuda:0
    buf321.group.iteration = (1, 1)
    buf321.sizes = ([], [])
    primals_95_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf320_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf321_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf321.mutations = ['primals_95']
    class buf321_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf320', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf321', get_index_1, load, None)
            return store
    buf321 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf320_buf321 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf328_buf329: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf328_buf329.writes = [MemoryDep('buf328', 0, {}, None), MemoryDep('buf329', 0, {}, None)]
buf328_buf329.unmet_dependencies = []
buf328_buf329.met_dependencies = [MemoryDep('primals_98', 0, {}, None), StarDep(name='primals_98', mode=None)]
buf328_buf329.users = []
    buf328_buf329.snodes[0] =
    buf328: SchedulerNode(ComputedBuffer)
    buf328.writes = [MemoryDep('buf328', 0, {}, None)]
    buf328.unmet_dependencies = []
    buf328.met_dependencies = [MemoryDep('primals_98', 0, {}, None)]
    buf328.users = [NodeUser(node=SchedulerNode(name='buf329'), can_inplace=True, is_weak=False)]
    buf328.group.device = cuda:0
    buf328.group.iteration = (1, 1)
    buf328.sizes = ([], [])
    primals_98_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf328_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf328_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_98', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf328', get_index_1, add, None)
            return store
    buf328 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf328_buf329.snodes[1] =
    buf329: SchedulerNode(ComputedBuffer)
    buf329.writes = [MemoryDep('buf329', 0, {}, None)]
    buf329.unmet_dependencies = [MemoryDep('buf328', 0, {}, None)]
    buf329.met_dependencies = [StarDep(name='primals_98', mode=None)]
    buf329.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf329.group.device = cuda:0
    buf329.group.iteration = (1, 1)
    buf329.sizes = ([], [])
    buf328_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_98_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf329_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf329.mutations = ['primals_98']
    class buf329_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf328', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf329', get_index_1, load, None)
            return store
    buf329 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf328_buf329 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf336_buf337: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf336_buf337.writes = [MemoryDep('buf336', 0, {}, None), MemoryDep('buf337', 0, {}, None)]
buf336_buf337.unmet_dependencies = []
buf336_buf337.met_dependencies = [MemoryDep('primals_101', 0, {}, None), StarDep(name='primals_101', mode=None)]
buf336_buf337.users = []
    buf336_buf337.snodes[0] =
    buf336: SchedulerNode(ComputedBuffer)
    buf336.writes = [MemoryDep('buf336', 0, {}, None)]
    buf336.unmet_dependencies = []
    buf336.met_dependencies = [MemoryDep('primals_101', 0, {}, None)]
    buf336.users = [NodeUser(node=SchedulerNode(name='buf337'), can_inplace=True, is_weak=False)]
    buf336.group.device = cuda:0
    buf336.group.iteration = (1, 1)
    buf336.sizes = ([], [])
    primals_101_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf336_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf336_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_101', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf336', get_index_1, add, None)
            return store
    buf336 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf336_buf337.snodes[1] =
    buf337: SchedulerNode(ComputedBuffer)
    buf337.writes = [MemoryDep('buf337', 0, {}, None)]
    buf337.unmet_dependencies = [MemoryDep('buf336', 0, {}, None)]
    buf337.met_dependencies = [StarDep(name='primals_101', mode=None)]
    buf337.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf337.group.device = cuda:0
    buf337.group.iteration = (1, 1)
    buf337.sizes = ([], [])
    buf336_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_101_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf337_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf337.mutations = ['primals_101']
    class buf337_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf336', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf337', get_index_1, load, None)
            return store
    buf337 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf336_buf337 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf344_buf345: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf344_buf345.writes = [MemoryDep('buf344', 0, {}, None), MemoryDep('buf345', 0, {}, None)]
buf344_buf345.unmet_dependencies = []
buf344_buf345.met_dependencies = [MemoryDep('primals_104', 0, {}, None), StarDep(name='primals_104', mode=None)]
buf344_buf345.users = []
    buf344_buf345.snodes[0] =
    buf344: SchedulerNode(ComputedBuffer)
    buf344.writes = [MemoryDep('buf344', 0, {}, None)]
    buf344.unmet_dependencies = []
    buf344.met_dependencies = [MemoryDep('primals_104', 0, {}, None)]
    buf344.users = [NodeUser(node=SchedulerNode(name='buf345'), can_inplace=True, is_weak=False)]
    buf344.group.device = cuda:0
    buf344.group.iteration = (1, 1)
    buf344.sizes = ([], [])
    primals_104_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf344_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf344_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_104', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf344', get_index_1, add, None)
            return store
    buf344 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf344_buf345.snodes[1] =
    buf345: SchedulerNode(ComputedBuffer)
    buf345.writes = [MemoryDep('buf345', 0, {}, None)]
    buf345.unmet_dependencies = [MemoryDep('buf344', 0, {}, None)]
    buf345.met_dependencies = [StarDep(name='primals_104', mode=None)]
    buf345.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf345.group.device = cuda:0
    buf345.group.iteration = (1, 1)
    buf345.sizes = ([], [])
    primals_104_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf344_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf345_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf345.mutations = ['primals_104']
    class buf345_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf344', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf345', get_index_1, load, None)
            return store
    buf345 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf344_buf345 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf352_buf353: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf352_buf353.writes = [MemoryDep('buf352', 0, {}, None), MemoryDep('buf353', 0, {}, None)]
buf352_buf353.unmet_dependencies = []
buf352_buf353.met_dependencies = [MemoryDep('primals_107', 0, {}, None), StarDep(name='primals_107', mode=None)]
buf352_buf353.users = []
    buf352_buf353.snodes[0] =
    buf352: SchedulerNode(ComputedBuffer)
    buf352.writes = [MemoryDep('buf352', 0, {}, None)]
    buf352.unmet_dependencies = []
    buf352.met_dependencies = [MemoryDep('primals_107', 0, {}, None)]
    buf352.users = [NodeUser(node=SchedulerNode(name='buf353'), can_inplace=True, is_weak=False)]
    buf352.group.device = cuda:0
    buf352.group.iteration = (1, 1)
    buf352.sizes = ([], [])
    primals_107_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf352_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf352_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_107', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf352', get_index_1, add, None)
            return store
    buf352 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf352_buf353.snodes[1] =
    buf353: SchedulerNode(ComputedBuffer)
    buf353.writes = [MemoryDep('buf353', 0, {}, None)]
    buf353.unmet_dependencies = [MemoryDep('buf352', 0, {}, None)]
    buf353.met_dependencies = [StarDep(name='primals_107', mode=None)]
    buf353.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf353.group.device = cuda:0
    buf353.group.iteration = (1, 1)
    buf353.sizes = ([], [])
    primals_107_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf352_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf353_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf353.mutations = ['primals_107']
    class buf353_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf352', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf353', get_index_1, load, None)
            return store
    buf353 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf352_buf353 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf360_buf361: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf360_buf361.writes = [MemoryDep('buf360', 0, {}, None), MemoryDep('buf361', 0, {}, None)]
buf360_buf361.unmet_dependencies = []
buf360_buf361.met_dependencies = [MemoryDep('primals_110', 0, {}, None), StarDep(name='primals_110', mode=None)]
buf360_buf361.users = []
    buf360_buf361.snodes[0] =
    buf360: SchedulerNode(ComputedBuffer)
    buf360.writes = [MemoryDep('buf360', 0, {}, None)]
    buf360.unmet_dependencies = []
    buf360.met_dependencies = [MemoryDep('primals_110', 0, {}, None)]
    buf360.users = [NodeUser(node=SchedulerNode(name='buf361'), can_inplace=True, is_weak=False)]
    buf360.group.device = cuda:0
    buf360.group.iteration = (1, 1)
    buf360.sizes = ([], [])
    primals_110_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf360_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf360_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_110', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf360', get_index_1, add, None)
            return store
    buf360 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf360_buf361.snodes[1] =
    buf361: SchedulerNode(ComputedBuffer)
    buf361.writes = [MemoryDep('buf361', 0, {}, None)]
    buf361.unmet_dependencies = [MemoryDep('buf360', 0, {}, None)]
    buf361.met_dependencies = [StarDep(name='primals_110', mode=None)]
    buf361.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf361.group.device = cuda:0
    buf361.group.iteration = (1, 1)
    buf361.sizes = ([], [])
    buf360_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_110_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf361_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf361.mutations = ['primals_110']
    class buf361_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf360', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf361', get_index_1, load, None)
            return store
    buf361 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf360_buf361 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf368_buf369: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf368_buf369.writes = [MemoryDep('buf368', 0, {}, None), MemoryDep('buf369', 0, {}, None)]
buf368_buf369.unmet_dependencies = []
buf368_buf369.met_dependencies = [MemoryDep('primals_113', 0, {}, None), StarDep(name='primals_113', mode=None)]
buf368_buf369.users = []
    buf368_buf369.snodes[0] =
    buf368: SchedulerNode(ComputedBuffer)
    buf368.writes = [MemoryDep('buf368', 0, {}, None)]
    buf368.unmet_dependencies = []
    buf368.met_dependencies = [MemoryDep('primals_113', 0, {}, None)]
    buf368.users = [NodeUser(node=SchedulerNode(name='buf369'), can_inplace=True, is_weak=False)]
    buf368.group.device = cuda:0
    buf368.group.iteration = (1, 1)
    buf368.sizes = ([], [])
    primals_113_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf368_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf368_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_113', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf368', get_index_1, add, None)
            return store
    buf368 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf368_buf369.snodes[1] =
    buf369: SchedulerNode(ComputedBuffer)
    buf369.writes = [MemoryDep('buf369', 0, {}, None)]
    buf369.unmet_dependencies = [MemoryDep('buf368', 0, {}, None)]
    buf369.met_dependencies = [StarDep(name='primals_113', mode=None)]
    buf369.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf369.group.device = cuda:0
    buf369.group.iteration = (1, 1)
    buf369.sizes = ([], [])
    buf368_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    primals_113_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf369_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf369.mutations = ['primals_113']
    class buf369_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf368', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf369', get_index_1, load, None)
            return store
    buf369 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf368_buf369 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf376_buf377: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf376_buf377.writes = [MemoryDep('buf376', 0, {}, None), MemoryDep('buf377', 0, {}, None)]
buf376_buf377.unmet_dependencies = []
buf376_buf377.met_dependencies = [MemoryDep('primals_116', 0, {}, None), StarDep(name='primals_116', mode=None)]
buf376_buf377.users = []
    buf376_buf377.snodes[0] =
    buf376: SchedulerNode(ComputedBuffer)
    buf376.writes = [MemoryDep('buf376', 0, {}, None)]
    buf376.unmet_dependencies = []
    buf376.met_dependencies = [MemoryDep('primals_116', 0, {}, None)]
    buf376.users = [NodeUser(node=SchedulerNode(name='buf377'), can_inplace=True, is_weak=False)]
    buf376.group.device = cuda:0
    buf376.group.iteration = (1, 1)
    buf376.sizes = ([], [])
    primals_116_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf376_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf376_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_116', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf376', get_index_1, add, None)
            return store
    buf376 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf376_buf377.snodes[1] =
    buf377: SchedulerNode(ComputedBuffer)
    buf377.writes = [MemoryDep('buf377', 0, {}, None)]
    buf377.unmet_dependencies = [MemoryDep('buf376', 0, {}, None)]
    buf377.met_dependencies = [StarDep(name='primals_116', mode=None)]
    buf377.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf377.group.device = cuda:0
    buf377.group.iteration = (1, 1)
    buf377.sizes = ([], [])
    primals_116_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf376_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf377_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf377.mutations = ['primals_116']
    class buf377_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf376', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf377', get_index_1, load, None)
            return store
    buf377 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf376_buf377 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf384_buf385: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf384_buf385.writes = [MemoryDep('buf384', 0, {}, None), MemoryDep('buf385', 0, {}, None)]
buf384_buf385.unmet_dependencies = []
buf384_buf385.met_dependencies = [MemoryDep('primals_119', 0, {}, None), StarDep(name='primals_119', mode=None)]
buf384_buf385.users = []
    buf384_buf385.snodes[0] =
    buf384: SchedulerNode(ComputedBuffer)
    buf384.writes = [MemoryDep('buf384', 0, {}, None)]
    buf384.unmet_dependencies = []
    buf384.met_dependencies = [MemoryDep('primals_119', 0, {}, None)]
    buf384.users = [NodeUser(node=SchedulerNode(name='buf385'), can_inplace=True, is_weak=False)]
    buf384.group.device = cuda:0
    buf384.group.iteration = (1, 1)
    buf384.sizes = ([], [])
    primals_119_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf384_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf384_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_119', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf384', get_index_1, add, None)
            return store
    buf384 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf384_buf385.snodes[1] =
    buf385: SchedulerNode(ComputedBuffer)
    buf385.writes = [MemoryDep('buf385', 0, {}, None)]
    buf385.unmet_dependencies = [MemoryDep('buf384', 0, {}, None)]
    buf385.met_dependencies = [StarDep(name='primals_119', mode=None)]
    buf385.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf385.group.device = cuda:0
    buf385.group.iteration = (1, 1)
    buf385.sizes = ([], [])
    primals_119_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf384_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf385_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf385.mutations = ['primals_119']
    class buf385_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf384', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf385', get_index_1, load, None)
            return store
    buf385 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf384_buf385 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


buf392_buf393: FusedSchedulerNode(SchedulerNode,SchedulerNode)
buf392_buf393.writes = [MemoryDep('buf392', 0, {}, None), MemoryDep('buf393', 0, {}, None)]
buf392_buf393.unmet_dependencies = []
buf392_buf393.met_dependencies = [MemoryDep('primals_122', 0, {}, None), StarDep(name='primals_122', mode=None)]
buf392_buf393.users = []
    buf392_buf393.snodes[0] =
    buf392: SchedulerNode(ComputedBuffer)
    buf392.writes = [MemoryDep('buf392', 0, {}, None)]
    buf392.unmet_dependencies = []
    buf392.met_dependencies = [MemoryDep('primals_122', 0, {}, None)]
    buf392.users = [NodeUser(node=SchedulerNode(name='buf393'), can_inplace=True, is_weak=False)]
    buf392.group.device = cuda:0
    buf392.group.iteration = (1, 1)
    buf392.sizes = ([], [])
    primals_122_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf392_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    class buf392_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('primals_122', get_index)
            constant = ops.constant(1, torch.int64)
            add = ops.add(load, constant)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf392', get_index_1, add, None)
            return store
    buf392 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
    buf392_buf393.snodes[1] =
    buf393: SchedulerNode(ComputedBuffer)
    buf393.writes = [MemoryDep('buf393', 0, {}, None)]
    buf393.unmet_dependencies = [MemoryDep('buf392', 0, {}, None)]
    buf393.met_dependencies = [StarDep(name='primals_122', mode=None)]
    buf393.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf393.group.device = cuda:0
    buf393.group.iteration = (1, 1)
    buf393.sizes = ([], [])
    primals_122_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf392_layout = FixedLayout('cuda', torch.int64, size=[], stride=[])
    buf393_layout = MutationLayoutSHOULDREMOVE('cuda', torch.int64, size=[], stride=[])
    buf393.mutations = ['primals_122']
    class buf393_loop_body:
        var_ranges = {}
        index0 = 0
        def body(self, ops):
            get_index = self.get_index('index0')
            load = ops.load('buf392', get_index)
            get_index_1 = self.get_index('index0')
            store = ops.store('buf393', get_index_1, load, None)
            return store
    buf393 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['out_ptr0'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp1, None)
    buf392_buf393 Triton code:
        import triton
        import triton.language as tl
        from triton.compiler.compiler import AttrsDescriptor

        from torch._inductor.runtime import triton_helpers, triton_heuristics
        from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
        from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

        @triton_heuristics.pointwise(
            size_hints=[1], 
            filename=__file__,
            triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=75, major=7, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1024, multi_processor_count=68), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
            inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_ptr0', 'out_ptr1'], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '3472E74E07164CD5A94178B887164652E5C68546B4AF361AEB32FE97E562B33C', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
            min_elem_per_thread=0
        )
        @triton.jit
        def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
            xnumel = 1
            xoffset = tl.program_id(0) * XBLOCK
            xindex = xoffset + tl.arange(0, XBLOCK)[:]
            xmask = xindex < xnumel
            tmp0 = tl.load(in_ptr0 + (0))
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
            tmp2 = tl.full([1], 1, tl.int64)
            tmp3 = tmp1 + tmp2
            tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)


